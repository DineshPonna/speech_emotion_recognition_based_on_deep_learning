{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 574,
      "id": "e1f95dfd",
      "metadata": {
        "id": "e1f95dfd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import seaborn as sns\n",
        "import librosa\n",
        "import librosa.display\n",
        "import IPython.display as pld\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow.keras as keras\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xe7uVNwQ3Ppw",
        "outputId": "a797fc62-6388-4370-8b15-49275729b95a"
      },
      "id": "Xe7uVNwQ3Ppw",
      "execution_count": 575,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 576,
      "id": "603a1332",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "603a1332",
        "outputId": "1b044c50-63ad-43f2-de9d-013a771201a3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Unnamed: 0          0          1          2          3          4  \\\n",
              "0             0 -482.45233  62.835957  -0.348998  26.264595   2.978607   \n",
              "1             1 -469.48477  88.400730  -7.127512  29.156132   5.335554   \n",
              "2             2 -454.89886  45.067265  -0.193278  15.111545   3.080835   \n",
              "3             3 -447.12630  86.114920   4.772520  38.097256   8.324276   \n",
              "4             4 -451.45264  71.335200  12.223010  32.649555   3.997801   \n",
              "..          ...        ...        ...        ...        ...        ...   \n",
              "423         423 -478.05527   5.705422 -24.631056  27.622614 -19.235449   \n",
              "424         424 -418.62490  57.015880   6.383415  47.618423  -8.051490   \n",
              "425         425 -427.36716  51.473750   4.835125  40.900140   6.937289   \n",
              "426         426 -526.19570  11.317784 -18.942173  29.540787 -28.057306   \n",
              "427         427 -437.97220   5.289146 -22.667547  25.394840 -28.545520   \n",
              "\n",
              "             5          6         7          8  ...       250       251  \\\n",
              "0     6.900927 -13.006243  0.273391  -9.196591  ...  0.675823  0.684034   \n",
              "1     7.147227  -6.727572 -8.307674  -3.364513  ...  0.635522  0.544438   \n",
              "2     4.204241 -10.440731 -6.615343 -16.249382  ...  0.575784  0.523305   \n",
              "3     8.538317  -4.507682 -7.680664  -7.317249  ...  0.615263  0.566964   \n",
              "4    15.200773  -2.812883 -1.384373  -6.467040  ...  0.719856  0.667424   \n",
              "..         ...        ...       ...        ...  ...       ...       ...   \n",
              "423  -7.040019 -13.293165 -9.629133 -14.067036  ...  0.590422  0.481957   \n",
              "424   4.213936 -15.029120 -2.448467 -10.805821  ...  0.569263  0.551809   \n",
              "425  13.700687  -8.331753 -0.583414  -6.279562  ...  0.638155  0.574542   \n",
              "426   1.299599 -16.251814 -7.512440 -23.191568  ...  0.528861  0.501070   \n",
              "427   0.428451 -11.650926 -8.022680 -18.337156  ...  0.495079  0.539387   \n",
              "\n",
              "          252       253       254       255       256       257       258  0.1  \n",
              "0    0.627376 -0.001574  0.012645 -0.027069  0.019313 -0.002252 -0.006220    0  \n",
              "1    0.532856 -0.018488  0.011973 -0.011038  0.079758 -0.021044 -0.019445    1  \n",
              "2    0.423375  0.009395 -0.025547 -0.035554 -0.025885  0.011198 -0.000163    0  \n",
              "3    0.605103 -0.008389 -0.051995 -0.056544 -0.020014  0.013964  0.008349    1  \n",
              "4    0.570905  0.003044 -0.006101 -0.009038 -0.049699  0.027615  0.021319    3  \n",
              "..        ...       ...       ...       ...       ...       ...       ...  ...  \n",
              "423  0.481437 -0.011216 -0.031485 -0.029936  0.042160 -0.013815  0.009839    0  \n",
              "424  0.576764  0.016046 -0.025610  0.025426 -0.094371  0.008999 -0.004985    5  \n",
              "425  0.503516  0.019632  0.046315  0.074801  0.018078  0.022948 -0.016365    3  \n",
              "426  0.496900  0.007856  0.005917 -0.045393 -0.004246 -0.001628  0.015051    2  \n",
              "427  0.527394 -0.001086  0.013948  0.013274 -0.056855 -0.001004 -0.001355    2  \n",
              "\n",
              "[428 rows x 261 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6c02d54b-64cd-4ae2-af13-0545a1f85de0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>...</th>\n",
              "      <th>250</th>\n",
              "      <th>251</th>\n",
              "      <th>252</th>\n",
              "      <th>253</th>\n",
              "      <th>254</th>\n",
              "      <th>255</th>\n",
              "      <th>256</th>\n",
              "      <th>257</th>\n",
              "      <th>258</th>\n",
              "      <th>0.1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>-482.45233</td>\n",
              "      <td>62.835957</td>\n",
              "      <td>-0.348998</td>\n",
              "      <td>26.264595</td>\n",
              "      <td>2.978607</td>\n",
              "      <td>6.900927</td>\n",
              "      <td>-13.006243</td>\n",
              "      <td>0.273391</td>\n",
              "      <td>-9.196591</td>\n",
              "      <td>...</td>\n",
              "      <td>0.675823</td>\n",
              "      <td>0.684034</td>\n",
              "      <td>0.627376</td>\n",
              "      <td>-0.001574</td>\n",
              "      <td>0.012645</td>\n",
              "      <td>-0.027069</td>\n",
              "      <td>0.019313</td>\n",
              "      <td>-0.002252</td>\n",
              "      <td>-0.006220</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>-469.48477</td>\n",
              "      <td>88.400730</td>\n",
              "      <td>-7.127512</td>\n",
              "      <td>29.156132</td>\n",
              "      <td>5.335554</td>\n",
              "      <td>7.147227</td>\n",
              "      <td>-6.727572</td>\n",
              "      <td>-8.307674</td>\n",
              "      <td>-3.364513</td>\n",
              "      <td>...</td>\n",
              "      <td>0.635522</td>\n",
              "      <td>0.544438</td>\n",
              "      <td>0.532856</td>\n",
              "      <td>-0.018488</td>\n",
              "      <td>0.011973</td>\n",
              "      <td>-0.011038</td>\n",
              "      <td>0.079758</td>\n",
              "      <td>-0.021044</td>\n",
              "      <td>-0.019445</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>-454.89886</td>\n",
              "      <td>45.067265</td>\n",
              "      <td>-0.193278</td>\n",
              "      <td>15.111545</td>\n",
              "      <td>3.080835</td>\n",
              "      <td>4.204241</td>\n",
              "      <td>-10.440731</td>\n",
              "      <td>-6.615343</td>\n",
              "      <td>-16.249382</td>\n",
              "      <td>...</td>\n",
              "      <td>0.575784</td>\n",
              "      <td>0.523305</td>\n",
              "      <td>0.423375</td>\n",
              "      <td>0.009395</td>\n",
              "      <td>-0.025547</td>\n",
              "      <td>-0.035554</td>\n",
              "      <td>-0.025885</td>\n",
              "      <td>0.011198</td>\n",
              "      <td>-0.000163</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>-447.12630</td>\n",
              "      <td>86.114920</td>\n",
              "      <td>4.772520</td>\n",
              "      <td>38.097256</td>\n",
              "      <td>8.324276</td>\n",
              "      <td>8.538317</td>\n",
              "      <td>-4.507682</td>\n",
              "      <td>-7.680664</td>\n",
              "      <td>-7.317249</td>\n",
              "      <td>...</td>\n",
              "      <td>0.615263</td>\n",
              "      <td>0.566964</td>\n",
              "      <td>0.605103</td>\n",
              "      <td>-0.008389</td>\n",
              "      <td>-0.051995</td>\n",
              "      <td>-0.056544</td>\n",
              "      <td>-0.020014</td>\n",
              "      <td>0.013964</td>\n",
              "      <td>0.008349</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>-451.45264</td>\n",
              "      <td>71.335200</td>\n",
              "      <td>12.223010</td>\n",
              "      <td>32.649555</td>\n",
              "      <td>3.997801</td>\n",
              "      <td>15.200773</td>\n",
              "      <td>-2.812883</td>\n",
              "      <td>-1.384373</td>\n",
              "      <td>-6.467040</td>\n",
              "      <td>...</td>\n",
              "      <td>0.719856</td>\n",
              "      <td>0.667424</td>\n",
              "      <td>0.570905</td>\n",
              "      <td>0.003044</td>\n",
              "      <td>-0.006101</td>\n",
              "      <td>-0.009038</td>\n",
              "      <td>-0.049699</td>\n",
              "      <td>0.027615</td>\n",
              "      <td>0.021319</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>423</th>\n",
              "      <td>423</td>\n",
              "      <td>-478.05527</td>\n",
              "      <td>5.705422</td>\n",
              "      <td>-24.631056</td>\n",
              "      <td>27.622614</td>\n",
              "      <td>-19.235449</td>\n",
              "      <td>-7.040019</td>\n",
              "      <td>-13.293165</td>\n",
              "      <td>-9.629133</td>\n",
              "      <td>-14.067036</td>\n",
              "      <td>...</td>\n",
              "      <td>0.590422</td>\n",
              "      <td>0.481957</td>\n",
              "      <td>0.481437</td>\n",
              "      <td>-0.011216</td>\n",
              "      <td>-0.031485</td>\n",
              "      <td>-0.029936</td>\n",
              "      <td>0.042160</td>\n",
              "      <td>-0.013815</td>\n",
              "      <td>0.009839</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>424</th>\n",
              "      <td>424</td>\n",
              "      <td>-418.62490</td>\n",
              "      <td>57.015880</td>\n",
              "      <td>6.383415</td>\n",
              "      <td>47.618423</td>\n",
              "      <td>-8.051490</td>\n",
              "      <td>4.213936</td>\n",
              "      <td>-15.029120</td>\n",
              "      <td>-2.448467</td>\n",
              "      <td>-10.805821</td>\n",
              "      <td>...</td>\n",
              "      <td>0.569263</td>\n",
              "      <td>0.551809</td>\n",
              "      <td>0.576764</td>\n",
              "      <td>0.016046</td>\n",
              "      <td>-0.025610</td>\n",
              "      <td>0.025426</td>\n",
              "      <td>-0.094371</td>\n",
              "      <td>0.008999</td>\n",
              "      <td>-0.004985</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>425</th>\n",
              "      <td>425</td>\n",
              "      <td>-427.36716</td>\n",
              "      <td>51.473750</td>\n",
              "      <td>4.835125</td>\n",
              "      <td>40.900140</td>\n",
              "      <td>6.937289</td>\n",
              "      <td>13.700687</td>\n",
              "      <td>-8.331753</td>\n",
              "      <td>-0.583414</td>\n",
              "      <td>-6.279562</td>\n",
              "      <td>...</td>\n",
              "      <td>0.638155</td>\n",
              "      <td>0.574542</td>\n",
              "      <td>0.503516</td>\n",
              "      <td>0.019632</td>\n",
              "      <td>0.046315</td>\n",
              "      <td>0.074801</td>\n",
              "      <td>0.018078</td>\n",
              "      <td>0.022948</td>\n",
              "      <td>-0.016365</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>426</th>\n",
              "      <td>426</td>\n",
              "      <td>-526.19570</td>\n",
              "      <td>11.317784</td>\n",
              "      <td>-18.942173</td>\n",
              "      <td>29.540787</td>\n",
              "      <td>-28.057306</td>\n",
              "      <td>1.299599</td>\n",
              "      <td>-16.251814</td>\n",
              "      <td>-7.512440</td>\n",
              "      <td>-23.191568</td>\n",
              "      <td>...</td>\n",
              "      <td>0.528861</td>\n",
              "      <td>0.501070</td>\n",
              "      <td>0.496900</td>\n",
              "      <td>0.007856</td>\n",
              "      <td>0.005917</td>\n",
              "      <td>-0.045393</td>\n",
              "      <td>-0.004246</td>\n",
              "      <td>-0.001628</td>\n",
              "      <td>0.015051</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>427</th>\n",
              "      <td>427</td>\n",
              "      <td>-437.97220</td>\n",
              "      <td>5.289146</td>\n",
              "      <td>-22.667547</td>\n",
              "      <td>25.394840</td>\n",
              "      <td>-28.545520</td>\n",
              "      <td>0.428451</td>\n",
              "      <td>-11.650926</td>\n",
              "      <td>-8.022680</td>\n",
              "      <td>-18.337156</td>\n",
              "      <td>...</td>\n",
              "      <td>0.495079</td>\n",
              "      <td>0.539387</td>\n",
              "      <td>0.527394</td>\n",
              "      <td>-0.001086</td>\n",
              "      <td>0.013948</td>\n",
              "      <td>0.013274</td>\n",
              "      <td>-0.056855</td>\n",
              "      <td>-0.001004</td>\n",
              "      <td>-0.001355</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>428 rows × 261 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6c02d54b-64cd-4ae2-af13-0545a1f85de0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6c02d54b-64cd-4ae2-af13-0545a1f85de0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6c02d54b-64cd-4ae2-af13-0545a1f85de0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-46174372-8dd4-4ccf-a62c-82a98a709ffa\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-46174372-8dd4-4ccf-a62c-82a98a709ffa')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-46174372-8dd4-4ccf-a62c-82a98a709ffa button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df1"
            }
          },
          "metadata": {},
          "execution_count": 576
        }
      ],
      "source": [
        "df1=pd.read_csv('/content/drive/MyDrive/DATASETS/EmoDB Dataset/train_fold1.csv')\n",
        "df1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 577,
      "id": "a08acf9d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "a08acf9d",
        "outputId": "0b168ec1-daaf-42dc-8caf-5e5ff9b0947b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Unnamed: 0          0          1          2          3          4  \\\n",
              "0             0 -434.88647  41.972150 -29.416862  18.537344  -4.156565   \n",
              "1             1 -478.92007  56.887730  -9.496516  12.799419  -0.196528   \n",
              "2             2 -449.64343  72.503365  11.100903  33.304817   3.467445   \n",
              "3             3 -448.45706  71.748140  15.644665  37.692158   1.685971   \n",
              "4             4 -414.10510  86.937454   8.643685  41.722900   3.845868   \n",
              "..          ...        ...        ...        ...        ...        ...   \n",
              "102         102 -542.56660   2.070298 -18.764479  16.167446 -24.879025   \n",
              "103         103 -406.23282  75.852394  -8.423434  34.064934 -11.914997   \n",
              "104         104 -427.61200  36.440388 -21.528141  13.495537 -19.663698   \n",
              "105         105 -397.74173  65.599550  -1.686943  38.130620 -12.816805   \n",
              "106         106 -467.15588  52.217026  10.470471  47.414780   8.690019   \n",
              "\n",
              "             5          6          7          8  ...       250       251  \\\n",
              "0     5.257353 -11.410935  -8.983023 -11.285996  ...  0.648380  0.675295   \n",
              "1     3.286758  -9.909594  -2.337262  -7.694031  ...  0.664169  0.700484   \n",
              "2     6.772911  -3.323741  -7.746681  -9.884865  ...  0.661381  0.594747   \n",
              "3    14.594450  -1.984497  -2.601064  -4.511068  ...  0.738209  0.685561   \n",
              "4    16.058064  -6.323769  -8.956205  -6.782947  ...  0.533943  0.539635   \n",
              "..         ...        ...        ...        ...  ...       ...       ...   \n",
              "102   1.178926 -15.186148  -2.770954 -14.010069  ...  0.532020  0.520468   \n",
              "103   7.173997 -20.511670 -12.389133  -5.993309  ...  0.502517  0.556970   \n",
              "104   4.418462 -20.588242 -13.769891 -17.446966  ...  0.377521  0.407803   \n",
              "105  14.129421 -20.335257 -13.580517  -3.846510  ...  0.574512  0.554483   \n",
              "106  15.601270  -2.032935   4.985774  -7.432734  ...  0.523647  0.509723   \n",
              "\n",
              "          252       253       254       255       256       257       258  0.1  \n",
              "0    0.560000 -0.010576 -0.000228  0.011102 -0.074188  0.012116 -0.000779    2  \n",
              "1    0.594266 -0.029971  0.019514 -0.009344 -0.040153  0.013369 -0.006417    0  \n",
              "2    0.571205  0.010062  0.019729 -0.021405 -0.003546  0.006231  0.004258    1  \n",
              "3    0.608525  0.010726  0.004152  0.011977 -0.039160  0.010682  0.003822    3  \n",
              "4    0.496446  0.031052  0.047855 -0.039647  0.006998  0.021142 -0.037041    5  \n",
              "..        ...       ...       ...       ...       ...       ...       ...  ...  \n",
              "102  0.532640 -0.002613  0.006743  0.025558 -0.024244 -0.016319  0.003650    2  \n",
              "103  0.543809  0.005737 -0.018652  0.023123  0.039628  0.024378  0.005283    5  \n",
              "104  0.410098  0.005356 -0.030501 -0.028373  0.043300  0.014572 -0.005967    4  \n",
              "105  0.523765  0.003604 -0.009971 -0.011075 -0.030320 -0.005274 -0.003526    5  \n",
              "106  0.498566  0.051532  0.015525 -0.006052  0.018201  0.004361 -0.021649    3  \n",
              "\n",
              "[107 rows x 261 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a757ffb2-86ce-45ee-9c1c-bd2c22765e9f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>...</th>\n",
              "      <th>250</th>\n",
              "      <th>251</th>\n",
              "      <th>252</th>\n",
              "      <th>253</th>\n",
              "      <th>254</th>\n",
              "      <th>255</th>\n",
              "      <th>256</th>\n",
              "      <th>257</th>\n",
              "      <th>258</th>\n",
              "      <th>0.1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>-434.88647</td>\n",
              "      <td>41.972150</td>\n",
              "      <td>-29.416862</td>\n",
              "      <td>18.537344</td>\n",
              "      <td>-4.156565</td>\n",
              "      <td>5.257353</td>\n",
              "      <td>-11.410935</td>\n",
              "      <td>-8.983023</td>\n",
              "      <td>-11.285996</td>\n",
              "      <td>...</td>\n",
              "      <td>0.648380</td>\n",
              "      <td>0.675295</td>\n",
              "      <td>0.560000</td>\n",
              "      <td>-0.010576</td>\n",
              "      <td>-0.000228</td>\n",
              "      <td>0.011102</td>\n",
              "      <td>-0.074188</td>\n",
              "      <td>0.012116</td>\n",
              "      <td>-0.000779</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>-478.92007</td>\n",
              "      <td>56.887730</td>\n",
              "      <td>-9.496516</td>\n",
              "      <td>12.799419</td>\n",
              "      <td>-0.196528</td>\n",
              "      <td>3.286758</td>\n",
              "      <td>-9.909594</td>\n",
              "      <td>-2.337262</td>\n",
              "      <td>-7.694031</td>\n",
              "      <td>...</td>\n",
              "      <td>0.664169</td>\n",
              "      <td>0.700484</td>\n",
              "      <td>0.594266</td>\n",
              "      <td>-0.029971</td>\n",
              "      <td>0.019514</td>\n",
              "      <td>-0.009344</td>\n",
              "      <td>-0.040153</td>\n",
              "      <td>0.013369</td>\n",
              "      <td>-0.006417</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>-449.64343</td>\n",
              "      <td>72.503365</td>\n",
              "      <td>11.100903</td>\n",
              "      <td>33.304817</td>\n",
              "      <td>3.467445</td>\n",
              "      <td>6.772911</td>\n",
              "      <td>-3.323741</td>\n",
              "      <td>-7.746681</td>\n",
              "      <td>-9.884865</td>\n",
              "      <td>...</td>\n",
              "      <td>0.661381</td>\n",
              "      <td>0.594747</td>\n",
              "      <td>0.571205</td>\n",
              "      <td>0.010062</td>\n",
              "      <td>0.019729</td>\n",
              "      <td>-0.021405</td>\n",
              "      <td>-0.003546</td>\n",
              "      <td>0.006231</td>\n",
              "      <td>0.004258</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>-448.45706</td>\n",
              "      <td>71.748140</td>\n",
              "      <td>15.644665</td>\n",
              "      <td>37.692158</td>\n",
              "      <td>1.685971</td>\n",
              "      <td>14.594450</td>\n",
              "      <td>-1.984497</td>\n",
              "      <td>-2.601064</td>\n",
              "      <td>-4.511068</td>\n",
              "      <td>...</td>\n",
              "      <td>0.738209</td>\n",
              "      <td>0.685561</td>\n",
              "      <td>0.608525</td>\n",
              "      <td>0.010726</td>\n",
              "      <td>0.004152</td>\n",
              "      <td>0.011977</td>\n",
              "      <td>-0.039160</td>\n",
              "      <td>0.010682</td>\n",
              "      <td>0.003822</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>-414.10510</td>\n",
              "      <td>86.937454</td>\n",
              "      <td>8.643685</td>\n",
              "      <td>41.722900</td>\n",
              "      <td>3.845868</td>\n",
              "      <td>16.058064</td>\n",
              "      <td>-6.323769</td>\n",
              "      <td>-8.956205</td>\n",
              "      <td>-6.782947</td>\n",
              "      <td>...</td>\n",
              "      <td>0.533943</td>\n",
              "      <td>0.539635</td>\n",
              "      <td>0.496446</td>\n",
              "      <td>0.031052</td>\n",
              "      <td>0.047855</td>\n",
              "      <td>-0.039647</td>\n",
              "      <td>0.006998</td>\n",
              "      <td>0.021142</td>\n",
              "      <td>-0.037041</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>102</td>\n",
              "      <td>-542.56660</td>\n",
              "      <td>2.070298</td>\n",
              "      <td>-18.764479</td>\n",
              "      <td>16.167446</td>\n",
              "      <td>-24.879025</td>\n",
              "      <td>1.178926</td>\n",
              "      <td>-15.186148</td>\n",
              "      <td>-2.770954</td>\n",
              "      <td>-14.010069</td>\n",
              "      <td>...</td>\n",
              "      <td>0.532020</td>\n",
              "      <td>0.520468</td>\n",
              "      <td>0.532640</td>\n",
              "      <td>-0.002613</td>\n",
              "      <td>0.006743</td>\n",
              "      <td>0.025558</td>\n",
              "      <td>-0.024244</td>\n",
              "      <td>-0.016319</td>\n",
              "      <td>0.003650</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>103</td>\n",
              "      <td>-406.23282</td>\n",
              "      <td>75.852394</td>\n",
              "      <td>-8.423434</td>\n",
              "      <td>34.064934</td>\n",
              "      <td>-11.914997</td>\n",
              "      <td>7.173997</td>\n",
              "      <td>-20.511670</td>\n",
              "      <td>-12.389133</td>\n",
              "      <td>-5.993309</td>\n",
              "      <td>...</td>\n",
              "      <td>0.502517</td>\n",
              "      <td>0.556970</td>\n",
              "      <td>0.543809</td>\n",
              "      <td>0.005737</td>\n",
              "      <td>-0.018652</td>\n",
              "      <td>0.023123</td>\n",
              "      <td>0.039628</td>\n",
              "      <td>0.024378</td>\n",
              "      <td>0.005283</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>104</td>\n",
              "      <td>-427.61200</td>\n",
              "      <td>36.440388</td>\n",
              "      <td>-21.528141</td>\n",
              "      <td>13.495537</td>\n",
              "      <td>-19.663698</td>\n",
              "      <td>4.418462</td>\n",
              "      <td>-20.588242</td>\n",
              "      <td>-13.769891</td>\n",
              "      <td>-17.446966</td>\n",
              "      <td>...</td>\n",
              "      <td>0.377521</td>\n",
              "      <td>0.407803</td>\n",
              "      <td>0.410098</td>\n",
              "      <td>0.005356</td>\n",
              "      <td>-0.030501</td>\n",
              "      <td>-0.028373</td>\n",
              "      <td>0.043300</td>\n",
              "      <td>0.014572</td>\n",
              "      <td>-0.005967</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>105</td>\n",
              "      <td>-397.74173</td>\n",
              "      <td>65.599550</td>\n",
              "      <td>-1.686943</td>\n",
              "      <td>38.130620</td>\n",
              "      <td>-12.816805</td>\n",
              "      <td>14.129421</td>\n",
              "      <td>-20.335257</td>\n",
              "      <td>-13.580517</td>\n",
              "      <td>-3.846510</td>\n",
              "      <td>...</td>\n",
              "      <td>0.574512</td>\n",
              "      <td>0.554483</td>\n",
              "      <td>0.523765</td>\n",
              "      <td>0.003604</td>\n",
              "      <td>-0.009971</td>\n",
              "      <td>-0.011075</td>\n",
              "      <td>-0.030320</td>\n",
              "      <td>-0.005274</td>\n",
              "      <td>-0.003526</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>106</td>\n",
              "      <td>-467.15588</td>\n",
              "      <td>52.217026</td>\n",
              "      <td>10.470471</td>\n",
              "      <td>47.414780</td>\n",
              "      <td>8.690019</td>\n",
              "      <td>15.601270</td>\n",
              "      <td>-2.032935</td>\n",
              "      <td>4.985774</td>\n",
              "      <td>-7.432734</td>\n",
              "      <td>...</td>\n",
              "      <td>0.523647</td>\n",
              "      <td>0.509723</td>\n",
              "      <td>0.498566</td>\n",
              "      <td>0.051532</td>\n",
              "      <td>0.015525</td>\n",
              "      <td>-0.006052</td>\n",
              "      <td>0.018201</td>\n",
              "      <td>0.004361</td>\n",
              "      <td>-0.021649</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>107 rows × 261 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a757ffb2-86ce-45ee-9c1c-bd2c22765e9f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a757ffb2-86ce-45ee-9c1c-bd2c22765e9f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a757ffb2-86ce-45ee-9c1c-bd2c22765e9f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-94988ca7-8711-4fd4-b376-a70f9ef45364\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-94988ca7-8711-4fd4-b376-a70f9ef45364')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-94988ca7-8711-4fd4-b376-a70f9ef45364 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df2"
            }
          },
          "metadata": {},
          "execution_count": 577
        }
      ],
      "source": [
        "df2=pd.read_csv('/content/drive/MyDrive/DATASETS/EmoDB Dataset/test_fold1.csv')\n",
        "df2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 578,
      "id": "a3d750f7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3d750f7",
        "outputId": "6ac809a9-6442-493a-8593-3d11027eeeb1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-482.45233, -469.48477, -454.89886, -447.1263 , -451.45264,\n",
              "       -433.33972, -465.2206 , -407.61963, -445.90384, -432.8532 ,\n",
              "       -438.46402, -451.66434, -415.74384, -444.03302, -447.862  ,\n",
              "       -447.8849 , -414.28708, -405.8289 , -415.96158, -425.45212,\n",
              "       -434.169  , -491.33237, -433.93875, -381.5805 , -437.03818,\n",
              "       -440.71924, -440.73105, -525.19977, -451.39062, -447.41296,\n",
              "       -448.62344, -474.65   , -456.05096, -474.31326, -390.37305,\n",
              "       -423.79208, -446.3631 , -457.93448, -436.3282 , -433.23328,\n",
              "       -439.48215, -466.99695, -494.3395 , -426.0529 , -430.6762 ,\n",
              "       -482.82642, -446.7974 , -453.8969 , -521.504  , -376.84555,\n",
              "       -436.69876, -493.1862 , -442.59415, -446.97107, -456.72043,\n",
              "       -416.0819 , -446.98584, -418.3227 , -423.0657 , -461.82983,\n",
              "       -434.9256 , -425.79813, -435.4896 , -399.51852, -402.0103 ,\n",
              "       -464.13718, -461.44766, -474.8092 , -464.07745, -503.61353,\n",
              "       -453.04343, -482.67584, -409.22214, -432.09225, -500.27402,\n",
              "       -531.9213 , -455.4235 , -465.1539 , -424.5544 , -456.9332 ,\n",
              "       -469.68045, -485.50922, -444.93484, -427.06485, -418.001  ,\n",
              "       -456.90128, -492.80527, -477.71838, -468.5587 , -456.18542,\n",
              "       -439.49243, -437.33456, -514.9054 , -418.71957, -414.93512,\n",
              "       -503.28616, -460.4001 , -453.48303, -459.55142, -492.041  ,\n",
              "       -449.0555 , -407.6214 , -386.1615 , -463.09274, -447.04764,\n",
              "       -439.2523 , -446.3131 , -405.84958, -378.2114 , -390.5131 ,\n",
              "       -470.87045, -470.00208, -403.73657, -405.75662, -377.2399 ,\n",
              "       -473.9847 , -433.5633 , -433.1373 , -390.45312, -434.17294,\n",
              "       -446.96768, -448.68094, -423.73795, -447.18866, -448.96103,\n",
              "       -429.79407, -420.2247 , -446.1366 , -401.80896, -428.3561 ,\n",
              "       -405.93726, -420.10004, -389.66595, -514.8218 , -345.723  ,\n",
              "       -402.585  , -434.36496, -364.07712, -412.15396, -409.9087 ,\n",
              "       -413.8373 , -359.38922, -370.994  , -373.46188, -427.5882 ,\n",
              "       -437.44412, -365.9771 , -400.4402 , -412.62817, -521.55493,\n",
              "       -414.99844, -421.95407, -440.67435, -497.26077, -420.12646,\n",
              "       -466.10834, -416.39185, -467.4495 , -457.78012, -454.6912 ,\n",
              "       -488.26974, -461.97726, -460.52005, -443.02942, -464.94745,\n",
              "       -460.19077, -451.02377, -547.34924, -470.54938, -443.90628,\n",
              "       -481.4349 , -408.07852, -473.36694, -467.0893 , -407.5873 ,\n",
              "       -422.1737 , -409.21838, -470.8944 , -479.00146, -413.97577,\n",
              "       -453.5756 , -462.8844 , -471.02194, -469.223  , -479.2676 ,\n",
              "       -481.2874 , -443.0332 , -513.6494 , -441.25516, -434.86633,\n",
              "       -435.5582 , -464.69373, -470.0053 , -482.287  , -416.1406 ,\n",
              "       -434.42883, -474.72525, -376.26874, -501.81232, -444.86087,\n",
              "       -418.1163 , -405.00757, -435.22946, -443.18646, -470.02222,\n",
              "       -439.98254, -417.20303, -377.4015 , -385.19785, -441.78366,\n",
              "       -454.7903 , -402.7788 , -467.03882, -457.7515 , -422.8841 ,\n",
              "       -428.71326, -438.01385, -446.06177, -382.74545, -484.20596,\n",
              "       -466.87482, -423.7153 , -423.8322 , -443.76602, -422.04797,\n",
              "       -392.5137 , -375.1225 , -409.2057 , -459.8976 , -431.6872 ,\n",
              "       -407.01892, -454.1528 , -405.38095, -419.83594, -407.77988,\n",
              "       -455.91553, -395.2997 , -453.7782 , -393.9526 , -423.10638,\n",
              "       -439.494  , -386.62506, -428.13434, -496.95926, -473.18396,\n",
              "       -464.56476, -391.08258, -365.09543, -433.9074 , -405.67502,\n",
              "       -416.07724, -461.75302, -438.8606 , -404.93027, -403.1864 ,\n",
              "       -392.26648, -452.835  , -448.45685, -413.7153 , -394.94235,\n",
              "       -421.18414, -447.04645, -389.36047, -387.3086 , -420.1675 ,\n",
              "       -421.31525, -425.45074, -438.37827, -409.21655, -412.8278 ,\n",
              "       -414.18164, -400.93872, -427.86765, -468.193  , -444.60718,\n",
              "       -418.8131 , -439.90536, -445.24417, -421.23648, -484.93997,\n",
              "       -446.16428, -367.194  , -481.92627, -474.5434 , -442.24258,\n",
              "       -522.2874 , -423.3954 , -502.14194, -417.8694 , -461.70255,\n",
              "       -470.61038, -487.77856, -448.38986, -443.2527 , -487.9756 ,\n",
              "       -441.62894, -459.56256, -426.17914, -504.21188, -464.8163 ,\n",
              "       -431.91074, -454.7633 , -466.36984, -471.5478 , -420.90936,\n",
              "       -436.0145 , -489.41888, -493.87128, -421.56473, -429.95325,\n",
              "       -449.66565, -484.456  , -428.66187, -427.8873 , -412.55634,\n",
              "       -466.64697, -463.29285, -379.56708, -483.3338 , -478.16122,\n",
              "       -441.50995, -454.05173, -431.52588, -385.76328, -449.0907 ,\n",
              "       -412.06152, -462.45517, -469.98242, -459.4864 , -378.77286,\n",
              "       -432.5484 , -462.3047 , -407.74323, -386.1994 , -472.4163 ,\n",
              "       -469.46295, -477.94263, -363.5735 , -414.5706 , -435.86343,\n",
              "       -442.37482, -415.02478, -449.23508, -485.03238, -471.95856,\n",
              "       -440.10852, -404.7512 , -439.35873, -403.8571 , -372.10165,\n",
              "       -429.20193, -393.0507 , -403.01038, -394.76035, -451.00165,\n",
              "       -412.0556 , -408.7152 , -426.08667, -411.78372, -414.32397,\n",
              "       -467.7443 , -398.8699 , -395.0607 , -468.89825, -463.91916,\n",
              "       -397.55426, -404.50937, -408.56897, -425.47263, -423.54108,\n",
              "       -457.2802 , -412.13974, -471.60022, -467.06317, -464.36145,\n",
              "       -416.08627, -432.17923, -392.51147, -542.9345 , -404.80206,\n",
              "       -417.062  , -465.24496, -432.88263, -404.11523, -393.34085,\n",
              "       -436.95248, -476.9987 , -498.8898 , -457.2986 , -455.44485,\n",
              "       -441.25778, -477.11566, -411.96274, -524.4419 , -360.47025,\n",
              "       -422.18552, -458.9268 , -396.28677, -423.83383, -527.49243,\n",
              "       -408.97797, -390.08295, -465.86484, -427.65176, -462.9359 ,\n",
              "       -450.64505, -386.80893, -435.4015 , -479.6645 , -441.11627,\n",
              "       -485.59613, -464.9679 , -392.4652 , -447.6558 , -491.1511 ,\n",
              "       -442.5056 , -475.25198, -506.06097, -392.73694, -431.76166,\n",
              "       -505.94534, -403.50656, -429.41583, -478.05527, -418.6249 ,\n",
              "       -427.36716, -526.1957 , -437.9722 ])"
            ]
          },
          "metadata": {},
          "execution_count": 578
        }
      ],
      "source": [
        "df1['0'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 579,
      "id": "72e890ce",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72e890ce",
        "outputId": "f584bc88-b4a2-4834-eef3-d1bba9ed7926"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-434.88647, -478.92007, -449.64343, -448.45706, -414.1051 ,\n",
              "       -403.34033, -452.2124 , -456.17935, -454.38022, -508.38065,\n",
              "       -466.81842, -448.18274, -410.33658, -453.46445, -454.48465,\n",
              "       -468.04486, -478.63577, -483.07538, -512.6878 , -488.90784,\n",
              "       -503.9724 , -447.12366, -504.06378, -488.23538, -432.9396 ,\n",
              "       -458.41788, -470.88403, -413.56833, -445.18192, -434.1118 ,\n",
              "       -410.16275, -406.1605 , -403.9027 , -472.72705, -391.26596,\n",
              "       -449.62973, -464.32104, -418.5449 , -463.6061 , -513.68   ,\n",
              "       -452.5104 , -426.89627, -421.20755, -473.6945 , -411.14822,\n",
              "       -513.1609 , -517.8032 , -410.65417, -458.29306, -462.08606,\n",
              "       -413.52936, -443.34912, -475.37103, -420.7548 , -452.5595 ,\n",
              "       -464.00873, -403.3263 , -421.93167, -471.28308, -399.32123,\n",
              "       -413.09387, -481.6817 , -380.43036, -410.75797, -437.94302,\n",
              "       -441.02634, -412.16312, -453.3949 , -406.41467, -459.23962,\n",
              "       -460.4038 , -465.9359 , -491.2516 , -446.5495 , -443.65494,\n",
              "       -440.50952, -424.6715 , -449.63315, -440.85495, -442.1517 ,\n",
              "       -405.81763, -434.34827, -419.2449 , -379.51093, -446.7613 ,\n",
              "       -421.0112 , -460.42752, -412.05164, -372.68307, -332.69867,\n",
              "       -428.96658, -476.0034 , -452.18256, -456.82553, -393.92816,\n",
              "       -437.02637, -420.7758 , -530.95605, -411.51193, -492.2898 ,\n",
              "       -457.94778, -358.59656, -542.5666 , -406.23282, -427.612  ,\n",
              "       -397.74173, -467.15588])"
            ]
          },
          "metadata": {},
          "execution_count": 579
        }
      ],
      "source": [
        "df2['0'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 580,
      "id": "caeabe41",
      "metadata": {
        "id": "caeabe41"
      },
      "outputs": [],
      "source": [
        "x_train=df1.iloc[:,0:(df1.shape[1]-1)]\n",
        "y_train=df1.iloc[:,-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 581,
      "id": "08d5857c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "08d5857c",
        "outputId": "b4b21da4-50ef-42d0-d9ef-5606b2793df1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Unnamed: 0          0          1          2          3          4  \\\n",
              "0             0 -482.45233  62.835957  -0.348998  26.264595   2.978607   \n",
              "1             1 -469.48477  88.400730  -7.127512  29.156132   5.335554   \n",
              "2             2 -454.89886  45.067265  -0.193278  15.111545   3.080835   \n",
              "3             3 -447.12630  86.114920   4.772520  38.097256   8.324276   \n",
              "4             4 -451.45264  71.335200  12.223010  32.649555   3.997801   \n",
              "..          ...        ...        ...        ...        ...        ...   \n",
              "423         423 -478.05527   5.705422 -24.631056  27.622614 -19.235449   \n",
              "424         424 -418.62490  57.015880   6.383415  47.618423  -8.051490   \n",
              "425         425 -427.36716  51.473750   4.835125  40.900140   6.937289   \n",
              "426         426 -526.19570  11.317784 -18.942173  29.540787 -28.057306   \n",
              "427         427 -437.97220   5.289146 -22.667547  25.394840 -28.545520   \n",
              "\n",
              "             5          6         7          8  ...       249       250  \\\n",
              "0     6.900927 -13.006243  0.273391  -9.196591  ...  0.635609  0.675823   \n",
              "1     7.147227  -6.727572 -8.307674  -3.364513  ...  0.646426  0.635522   \n",
              "2     4.204241 -10.440731 -6.615343 -16.249382  ...  0.506934  0.575784   \n",
              "3     8.538317  -4.507682 -7.680664  -7.317249  ...  0.698287  0.615263   \n",
              "4    15.200773  -2.812883 -1.384373  -6.467040  ...  0.696758  0.719856   \n",
              "..         ...        ...       ...        ...  ...       ...       ...   \n",
              "423  -7.040019 -13.293165 -9.629133 -14.067036  ...  0.597085  0.590422   \n",
              "424   4.213936 -15.029120 -2.448467 -10.805821  ...  0.566316  0.569263   \n",
              "425  13.700687  -8.331753 -0.583414  -6.279562  ...  0.671834  0.638155   \n",
              "426   1.299599 -16.251814 -7.512440 -23.191568  ...  0.497285  0.528861   \n",
              "427   0.428451 -11.650926 -8.022680 -18.337156  ...  0.510255  0.495079   \n",
              "\n",
              "          251       252       253       254       255       256       257  \\\n",
              "0    0.684034  0.627376 -0.001574  0.012645 -0.027069  0.019313 -0.002252   \n",
              "1    0.544438  0.532856 -0.018488  0.011973 -0.011038  0.079758 -0.021044   \n",
              "2    0.523305  0.423375  0.009395 -0.025547 -0.035554 -0.025885  0.011198   \n",
              "3    0.566964  0.605103 -0.008389 -0.051995 -0.056544 -0.020014  0.013964   \n",
              "4    0.667424  0.570905  0.003044 -0.006101 -0.009038 -0.049699  0.027615   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "423  0.481957  0.481437 -0.011216 -0.031485 -0.029936  0.042160 -0.013815   \n",
              "424  0.551809  0.576764  0.016046 -0.025610  0.025426 -0.094371  0.008999   \n",
              "425  0.574542  0.503516  0.019632  0.046315  0.074801  0.018078  0.022948   \n",
              "426  0.501070  0.496900  0.007856  0.005917 -0.045393 -0.004246 -0.001628   \n",
              "427  0.539387  0.527394 -0.001086  0.013948  0.013274 -0.056855 -0.001004   \n",
              "\n",
              "          258  \n",
              "0   -0.006220  \n",
              "1   -0.019445  \n",
              "2   -0.000163  \n",
              "3    0.008349  \n",
              "4    0.021319  \n",
              "..        ...  \n",
              "423  0.009839  \n",
              "424 -0.004985  \n",
              "425 -0.016365  \n",
              "426  0.015051  \n",
              "427 -0.001355  \n",
              "\n",
              "[428 rows x 260 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b775a1d7-d354-4935-bdbb-94dd2f41a69b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>...</th>\n",
              "      <th>249</th>\n",
              "      <th>250</th>\n",
              "      <th>251</th>\n",
              "      <th>252</th>\n",
              "      <th>253</th>\n",
              "      <th>254</th>\n",
              "      <th>255</th>\n",
              "      <th>256</th>\n",
              "      <th>257</th>\n",
              "      <th>258</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>-482.45233</td>\n",
              "      <td>62.835957</td>\n",
              "      <td>-0.348998</td>\n",
              "      <td>26.264595</td>\n",
              "      <td>2.978607</td>\n",
              "      <td>6.900927</td>\n",
              "      <td>-13.006243</td>\n",
              "      <td>0.273391</td>\n",
              "      <td>-9.196591</td>\n",
              "      <td>...</td>\n",
              "      <td>0.635609</td>\n",
              "      <td>0.675823</td>\n",
              "      <td>0.684034</td>\n",
              "      <td>0.627376</td>\n",
              "      <td>-0.001574</td>\n",
              "      <td>0.012645</td>\n",
              "      <td>-0.027069</td>\n",
              "      <td>0.019313</td>\n",
              "      <td>-0.002252</td>\n",
              "      <td>-0.006220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>-469.48477</td>\n",
              "      <td>88.400730</td>\n",
              "      <td>-7.127512</td>\n",
              "      <td>29.156132</td>\n",
              "      <td>5.335554</td>\n",
              "      <td>7.147227</td>\n",
              "      <td>-6.727572</td>\n",
              "      <td>-8.307674</td>\n",
              "      <td>-3.364513</td>\n",
              "      <td>...</td>\n",
              "      <td>0.646426</td>\n",
              "      <td>0.635522</td>\n",
              "      <td>0.544438</td>\n",
              "      <td>0.532856</td>\n",
              "      <td>-0.018488</td>\n",
              "      <td>0.011973</td>\n",
              "      <td>-0.011038</td>\n",
              "      <td>0.079758</td>\n",
              "      <td>-0.021044</td>\n",
              "      <td>-0.019445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>-454.89886</td>\n",
              "      <td>45.067265</td>\n",
              "      <td>-0.193278</td>\n",
              "      <td>15.111545</td>\n",
              "      <td>3.080835</td>\n",
              "      <td>4.204241</td>\n",
              "      <td>-10.440731</td>\n",
              "      <td>-6.615343</td>\n",
              "      <td>-16.249382</td>\n",
              "      <td>...</td>\n",
              "      <td>0.506934</td>\n",
              "      <td>0.575784</td>\n",
              "      <td>0.523305</td>\n",
              "      <td>0.423375</td>\n",
              "      <td>0.009395</td>\n",
              "      <td>-0.025547</td>\n",
              "      <td>-0.035554</td>\n",
              "      <td>-0.025885</td>\n",
              "      <td>0.011198</td>\n",
              "      <td>-0.000163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>-447.12630</td>\n",
              "      <td>86.114920</td>\n",
              "      <td>4.772520</td>\n",
              "      <td>38.097256</td>\n",
              "      <td>8.324276</td>\n",
              "      <td>8.538317</td>\n",
              "      <td>-4.507682</td>\n",
              "      <td>-7.680664</td>\n",
              "      <td>-7.317249</td>\n",
              "      <td>...</td>\n",
              "      <td>0.698287</td>\n",
              "      <td>0.615263</td>\n",
              "      <td>0.566964</td>\n",
              "      <td>0.605103</td>\n",
              "      <td>-0.008389</td>\n",
              "      <td>-0.051995</td>\n",
              "      <td>-0.056544</td>\n",
              "      <td>-0.020014</td>\n",
              "      <td>0.013964</td>\n",
              "      <td>0.008349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>-451.45264</td>\n",
              "      <td>71.335200</td>\n",
              "      <td>12.223010</td>\n",
              "      <td>32.649555</td>\n",
              "      <td>3.997801</td>\n",
              "      <td>15.200773</td>\n",
              "      <td>-2.812883</td>\n",
              "      <td>-1.384373</td>\n",
              "      <td>-6.467040</td>\n",
              "      <td>...</td>\n",
              "      <td>0.696758</td>\n",
              "      <td>0.719856</td>\n",
              "      <td>0.667424</td>\n",
              "      <td>0.570905</td>\n",
              "      <td>0.003044</td>\n",
              "      <td>-0.006101</td>\n",
              "      <td>-0.009038</td>\n",
              "      <td>-0.049699</td>\n",
              "      <td>0.027615</td>\n",
              "      <td>0.021319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>423</th>\n",
              "      <td>423</td>\n",
              "      <td>-478.05527</td>\n",
              "      <td>5.705422</td>\n",
              "      <td>-24.631056</td>\n",
              "      <td>27.622614</td>\n",
              "      <td>-19.235449</td>\n",
              "      <td>-7.040019</td>\n",
              "      <td>-13.293165</td>\n",
              "      <td>-9.629133</td>\n",
              "      <td>-14.067036</td>\n",
              "      <td>...</td>\n",
              "      <td>0.597085</td>\n",
              "      <td>0.590422</td>\n",
              "      <td>0.481957</td>\n",
              "      <td>0.481437</td>\n",
              "      <td>-0.011216</td>\n",
              "      <td>-0.031485</td>\n",
              "      <td>-0.029936</td>\n",
              "      <td>0.042160</td>\n",
              "      <td>-0.013815</td>\n",
              "      <td>0.009839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>424</th>\n",
              "      <td>424</td>\n",
              "      <td>-418.62490</td>\n",
              "      <td>57.015880</td>\n",
              "      <td>6.383415</td>\n",
              "      <td>47.618423</td>\n",
              "      <td>-8.051490</td>\n",
              "      <td>4.213936</td>\n",
              "      <td>-15.029120</td>\n",
              "      <td>-2.448467</td>\n",
              "      <td>-10.805821</td>\n",
              "      <td>...</td>\n",
              "      <td>0.566316</td>\n",
              "      <td>0.569263</td>\n",
              "      <td>0.551809</td>\n",
              "      <td>0.576764</td>\n",
              "      <td>0.016046</td>\n",
              "      <td>-0.025610</td>\n",
              "      <td>0.025426</td>\n",
              "      <td>-0.094371</td>\n",
              "      <td>0.008999</td>\n",
              "      <td>-0.004985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>425</th>\n",
              "      <td>425</td>\n",
              "      <td>-427.36716</td>\n",
              "      <td>51.473750</td>\n",
              "      <td>4.835125</td>\n",
              "      <td>40.900140</td>\n",
              "      <td>6.937289</td>\n",
              "      <td>13.700687</td>\n",
              "      <td>-8.331753</td>\n",
              "      <td>-0.583414</td>\n",
              "      <td>-6.279562</td>\n",
              "      <td>...</td>\n",
              "      <td>0.671834</td>\n",
              "      <td>0.638155</td>\n",
              "      <td>0.574542</td>\n",
              "      <td>0.503516</td>\n",
              "      <td>0.019632</td>\n",
              "      <td>0.046315</td>\n",
              "      <td>0.074801</td>\n",
              "      <td>0.018078</td>\n",
              "      <td>0.022948</td>\n",
              "      <td>-0.016365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>426</th>\n",
              "      <td>426</td>\n",
              "      <td>-526.19570</td>\n",
              "      <td>11.317784</td>\n",
              "      <td>-18.942173</td>\n",
              "      <td>29.540787</td>\n",
              "      <td>-28.057306</td>\n",
              "      <td>1.299599</td>\n",
              "      <td>-16.251814</td>\n",
              "      <td>-7.512440</td>\n",
              "      <td>-23.191568</td>\n",
              "      <td>...</td>\n",
              "      <td>0.497285</td>\n",
              "      <td>0.528861</td>\n",
              "      <td>0.501070</td>\n",
              "      <td>0.496900</td>\n",
              "      <td>0.007856</td>\n",
              "      <td>0.005917</td>\n",
              "      <td>-0.045393</td>\n",
              "      <td>-0.004246</td>\n",
              "      <td>-0.001628</td>\n",
              "      <td>0.015051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>427</th>\n",
              "      <td>427</td>\n",
              "      <td>-437.97220</td>\n",
              "      <td>5.289146</td>\n",
              "      <td>-22.667547</td>\n",
              "      <td>25.394840</td>\n",
              "      <td>-28.545520</td>\n",
              "      <td>0.428451</td>\n",
              "      <td>-11.650926</td>\n",
              "      <td>-8.022680</td>\n",
              "      <td>-18.337156</td>\n",
              "      <td>...</td>\n",
              "      <td>0.510255</td>\n",
              "      <td>0.495079</td>\n",
              "      <td>0.539387</td>\n",
              "      <td>0.527394</td>\n",
              "      <td>-0.001086</td>\n",
              "      <td>0.013948</td>\n",
              "      <td>0.013274</td>\n",
              "      <td>-0.056855</td>\n",
              "      <td>-0.001004</td>\n",
              "      <td>-0.001355</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>428 rows × 260 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b775a1d7-d354-4935-bdbb-94dd2f41a69b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b775a1d7-d354-4935-bdbb-94dd2f41a69b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b775a1d7-d354-4935-bdbb-94dd2f41a69b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9914ab7c-877b-41a5-b31e-3bba3c548dd1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9914ab7c-877b-41a5-b31e-3bba3c548dd1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9914ab7c-877b-41a5-b31e-3bba3c548dd1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "x_train"
            }
          },
          "metadata": {},
          "execution_count": 581
        }
      ],
      "source": [
        "x_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 582,
      "id": "d2127f10",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2127f10",
        "outputId": "e9f6a4ac-4308-496f-d094-4c389d85b7be"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      0\n",
              "1      1\n",
              "2      0\n",
              "3      1\n",
              "4      3\n",
              "      ..\n",
              "423    0\n",
              "424    5\n",
              "425    3\n",
              "426    2\n",
              "427    2\n",
              "Name: 0.1, Length: 428, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 582
        }
      ],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 583,
      "id": "7311d746",
      "metadata": {
        "id": "7311d746"
      },
      "outputs": [],
      "source": [
        "x_test=df2.iloc[:,0:(df2.shape[1]-1)]\n",
        "y_test=df2.iloc[:,-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 584,
      "id": "ae86f98c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "ae86f98c",
        "outputId": "ff6ce315-d159-4acf-967a-517e2e2ad3e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Unnamed: 0          0          1          2          3          4  \\\n",
              "0             0 -434.88647  41.972150 -29.416862  18.537344  -4.156565   \n",
              "1             1 -478.92007  56.887730  -9.496516  12.799419  -0.196528   \n",
              "2             2 -449.64343  72.503365  11.100903  33.304817   3.467445   \n",
              "3             3 -448.45706  71.748140  15.644665  37.692158   1.685971   \n",
              "4             4 -414.10510  86.937454   8.643685  41.722900   3.845868   \n",
              "..          ...        ...        ...        ...        ...        ...   \n",
              "102         102 -542.56660   2.070298 -18.764479  16.167446 -24.879025   \n",
              "103         103 -406.23282  75.852394  -8.423434  34.064934 -11.914997   \n",
              "104         104 -427.61200  36.440388 -21.528141  13.495537 -19.663698   \n",
              "105         105 -397.74173  65.599550  -1.686943  38.130620 -12.816805   \n",
              "106         106 -467.15588  52.217026  10.470471  47.414780   8.690019   \n",
              "\n",
              "             5          6          7          8  ...       249       250  \\\n",
              "0     5.257353 -11.410935  -8.983023 -11.285996  ...  0.600825  0.648380   \n",
              "1     3.286758  -9.909594  -2.337262  -7.694031  ...  0.649602  0.664169   \n",
              "2     6.772911  -3.323741  -7.746681  -9.884865  ...  0.648118  0.661381   \n",
              "3    14.594450  -1.984497  -2.601064  -4.511068  ...  0.744050  0.738209   \n",
              "4    16.058064  -6.323769  -8.956205  -6.782947  ...  0.536966  0.533943   \n",
              "..         ...        ...        ...        ...  ...       ...       ...   \n",
              "102   1.178926 -15.186148  -2.770954 -14.010069  ...  0.600697  0.532020   \n",
              "103   7.173997 -20.511670 -12.389133  -5.993309  ...  0.480231  0.502517   \n",
              "104   4.418462 -20.588242 -13.769891 -17.446966  ...  0.396666  0.377521   \n",
              "105  14.129421 -20.335257 -13.580517  -3.846510  ...  0.568361  0.574512   \n",
              "106  15.601270  -2.032935   4.985774  -7.432734  ...  0.531997  0.523647   \n",
              "\n",
              "          251       252       253       254       255       256       257  \\\n",
              "0    0.675295  0.560000 -0.010576 -0.000228  0.011102 -0.074188  0.012116   \n",
              "1    0.700484  0.594266 -0.029971  0.019514 -0.009344 -0.040153  0.013369   \n",
              "2    0.594747  0.571205  0.010062  0.019729 -0.021405 -0.003546  0.006231   \n",
              "3    0.685561  0.608525  0.010726  0.004152  0.011977 -0.039160  0.010682   \n",
              "4    0.539635  0.496446  0.031052  0.047855 -0.039647  0.006998  0.021142   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "102  0.520468  0.532640 -0.002613  0.006743  0.025558 -0.024244 -0.016319   \n",
              "103  0.556970  0.543809  0.005737 -0.018652  0.023123  0.039628  0.024378   \n",
              "104  0.407803  0.410098  0.005356 -0.030501 -0.028373  0.043300  0.014572   \n",
              "105  0.554483  0.523765  0.003604 -0.009971 -0.011075 -0.030320 -0.005274   \n",
              "106  0.509723  0.498566  0.051532  0.015525 -0.006052  0.018201  0.004361   \n",
              "\n",
              "          258  \n",
              "0   -0.000779  \n",
              "1   -0.006417  \n",
              "2    0.004258  \n",
              "3    0.003822  \n",
              "4   -0.037041  \n",
              "..        ...  \n",
              "102  0.003650  \n",
              "103  0.005283  \n",
              "104 -0.005967  \n",
              "105 -0.003526  \n",
              "106 -0.021649  \n",
              "\n",
              "[107 rows x 260 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1b39563a-dc30-46bf-ba14-0a574fa8387b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>...</th>\n",
              "      <th>249</th>\n",
              "      <th>250</th>\n",
              "      <th>251</th>\n",
              "      <th>252</th>\n",
              "      <th>253</th>\n",
              "      <th>254</th>\n",
              "      <th>255</th>\n",
              "      <th>256</th>\n",
              "      <th>257</th>\n",
              "      <th>258</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>-434.88647</td>\n",
              "      <td>41.972150</td>\n",
              "      <td>-29.416862</td>\n",
              "      <td>18.537344</td>\n",
              "      <td>-4.156565</td>\n",
              "      <td>5.257353</td>\n",
              "      <td>-11.410935</td>\n",
              "      <td>-8.983023</td>\n",
              "      <td>-11.285996</td>\n",
              "      <td>...</td>\n",
              "      <td>0.600825</td>\n",
              "      <td>0.648380</td>\n",
              "      <td>0.675295</td>\n",
              "      <td>0.560000</td>\n",
              "      <td>-0.010576</td>\n",
              "      <td>-0.000228</td>\n",
              "      <td>0.011102</td>\n",
              "      <td>-0.074188</td>\n",
              "      <td>0.012116</td>\n",
              "      <td>-0.000779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>-478.92007</td>\n",
              "      <td>56.887730</td>\n",
              "      <td>-9.496516</td>\n",
              "      <td>12.799419</td>\n",
              "      <td>-0.196528</td>\n",
              "      <td>3.286758</td>\n",
              "      <td>-9.909594</td>\n",
              "      <td>-2.337262</td>\n",
              "      <td>-7.694031</td>\n",
              "      <td>...</td>\n",
              "      <td>0.649602</td>\n",
              "      <td>0.664169</td>\n",
              "      <td>0.700484</td>\n",
              "      <td>0.594266</td>\n",
              "      <td>-0.029971</td>\n",
              "      <td>0.019514</td>\n",
              "      <td>-0.009344</td>\n",
              "      <td>-0.040153</td>\n",
              "      <td>0.013369</td>\n",
              "      <td>-0.006417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>-449.64343</td>\n",
              "      <td>72.503365</td>\n",
              "      <td>11.100903</td>\n",
              "      <td>33.304817</td>\n",
              "      <td>3.467445</td>\n",
              "      <td>6.772911</td>\n",
              "      <td>-3.323741</td>\n",
              "      <td>-7.746681</td>\n",
              "      <td>-9.884865</td>\n",
              "      <td>...</td>\n",
              "      <td>0.648118</td>\n",
              "      <td>0.661381</td>\n",
              "      <td>0.594747</td>\n",
              "      <td>0.571205</td>\n",
              "      <td>0.010062</td>\n",
              "      <td>0.019729</td>\n",
              "      <td>-0.021405</td>\n",
              "      <td>-0.003546</td>\n",
              "      <td>0.006231</td>\n",
              "      <td>0.004258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>-448.45706</td>\n",
              "      <td>71.748140</td>\n",
              "      <td>15.644665</td>\n",
              "      <td>37.692158</td>\n",
              "      <td>1.685971</td>\n",
              "      <td>14.594450</td>\n",
              "      <td>-1.984497</td>\n",
              "      <td>-2.601064</td>\n",
              "      <td>-4.511068</td>\n",
              "      <td>...</td>\n",
              "      <td>0.744050</td>\n",
              "      <td>0.738209</td>\n",
              "      <td>0.685561</td>\n",
              "      <td>0.608525</td>\n",
              "      <td>0.010726</td>\n",
              "      <td>0.004152</td>\n",
              "      <td>0.011977</td>\n",
              "      <td>-0.039160</td>\n",
              "      <td>0.010682</td>\n",
              "      <td>0.003822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>-414.10510</td>\n",
              "      <td>86.937454</td>\n",
              "      <td>8.643685</td>\n",
              "      <td>41.722900</td>\n",
              "      <td>3.845868</td>\n",
              "      <td>16.058064</td>\n",
              "      <td>-6.323769</td>\n",
              "      <td>-8.956205</td>\n",
              "      <td>-6.782947</td>\n",
              "      <td>...</td>\n",
              "      <td>0.536966</td>\n",
              "      <td>0.533943</td>\n",
              "      <td>0.539635</td>\n",
              "      <td>0.496446</td>\n",
              "      <td>0.031052</td>\n",
              "      <td>0.047855</td>\n",
              "      <td>-0.039647</td>\n",
              "      <td>0.006998</td>\n",
              "      <td>0.021142</td>\n",
              "      <td>-0.037041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>102</td>\n",
              "      <td>-542.56660</td>\n",
              "      <td>2.070298</td>\n",
              "      <td>-18.764479</td>\n",
              "      <td>16.167446</td>\n",
              "      <td>-24.879025</td>\n",
              "      <td>1.178926</td>\n",
              "      <td>-15.186148</td>\n",
              "      <td>-2.770954</td>\n",
              "      <td>-14.010069</td>\n",
              "      <td>...</td>\n",
              "      <td>0.600697</td>\n",
              "      <td>0.532020</td>\n",
              "      <td>0.520468</td>\n",
              "      <td>0.532640</td>\n",
              "      <td>-0.002613</td>\n",
              "      <td>0.006743</td>\n",
              "      <td>0.025558</td>\n",
              "      <td>-0.024244</td>\n",
              "      <td>-0.016319</td>\n",
              "      <td>0.003650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>103</td>\n",
              "      <td>-406.23282</td>\n",
              "      <td>75.852394</td>\n",
              "      <td>-8.423434</td>\n",
              "      <td>34.064934</td>\n",
              "      <td>-11.914997</td>\n",
              "      <td>7.173997</td>\n",
              "      <td>-20.511670</td>\n",
              "      <td>-12.389133</td>\n",
              "      <td>-5.993309</td>\n",
              "      <td>...</td>\n",
              "      <td>0.480231</td>\n",
              "      <td>0.502517</td>\n",
              "      <td>0.556970</td>\n",
              "      <td>0.543809</td>\n",
              "      <td>0.005737</td>\n",
              "      <td>-0.018652</td>\n",
              "      <td>0.023123</td>\n",
              "      <td>0.039628</td>\n",
              "      <td>0.024378</td>\n",
              "      <td>0.005283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>104</td>\n",
              "      <td>-427.61200</td>\n",
              "      <td>36.440388</td>\n",
              "      <td>-21.528141</td>\n",
              "      <td>13.495537</td>\n",
              "      <td>-19.663698</td>\n",
              "      <td>4.418462</td>\n",
              "      <td>-20.588242</td>\n",
              "      <td>-13.769891</td>\n",
              "      <td>-17.446966</td>\n",
              "      <td>...</td>\n",
              "      <td>0.396666</td>\n",
              "      <td>0.377521</td>\n",
              "      <td>0.407803</td>\n",
              "      <td>0.410098</td>\n",
              "      <td>0.005356</td>\n",
              "      <td>-0.030501</td>\n",
              "      <td>-0.028373</td>\n",
              "      <td>0.043300</td>\n",
              "      <td>0.014572</td>\n",
              "      <td>-0.005967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>105</td>\n",
              "      <td>-397.74173</td>\n",
              "      <td>65.599550</td>\n",
              "      <td>-1.686943</td>\n",
              "      <td>38.130620</td>\n",
              "      <td>-12.816805</td>\n",
              "      <td>14.129421</td>\n",
              "      <td>-20.335257</td>\n",
              "      <td>-13.580517</td>\n",
              "      <td>-3.846510</td>\n",
              "      <td>...</td>\n",
              "      <td>0.568361</td>\n",
              "      <td>0.574512</td>\n",
              "      <td>0.554483</td>\n",
              "      <td>0.523765</td>\n",
              "      <td>0.003604</td>\n",
              "      <td>-0.009971</td>\n",
              "      <td>-0.011075</td>\n",
              "      <td>-0.030320</td>\n",
              "      <td>-0.005274</td>\n",
              "      <td>-0.003526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>106</td>\n",
              "      <td>-467.15588</td>\n",
              "      <td>52.217026</td>\n",
              "      <td>10.470471</td>\n",
              "      <td>47.414780</td>\n",
              "      <td>8.690019</td>\n",
              "      <td>15.601270</td>\n",
              "      <td>-2.032935</td>\n",
              "      <td>4.985774</td>\n",
              "      <td>-7.432734</td>\n",
              "      <td>...</td>\n",
              "      <td>0.531997</td>\n",
              "      <td>0.523647</td>\n",
              "      <td>0.509723</td>\n",
              "      <td>0.498566</td>\n",
              "      <td>0.051532</td>\n",
              "      <td>0.015525</td>\n",
              "      <td>-0.006052</td>\n",
              "      <td>0.018201</td>\n",
              "      <td>0.004361</td>\n",
              "      <td>-0.021649</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>107 rows × 260 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1b39563a-dc30-46bf-ba14-0a574fa8387b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1b39563a-dc30-46bf-ba14-0a574fa8387b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1b39563a-dc30-46bf-ba14-0a574fa8387b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d7503a9b-5887-47ac-8d76-78e26a16b514\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d7503a9b-5887-47ac-8d76-78e26a16b514')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d7503a9b-5887-47ac-8d76-78e26a16b514 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "x_test"
            }
          },
          "metadata": {},
          "execution_count": 584
        }
      ],
      "source": [
        "x_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 585,
      "id": "62579094",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62579094",
        "outputId": "79655415-93e0-4ec1-dada-825829b06e05"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      2\n",
              "1      0\n",
              "2      1\n",
              "3      3\n",
              "4      5\n",
              "      ..\n",
              "102    2\n",
              "103    5\n",
              "104    4\n",
              "105    5\n",
              "106    3\n",
              "Name: 0.1, Length: 107, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 585
        }
      ],
      "source": [
        "y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 586,
      "id": "3beb4ef2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "3beb4ef2",
        "outputId": "6234e50e-4cd5-4695-de43-ae26b6f9c44c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: ylabel='count'>"
            ]
          },
          "metadata": {},
          "execution_count": 586
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "sns.countplot(df1['0'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 587,
      "id": "d58a5824",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "d58a5824",
        "outputId": "4140a8e5-deb3-46b0-f5e2-3bcb2fddb41f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: ylabel='count'>"
            ]
          },
          "metadata": {},
          "execution_count": 587
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "sns.countplot(df2['0'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 588,
      "id": "f4bf0f42",
      "metadata": {
        "id": "f4bf0f42"
      },
      "outputs": [],
      "source": [
        "# from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 589,
      "id": "5bd3a370",
      "metadata": {
        "id": "5bd3a370"
      },
      "outputs": [],
      "source": [
        "# x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 590,
      "id": "7b9f98bc",
      "metadata": {
        "id": "7b9f98bc"
      },
      "outputs": [],
      "source": [
        "# x_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 591,
      "id": "c8d669e4",
      "metadata": {
        "id": "c8d669e4"
      },
      "outputs": [],
      "source": [
        "# y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 592,
      "id": "3e5f00f5",
      "metadata": {
        "id": "3e5f00f5"
      },
      "outputs": [],
      "source": [
        "# x_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 593,
      "id": "6d201bc1",
      "metadata": {
        "id": "6d201bc1"
      },
      "outputs": [],
      "source": [
        "# y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 594,
      "id": "000082a7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "000082a7",
        "outputId": "0d3842fd-a1b5-41e0-b70d-1b767756c174"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 0, 1, 3, 5, 6, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 594
        }
      ],
      "source": [
        "#Check unique values for y_test\n",
        "y_test.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 595,
      "id": "0c50dd63",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c50dd63",
        "outputId": "64438821-0e25-4170-923f-19566652cff8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 3, 2, 4, 5, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 595
        }
      ],
      "source": [
        "#Check unique values for y_train\n",
        "y_train.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 596,
      "id": "2f69e286",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f69e286",
        "outputId": "5175c96b-f8de-4757-9030-67d62bdfce4d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 1.0918367346938775,\n",
              " 1: 0.9553571428571429,\n",
              " 2: 0.6053748231966054,\n",
              " 3: 1.2228571428571429,\n",
              " 4: 1.1116883116883116,\n",
              " 5: 0.9406593406593406,\n",
              " 6: 1.6525096525096525}"
            ]
          },
          "metadata": {},
          "execution_count": 596
        }
      ],
      "source": [
        "from sklearn.utils import compute_class_weight\n",
        "class_weights = compute_class_weight(\n",
        "                                        class_weight = \"balanced\",\n",
        "                                        classes = np.unique(y_train),\n",
        "                                        y = y_train\n",
        "                                    )\n",
        "class_weights = dict(zip(np.unique(y_train), class_weights))\n",
        "class_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 597,
      "id": "87b553a9",
      "metadata": {
        "id": "87b553a9"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "#Normalize the data\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(x_train)\n",
        "X_train_scalled = scaler.transform(x_train)\n",
        "X_test_scalled = scaler.transform(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 598,
      "id": "7b62969d",
      "metadata": {
        "id": "7b62969d"
      },
      "outputs": [],
      "source": [
        "#Import packages for CNN\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Conv1D\n",
        "from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM, BatchNormalization, Flatten, MaxPooling1D\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.regularizers import l2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 599,
      "id": "c598744f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c598744f",
        "outputId": "f08e3071-fd68-4c60-9124-3e045d8acc82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[490, 732, 815, 760]\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "res = []\n",
        "for j in range(4):\n",
        "    res.append(random.randint(300, 1000))\n",
        "# res.sort(reverse=True)\n",
        "print(res)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu', input_shape=(260, 1)))\n",
        "model.add(MaxPooling1D(pool_size=2, strides = 2, padding = 'same'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2, strides = 2, padding = 'same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2, strides = 2, padding = 'same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv1D(128, kernel_size=5, strides=1, padding='same', activation='sigmoid'))\n",
        "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# model.add(Conv1D(128, kernel_size=5, strides=1, padding='same', activation='sigmoid'))\n",
        "# model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Dropout(0.2))\n",
        "\n",
        "# model.add(Conv1D(64, kernel_size=5, strides=1, padding='same', activation='sigmoid'))\n",
        "# model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Dropout(0.3))\n",
        "##\n",
        "model.add(LSTM(256, return_sequences=True))\n",
        "model.add(LSTM(256))\n",
        "\n",
        "\n",
        "model.add(Dense(256, activation='relu'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(256, activation='relu'))\n",
        "# model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "##\n",
        "# model.add(Dense(64, activation='sigmoid'))\n",
        "# # model.add(BatchNormalization())\n",
        "# model.add(Dropout(0.3))\n",
        "\n",
        "# model.add(Dense(32, activation='sigmoid'))\n",
        "# # model.add(BatchNormalization())\n",
        "# model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(7, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Q6P4AQ4Mrdt",
        "outputId": "7024ad04-99b8-40aa-b640-ffa4f916bbde"
      },
      "id": "_Q6P4AQ4Mrdt",
      "execution_count": 600,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_44 (Conv1D)          (None, 260, 256)          1536      \n",
            "                                                                 \n",
            " max_pooling1d_44 (MaxPooli  (None, 130, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_44 (Ba  (None, 130, 256)          1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv1d_45 (Conv1D)          (None, 130, 256)          327936    \n",
            "                                                                 \n",
            " max_pooling1d_45 (MaxPooli  (None, 65, 256)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_45 (Ba  (None, 65, 256)           1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_44 (Dropout)        (None, 65, 256)           0         \n",
            "                                                                 \n",
            " conv1d_46 (Conv1D)          (None, 65, 256)           327936    \n",
            "                                                                 \n",
            " max_pooling1d_46 (MaxPooli  (None, 33, 256)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_46 (Ba  (None, 33, 256)           1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_45 (Dropout)        (None, 33, 256)           0         \n",
            "                                                                 \n",
            " conv1d_47 (Conv1D)          (None, 33, 128)           163968    \n",
            "                                                                 \n",
            " max_pooling1d_47 (MaxPooli  (None, 17, 128)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_47 (Ba  (None, 17, 128)           512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_46 (Dropout)        (None, 17, 128)           0         \n",
            "                                                                 \n",
            " lstm_22 (LSTM)              (None, 17, 256)           394240    \n",
            "                                                                 \n",
            " lstm_23 (LSTM)              (None, 256)               525312    \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 256)               65792     \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 256)               65792     \n",
            "                                                                 \n",
            " dropout_47 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 7)                 1799      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1877895 (7.16 MB)\n",
            "Trainable params: 1876103 (7.16 MB)\n",
            "Non-trainable params: 1792 (7.00 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tempfile\n",
        "initial_weights = os.path.join(tempfile.mkdtemp(), 'initial_weights')\n",
        "model.save_weights(initial_weights)"
      ],
      "metadata": {
        "id": "JCEBlr_YMzuM"
      },
      "id": "JCEBlr_YMzuM",
      "execution_count": 601,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(initial_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8l3JMDetM3-D",
        "outputId": "bef8d2a8-02d1-4033-b625-3d5ae8c8274e"
      },
      "id": "8l3JMDetM3-D",
      "execution_count": 602,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7a520af2ada0>"
            ]
          },
          "metadata": {},
          "execution_count": 602
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimiser = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=optimiser,\n",
        "              loss='sparse_categorical_crossentropy',                             #CategoricalCrossentropy\n",
        "              metrics=['SparseCategoricalAccuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WglAV3TMM7KM",
        "outputId": "d7b238fd-67e3-4f3e-9028-5729f3e74710"
      },
      "id": "WglAV3TMM7KM",
      "execution_count": 603,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_44 (Conv1D)          (None, 260, 256)          1536      \n",
            "                                                                 \n",
            " max_pooling1d_44 (MaxPooli  (None, 130, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_44 (Ba  (None, 130, 256)          1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv1d_45 (Conv1D)          (None, 130, 256)          327936    \n",
            "                                                                 \n",
            " max_pooling1d_45 (MaxPooli  (None, 65, 256)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_45 (Ba  (None, 65, 256)           1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_44 (Dropout)        (None, 65, 256)           0         \n",
            "                                                                 \n",
            " conv1d_46 (Conv1D)          (None, 65, 256)           327936    \n",
            "                                                                 \n",
            " max_pooling1d_46 (MaxPooli  (None, 33, 256)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_46 (Ba  (None, 33, 256)           1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_45 (Dropout)        (None, 33, 256)           0         \n",
            "                                                                 \n",
            " conv1d_47 (Conv1D)          (None, 33, 128)           163968    \n",
            "                                                                 \n",
            " max_pooling1d_47 (MaxPooli  (None, 17, 128)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_47 (Ba  (None, 17, 128)           512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_46 (Dropout)        (None, 17, 128)           0         \n",
            "                                                                 \n",
            " lstm_22 (LSTM)              (None, 17, 256)           394240    \n",
            "                                                                 \n",
            " lstm_23 (LSTM)              (None, 256)               525312    \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 256)               65792     \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 256)               65792     \n",
            "                                                                 \n",
            " dropout_47 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 7)                 1799      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1877895 (7.16 MB)\n",
            "Trainable params: 1876103 (7.16 MB)\n",
            "Non-trainable params: 1792 (7.00 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path='cnn_lstm_emodb3.ckpt'\n",
        "checkpoint_dir=os.path.dirname(checkpoint_path)\n",
        "callback1=tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, monitor='val_sparse_categorical_accuracy', verbose=1,\n",
        "   save_best_only=True,save_weights_only=True,)\n",
        "callback2=tf.keras.callbacks.EarlyStopping(monitor='val_sparse_categorical_accuracy',min_delta=0, patience=50, verbose=0, mode='auto',baseline=None,restore_best_weights=True)\n",
        "cp_callback=[callback1,callback2]"
      ],
      "metadata": {
        "id": "Kg0_S4kRM8DV"
      },
      "id": "Kg0_S4kRM8DV",
      "execution_count": 604,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train_scalled, y_train, validation_data=(X_test_scalled, y_test), batch_size=64, epochs=900, verbose=1,class_weight=class_weights,callbacks=cp_callback)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "giDUxkTnNGXy",
        "outputId": "927484c9-d9bc-40cb-95f5-69d237da4485"
      },
      "id": "giDUxkTnNGXy",
      "execution_count": 605,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.9272 - sparse_categorical_accuracy: 0.2360\n",
            "Epoch 1: val_sparse_categorical_accuracy improved from -inf to 0.14953, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 9s 217ms/step - loss: 1.9272 - sparse_categorical_accuracy: 0.2360 - val_loss: 1.9414 - val_sparse_categorical_accuracy: 0.1495\n",
            "Epoch 2/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.8763 - sparse_categorical_accuracy: 0.2664\n",
            "Epoch 2: val_sparse_categorical_accuracy did not improve from 0.14953\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 1.8763 - sparse_categorical_accuracy: 0.2664 - val_loss: 1.9431 - val_sparse_categorical_accuracy: 0.1402\n",
            "Epoch 3/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.8376 - sparse_categorical_accuracy: 0.2991\n",
            "Epoch 3: val_sparse_categorical_accuracy did not improve from 0.14953\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 1.8376 - sparse_categorical_accuracy: 0.2991 - val_loss: 1.9439 - val_sparse_categorical_accuracy: 0.1028\n",
            "Epoch 4/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.8020 - sparse_categorical_accuracy: 0.2991\n",
            "Epoch 4: val_sparse_categorical_accuracy did not improve from 0.14953\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 1.8020 - sparse_categorical_accuracy: 0.2991 - val_loss: 1.9452 - val_sparse_categorical_accuracy: 0.1121\n",
            "Epoch 5/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.7674 - sparse_categorical_accuracy: 0.3435\n",
            "Epoch 5: val_sparse_categorical_accuracy improved from 0.14953 to 0.15888, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 52ms/step - loss: 1.7674 - sparse_categorical_accuracy: 0.3435 - val_loss: 1.9471 - val_sparse_categorical_accuracy: 0.1589\n",
            "Epoch 6/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.7246 - sparse_categorical_accuracy: 0.3715\n",
            "Epoch 6: val_sparse_categorical_accuracy did not improve from 0.15888\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 1.7246 - sparse_categorical_accuracy: 0.3715 - val_loss: 1.9528 - val_sparse_categorical_accuracy: 0.1121\n",
            "Epoch 7/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.6822 - sparse_categorical_accuracy: 0.3949\n",
            "Epoch 7: val_sparse_categorical_accuracy did not improve from 0.15888\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 1.6822 - sparse_categorical_accuracy: 0.3949 - val_loss: 1.9611 - val_sparse_categorical_accuracy: 0.1121\n",
            "Epoch 8/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.6269 - sparse_categorical_accuracy: 0.4206\n",
            "Epoch 8: val_sparse_categorical_accuracy did not improve from 0.15888\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 1.6269 - sparse_categorical_accuracy: 0.4206 - val_loss: 1.9792 - val_sparse_categorical_accuracy: 0.1121\n",
            "Epoch 9/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.5423 - sparse_categorical_accuracy: 0.4673\n",
            "Epoch 9: val_sparse_categorical_accuracy did not improve from 0.15888\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 1.5423 - sparse_categorical_accuracy: 0.4673 - val_loss: 2.0110 - val_sparse_categorical_accuracy: 0.1121\n",
            "Epoch 10/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.4326 - sparse_categorical_accuracy: 0.4860\n",
            "Epoch 10: val_sparse_categorical_accuracy did not improve from 0.15888\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 1.4326 - sparse_categorical_accuracy: 0.4860 - val_loss: 2.0711 - val_sparse_categorical_accuracy: 0.1121\n",
            "Epoch 11/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.3389 - sparse_categorical_accuracy: 0.4930\n",
            "Epoch 11: val_sparse_categorical_accuracy did not improve from 0.15888\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 1.3389 - sparse_categorical_accuracy: 0.4930 - val_loss: 2.1670 - val_sparse_categorical_accuracy: 0.1308\n",
            "Epoch 12/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.2496 - sparse_categorical_accuracy: 0.5444\n",
            "Epoch 12: val_sparse_categorical_accuracy did not improve from 0.15888\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 1.2496 - sparse_categorical_accuracy: 0.5444 - val_loss: 2.2652 - val_sparse_categorical_accuracy: 0.1402\n",
            "Epoch 13/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.1801 - sparse_categorical_accuracy: 0.5491\n",
            "Epoch 13: val_sparse_categorical_accuracy did not improve from 0.15888\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 1.1801 - sparse_categorical_accuracy: 0.5491 - val_loss: 2.3839 - val_sparse_categorical_accuracy: 0.1402\n",
            "Epoch 14/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.0651 - sparse_categorical_accuracy: 0.5935\n",
            "Epoch 14: val_sparse_categorical_accuracy did not improve from 0.15888\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 1.0651 - sparse_categorical_accuracy: 0.5935 - val_loss: 2.5069 - val_sparse_categorical_accuracy: 0.1402\n",
            "Epoch 15/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.9785 - sparse_categorical_accuracy: 0.6425\n",
            "Epoch 15: val_sparse_categorical_accuracy did not improve from 0.15888\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.9785 - sparse_categorical_accuracy: 0.6425 - val_loss: 2.5602 - val_sparse_categorical_accuracy: 0.1402\n",
            "Epoch 16/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.8728 - sparse_categorical_accuracy: 0.6776\n",
            "Epoch 16: val_sparse_categorical_accuracy did not improve from 0.15888\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.8728 - sparse_categorical_accuracy: 0.6776 - val_loss: 2.4516 - val_sparse_categorical_accuracy: 0.1402\n",
            "Epoch 17/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.8139 - sparse_categorical_accuracy: 0.6565\n",
            "Epoch 17: val_sparse_categorical_accuracy did not improve from 0.15888\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.8139 - sparse_categorical_accuracy: 0.6565 - val_loss: 2.3082 - val_sparse_categorical_accuracy: 0.1402\n",
            "Epoch 18/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.7556 - sparse_categorical_accuracy: 0.6939\n",
            "Epoch 18: val_sparse_categorical_accuracy did not improve from 0.15888\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.7556 - sparse_categorical_accuracy: 0.6939 - val_loss: 2.1931 - val_sparse_categorical_accuracy: 0.1495\n",
            "Epoch 19/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.7024 - sparse_categorical_accuracy: 0.7150\n",
            "Epoch 19: val_sparse_categorical_accuracy did not improve from 0.15888\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.7024 - sparse_categorical_accuracy: 0.7150 - val_loss: 2.3882 - val_sparse_categorical_accuracy: 0.1402\n",
            "Epoch 20/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.5808 - sparse_categorical_accuracy: 0.7944\n",
            "Epoch 20: val_sparse_categorical_accuracy did not improve from 0.15888\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.5808 - sparse_categorical_accuracy: 0.7944 - val_loss: 2.7267 - val_sparse_categorical_accuracy: 0.1402\n",
            "Epoch 21/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.5660 - sparse_categorical_accuracy: 0.7921\n",
            "Epoch 21: val_sparse_categorical_accuracy did not improve from 0.15888\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.5660 - sparse_categorical_accuracy: 0.7921 - val_loss: 3.1033 - val_sparse_categorical_accuracy: 0.1402\n",
            "Epoch 22/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.5043 - sparse_categorical_accuracy: 0.7897\n",
            "Epoch 22: val_sparse_categorical_accuracy did not improve from 0.15888\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.5043 - sparse_categorical_accuracy: 0.7897 - val_loss: 3.4672 - val_sparse_categorical_accuracy: 0.1402\n",
            "Epoch 23/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.4721 - sparse_categorical_accuracy: 0.8224\n",
            "Epoch 23: val_sparse_categorical_accuracy did not improve from 0.15888\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.4721 - sparse_categorical_accuracy: 0.8224 - val_loss: 3.6278 - val_sparse_categorical_accuracy: 0.1402\n",
            "Epoch 24/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.4241 - sparse_categorical_accuracy: 0.8201\n",
            "Epoch 24: val_sparse_categorical_accuracy did not improve from 0.15888\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.4241 - sparse_categorical_accuracy: 0.8201 - val_loss: 3.7376 - val_sparse_categorical_accuracy: 0.1402\n",
            "Epoch 25/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.3826 - sparse_categorical_accuracy: 0.8458\n",
            "Epoch 25: val_sparse_categorical_accuracy did not improve from 0.15888\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.3826 - sparse_categorical_accuracy: 0.8458 - val_loss: 3.8833 - val_sparse_categorical_accuracy: 0.1402\n",
            "Epoch 26/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.4046 - sparse_categorical_accuracy: 0.8131\n",
            "Epoch 26: val_sparse_categorical_accuracy improved from 0.15888 to 0.19626, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 51ms/step - loss: 0.4046 - sparse_categorical_accuracy: 0.8131 - val_loss: 4.0840 - val_sparse_categorical_accuracy: 0.1963\n",
            "Epoch 27/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.2968 - sparse_categorical_accuracy: 0.8879\n",
            "Epoch 27: val_sparse_categorical_accuracy did not improve from 0.19626\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.2968 - sparse_categorical_accuracy: 0.8879 - val_loss: 4.2347 - val_sparse_categorical_accuracy: 0.1869\n",
            "Epoch 28/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.3088 - sparse_categorical_accuracy: 0.8762\n",
            "Epoch 28: val_sparse_categorical_accuracy did not improve from 0.19626\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.3088 - sparse_categorical_accuracy: 0.8762 - val_loss: 4.5162 - val_sparse_categorical_accuracy: 0.1963\n",
            "Epoch 29/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.3021 - sparse_categorical_accuracy: 0.8832\n",
            "Epoch 29: val_sparse_categorical_accuracy did not improve from 0.19626\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.3021 - sparse_categorical_accuracy: 0.8832 - val_loss: 4.7572 - val_sparse_categorical_accuracy: 0.1963\n",
            "Epoch 30/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.2611 - sparse_categorical_accuracy: 0.8879\n",
            "Epoch 30: val_sparse_categorical_accuracy did not improve from 0.19626\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.2611 - sparse_categorical_accuracy: 0.8879 - val_loss: 5.0121 - val_sparse_categorical_accuracy: 0.1402\n",
            "Epoch 31/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.2100 - sparse_categorical_accuracy: 0.9112\n",
            "Epoch 31: val_sparse_categorical_accuracy did not improve from 0.19626\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.2100 - sparse_categorical_accuracy: 0.9112 - val_loss: 5.1364 - val_sparse_categorical_accuracy: 0.1402\n",
            "Epoch 32/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.1932 - sparse_categorical_accuracy: 0.9346\n",
            "Epoch 32: val_sparse_categorical_accuracy did not improve from 0.19626\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.1932 - sparse_categorical_accuracy: 0.9346 - val_loss: 5.0667 - val_sparse_categorical_accuracy: 0.1963\n",
            "Epoch 33/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.1561 - sparse_categorical_accuracy: 0.9509\n",
            "Epoch 33: val_sparse_categorical_accuracy did not improve from 0.19626\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.1561 - sparse_categorical_accuracy: 0.9509 - val_loss: 5.5507 - val_sparse_categorical_accuracy: 0.1402\n",
            "Epoch 34/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.1582 - sparse_categorical_accuracy: 0.9463\n",
            "Epoch 34: val_sparse_categorical_accuracy did not improve from 0.19626\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.1582 - sparse_categorical_accuracy: 0.9463 - val_loss: 5.4721 - val_sparse_categorical_accuracy: 0.1402\n",
            "Epoch 35/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.1376 - sparse_categorical_accuracy: 0.9556\n",
            "Epoch 35: val_sparse_categorical_accuracy did not improve from 0.19626\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.1376 - sparse_categorical_accuracy: 0.9556 - val_loss: 5.4854 - val_sparse_categorical_accuracy: 0.1963\n",
            "Epoch 36/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.1269 - sparse_categorical_accuracy: 0.9603\n",
            "Epoch 36: val_sparse_categorical_accuracy did not improve from 0.19626\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.1269 - sparse_categorical_accuracy: 0.9603 - val_loss: 5.8290 - val_sparse_categorical_accuracy: 0.1402\n",
            "Epoch 37/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.1102 - sparse_categorical_accuracy: 0.9626\n",
            "Epoch 37: val_sparse_categorical_accuracy improved from 0.19626 to 0.20561, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 52ms/step - loss: 0.1102 - sparse_categorical_accuracy: 0.9626 - val_loss: 5.7921 - val_sparse_categorical_accuracy: 0.2056\n",
            "Epoch 38/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.1396 - sparse_categorical_accuracy: 0.9369\n",
            "Epoch 38: val_sparse_categorical_accuracy did not improve from 0.20561\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.1396 - sparse_categorical_accuracy: 0.9369 - val_loss: 6.1550 - val_sparse_categorical_accuracy: 0.1402\n",
            "Epoch 39/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.1261 - sparse_categorical_accuracy: 0.9626\n",
            "Epoch 39: val_sparse_categorical_accuracy did not improve from 0.20561\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.1261 - sparse_categorical_accuracy: 0.9626 - val_loss: 6.0837 - val_sparse_categorical_accuracy: 0.1402\n",
            "Epoch 40/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.1099 - sparse_categorical_accuracy: 0.9556\n",
            "Epoch 40: val_sparse_categorical_accuracy did not improve from 0.20561\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.1099 - sparse_categorical_accuracy: 0.9556 - val_loss: 5.9216 - val_sparse_categorical_accuracy: 0.1869\n",
            "Epoch 41/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.1024 - sparse_categorical_accuracy: 0.9673\n",
            "Epoch 41: val_sparse_categorical_accuracy did not improve from 0.20561\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.1024 - sparse_categorical_accuracy: 0.9673 - val_loss: 5.8707 - val_sparse_categorical_accuracy: 0.1869\n",
            "Epoch 42/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0914 - sparse_categorical_accuracy: 0.9673\n",
            "Epoch 42: val_sparse_categorical_accuracy did not improve from 0.20561\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.0914 - sparse_categorical_accuracy: 0.9673 - val_loss: 6.5275 - val_sparse_categorical_accuracy: 0.1402\n",
            "Epoch 43/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.1387 - sparse_categorical_accuracy: 0.9533\n",
            "Epoch 43: val_sparse_categorical_accuracy did not improve from 0.20561\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.1387 - sparse_categorical_accuracy: 0.9533 - val_loss: 6.9544 - val_sparse_categorical_accuracy: 0.1402\n",
            "Epoch 44/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0825 - sparse_categorical_accuracy: 0.9720\n",
            "Epoch 44: val_sparse_categorical_accuracy did not improve from 0.20561\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.0825 - sparse_categorical_accuracy: 0.9720 - val_loss: 6.4103 - val_sparse_categorical_accuracy: 0.1495\n",
            "Epoch 45/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0937 - sparse_categorical_accuracy: 0.9673\n",
            "Epoch 45: val_sparse_categorical_accuracy did not improve from 0.20561\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.0937 - sparse_categorical_accuracy: 0.9673 - val_loss: 5.8448 - val_sparse_categorical_accuracy: 0.1869\n",
            "Epoch 46/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0985 - sparse_categorical_accuracy: 0.9650\n",
            "Epoch 46: val_sparse_categorical_accuracy did not improve from 0.20561\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.0985 - sparse_categorical_accuracy: 0.9650 - val_loss: 6.2318 - val_sparse_categorical_accuracy: 0.1589\n",
            "Epoch 47/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0586 - sparse_categorical_accuracy: 0.9766\n",
            "Epoch 47: val_sparse_categorical_accuracy did not improve from 0.20561\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.0586 - sparse_categorical_accuracy: 0.9766 - val_loss: 6.4493 - val_sparse_categorical_accuracy: 0.1495\n",
            "Epoch 48/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0970 - sparse_categorical_accuracy: 0.9766\n",
            "Epoch 48: val_sparse_categorical_accuracy did not improve from 0.20561\n",
            "7/7 [==============================] - 0s 33ms/step - loss: 0.0909 - sparse_categorical_accuracy: 0.9790 - val_loss: 6.0538 - val_sparse_categorical_accuracy: 0.1869\n",
            "Epoch 49/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0791 - sparse_categorical_accuracy: 0.9790\n",
            "Epoch 49: val_sparse_categorical_accuracy improved from 0.20561 to 0.21495, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 63ms/step - loss: 0.0791 - sparse_categorical_accuracy: 0.9790 - val_loss: 6.0089 - val_sparse_categorical_accuracy: 0.2150\n",
            "Epoch 50/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.1080 - sparse_categorical_accuracy: 0.9688\n",
            "Epoch 50: val_sparse_categorical_accuracy did not improve from 0.21495\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.1028 - sparse_categorical_accuracy: 0.9696 - val_loss: 7.1361 - val_sparse_categorical_accuracy: 0.1495\n",
            "Epoch 51/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0936 - sparse_categorical_accuracy: 0.9579\n",
            "Epoch 51: val_sparse_categorical_accuracy did not improve from 0.21495\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 0.0936 - sparse_categorical_accuracy: 0.9579 - val_loss: 6.1988 - val_sparse_categorical_accuracy: 0.1963\n",
            "Epoch 52/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0748 - sparse_categorical_accuracy: 0.9740\n",
            "Epoch 52: val_sparse_categorical_accuracy did not improve from 0.21495\n",
            "7/7 [==============================] - 0s 33ms/step - loss: 0.0775 - sparse_categorical_accuracy: 0.9743 - val_loss: 5.9779 - val_sparse_categorical_accuracy: 0.1869\n",
            "Epoch 53/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0420 - sparse_categorical_accuracy: 0.9860\n",
            "Epoch 53: val_sparse_categorical_accuracy did not improve from 0.21495\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 0.0420 - sparse_categorical_accuracy: 0.9860 - val_loss: 6.0077 - val_sparse_categorical_accuracy: 0.1963\n",
            "Epoch 54/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0750 - sparse_categorical_accuracy: 0.9743\n",
            "Epoch 54: val_sparse_categorical_accuracy did not improve from 0.21495\n",
            "7/7 [==============================] - 0s 33ms/step - loss: 0.0750 - sparse_categorical_accuracy: 0.9743 - val_loss: 5.9024 - val_sparse_categorical_accuracy: 0.1963\n",
            "Epoch 55/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0971 - sparse_categorical_accuracy: 0.9696\n",
            "Epoch 55: val_sparse_categorical_accuracy did not improve from 0.21495\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.0971 - sparse_categorical_accuracy: 0.9696 - val_loss: 6.3021 - val_sparse_categorical_accuracy: 0.2056\n",
            "Epoch 56/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0647 - sparse_categorical_accuracy: 0.9743\n",
            "Epoch 56: val_sparse_categorical_accuracy did not improve from 0.21495\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 0.0647 - sparse_categorical_accuracy: 0.9743 - val_loss: 6.4332 - val_sparse_categorical_accuracy: 0.2056\n",
            "Epoch 57/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0438 - sparse_categorical_accuracy: 0.9860\n",
            "Epoch 57: val_sparse_categorical_accuracy did not improve from 0.21495\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.0438 - sparse_categorical_accuracy: 0.9860 - val_loss: 6.3102 - val_sparse_categorical_accuracy: 0.2056\n",
            "Epoch 58/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0281 - sparse_categorical_accuracy: 0.9948\n",
            "Epoch 58: val_sparse_categorical_accuracy did not improve from 0.21495\n",
            "7/7 [==============================] - 0s 33ms/step - loss: 0.0349 - sparse_categorical_accuracy: 0.9907 - val_loss: 6.7203 - val_sparse_categorical_accuracy: 0.2056\n",
            "Epoch 59/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0425 - sparse_categorical_accuracy: 0.9870\n",
            "Epoch 59: val_sparse_categorical_accuracy did not improve from 0.21495\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 0.0403 - sparse_categorical_accuracy: 0.9883 - val_loss: 6.7551 - val_sparse_categorical_accuracy: 0.2056\n",
            "Epoch 60/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0227 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 60: val_sparse_categorical_accuracy did not improve from 0.21495\n",
            "7/7 [==============================] - 0s 33ms/step - loss: 0.0227 - sparse_categorical_accuracy: 0.9977 - val_loss: 6.5008 - val_sparse_categorical_accuracy: 0.1869\n",
            "Epoch 61/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0440 - sparse_categorical_accuracy: 0.9907\n",
            "Epoch 61: val_sparse_categorical_accuracy did not improve from 0.21495\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 0.0440 - sparse_categorical_accuracy: 0.9907 - val_loss: 6.4622 - val_sparse_categorical_accuracy: 0.1869\n",
            "Epoch 62/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0270 - sparse_categorical_accuracy: 0.9907\n",
            "Epoch 62: val_sparse_categorical_accuracy did not improve from 0.21495\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.0270 - sparse_categorical_accuracy: 0.9907 - val_loss: 6.5619 - val_sparse_categorical_accuracy: 0.1963\n",
            "Epoch 63/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0288 - sparse_categorical_accuracy: 0.9953\n",
            "Epoch 63: val_sparse_categorical_accuracy did not improve from 0.21495\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.0288 - sparse_categorical_accuracy: 0.9953 - val_loss: 6.6770 - val_sparse_categorical_accuracy: 0.2056\n",
            "Epoch 64/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0158 - sparse_categorical_accuracy: 0.9953\n",
            "Epoch 64: val_sparse_categorical_accuracy did not improve from 0.21495\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.0158 - sparse_categorical_accuracy: 0.9953 - val_loss: 6.5738 - val_sparse_categorical_accuracy: 0.2150\n",
            "Epoch 65/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0213 - sparse_categorical_accuracy: 0.9930\n",
            "Epoch 65: val_sparse_categorical_accuracy did not improve from 0.21495\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.0213 - sparse_categorical_accuracy: 0.9930 - val_loss: 6.5957 - val_sparse_categorical_accuracy: 0.2056\n",
            "Epoch 66/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0264 - sparse_categorical_accuracy: 0.9907\n",
            "Epoch 66: val_sparse_categorical_accuracy did not improve from 0.21495\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.0264 - sparse_categorical_accuracy: 0.9907 - val_loss: 6.5737 - val_sparse_categorical_accuracy: 0.2056\n",
            "Epoch 67/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0298 - sparse_categorical_accuracy: 0.9883\n",
            "Epoch 67: val_sparse_categorical_accuracy did not improve from 0.21495\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.0298 - sparse_categorical_accuracy: 0.9883 - val_loss: 6.6540 - val_sparse_categorical_accuracy: 0.2056\n",
            "Epoch 68/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0128 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 68: val_sparse_categorical_accuracy did not improve from 0.21495\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.0128 - sparse_categorical_accuracy: 0.9977 - val_loss: 6.5551 - val_sparse_categorical_accuracy: 0.2150\n",
            "Epoch 69/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0283 - sparse_categorical_accuracy: 0.9930\n",
            "Epoch 69: val_sparse_categorical_accuracy did not improve from 0.21495\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.0283 - sparse_categorical_accuracy: 0.9930 - val_loss: 6.6132 - val_sparse_categorical_accuracy: 0.1963\n",
            "Epoch 70/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0326 - sparse_categorical_accuracy: 0.9907\n",
            "Epoch 70: val_sparse_categorical_accuracy did not improve from 0.21495\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.0326 - sparse_categorical_accuracy: 0.9907 - val_loss: 6.4574 - val_sparse_categorical_accuracy: 0.2150\n",
            "Epoch 71/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0616 - sparse_categorical_accuracy: 0.9813\n",
            "Epoch 71: val_sparse_categorical_accuracy improved from 0.21495 to 0.23364, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 53ms/step - loss: 0.0616 - sparse_categorical_accuracy: 0.9813 - val_loss: 6.4083 - val_sparse_categorical_accuracy: 0.2336\n",
            "Epoch 72/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0412 - sparse_categorical_accuracy: 0.9836\n",
            "Epoch 72: val_sparse_categorical_accuracy did not improve from 0.23364\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.0412 - sparse_categorical_accuracy: 0.9836 - val_loss: 5.7471 - val_sparse_categorical_accuracy: 0.2243\n",
            "Epoch 73/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0381 - sparse_categorical_accuracy: 0.9836\n",
            "Epoch 73: val_sparse_categorical_accuracy did not improve from 0.23364\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.0381 - sparse_categorical_accuracy: 0.9836 - val_loss: 4.8091 - val_sparse_categorical_accuracy: 0.2336\n",
            "Epoch 74/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0543 - sparse_categorical_accuracy: 0.9907\n",
            "Epoch 74: val_sparse_categorical_accuracy improved from 0.23364 to 0.29907, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 54ms/step - loss: 0.0543 - sparse_categorical_accuracy: 0.9907 - val_loss: 4.6703 - val_sparse_categorical_accuracy: 0.2991\n",
            "Epoch 75/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0384 - sparse_categorical_accuracy: 0.9836\n",
            "Epoch 75: val_sparse_categorical_accuracy improved from 0.29907 to 0.31776, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 62ms/step - loss: 0.0384 - sparse_categorical_accuracy: 0.9836 - val_loss: 4.6013 - val_sparse_categorical_accuracy: 0.3178\n",
            "Epoch 76/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0428 - sparse_categorical_accuracy: 0.9860\n",
            "Epoch 76: val_sparse_categorical_accuracy did not improve from 0.31776\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.0428 - sparse_categorical_accuracy: 0.9860 - val_loss: 5.1423 - val_sparse_categorical_accuracy: 0.2617\n",
            "Epoch 77/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0424 - sparse_categorical_accuracy: 0.9836\n",
            "Epoch 77: val_sparse_categorical_accuracy did not improve from 0.31776\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.0424 - sparse_categorical_accuracy: 0.9836 - val_loss: 4.5365 - val_sparse_categorical_accuracy: 0.2897\n",
            "Epoch 78/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0283 - sparse_categorical_accuracy: 0.9883\n",
            "Epoch 78: val_sparse_categorical_accuracy did not improve from 0.31776\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.0283 - sparse_categorical_accuracy: 0.9883 - val_loss: 4.3767 - val_sparse_categorical_accuracy: 0.2991\n",
            "Epoch 79/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0121 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 79: val_sparse_categorical_accuracy did not improve from 0.31776\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.0121 - sparse_categorical_accuracy: 0.9977 - val_loss: 4.1339 - val_sparse_categorical_accuracy: 0.3084\n",
            "Epoch 80/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0273 - sparse_categorical_accuracy: 0.9907\n",
            "Epoch 80: val_sparse_categorical_accuracy improved from 0.31776 to 0.35514, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 50ms/step - loss: 0.0273 - sparse_categorical_accuracy: 0.9907 - val_loss: 3.8308 - val_sparse_categorical_accuracy: 0.3551\n",
            "Epoch 81/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0324 - sparse_categorical_accuracy: 0.9930\n",
            "Epoch 81: val_sparse_categorical_accuracy improved from 0.35514 to 0.37383, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 51ms/step - loss: 0.0324 - sparse_categorical_accuracy: 0.9930 - val_loss: 3.6328 - val_sparse_categorical_accuracy: 0.3738\n",
            "Epoch 82/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0294 - sparse_categorical_accuracy: 0.9883\n",
            "Epoch 82: val_sparse_categorical_accuracy improved from 0.37383 to 0.41121, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 52ms/step - loss: 0.0294 - sparse_categorical_accuracy: 0.9883 - val_loss: 3.6018 - val_sparse_categorical_accuracy: 0.4112\n",
            "Epoch 83/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0095 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 83: val_sparse_categorical_accuracy did not improve from 0.41121\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.0095 - sparse_categorical_accuracy: 0.9977 - val_loss: 3.5285 - val_sparse_categorical_accuracy: 0.4019\n",
            "Epoch 84/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0239 - sparse_categorical_accuracy: 0.9930\n",
            "Epoch 84: val_sparse_categorical_accuracy improved from 0.41121 to 0.46729, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 52ms/step - loss: 0.0239 - sparse_categorical_accuracy: 0.9930 - val_loss: 3.1269 - val_sparse_categorical_accuracy: 0.4673\n",
            "Epoch 85/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0313 - sparse_categorical_accuracy: 0.9883\n",
            "Epoch 85: val_sparse_categorical_accuracy improved from 0.46729 to 0.48598, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 53ms/step - loss: 0.0313 - sparse_categorical_accuracy: 0.9883 - val_loss: 2.7823 - val_sparse_categorical_accuracy: 0.4860\n",
            "Epoch 86/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0167 - sparse_categorical_accuracy: 0.9953\n",
            "Epoch 86: val_sparse_categorical_accuracy did not improve from 0.48598\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.0167 - sparse_categorical_accuracy: 0.9953 - val_loss: 2.5372 - val_sparse_categorical_accuracy: 0.4860\n",
            "Epoch 87/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0114 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 87: val_sparse_categorical_accuracy did not improve from 0.48598\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.0114 - sparse_categorical_accuracy: 0.9977 - val_loss: 2.4096 - val_sparse_categorical_accuracy: 0.4860\n",
            "Epoch 88/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0147 - sparse_categorical_accuracy: 0.9953\n",
            "Epoch 88: val_sparse_categorical_accuracy improved from 0.48598 to 0.51402, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 50ms/step - loss: 0.0147 - sparse_categorical_accuracy: 0.9953 - val_loss: 2.3735 - val_sparse_categorical_accuracy: 0.5140\n",
            "Epoch 89/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0245 - sparse_categorical_accuracy: 0.9883\n",
            "Epoch 89: val_sparse_categorical_accuracy improved from 0.51402 to 0.56075, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 53ms/step - loss: 0.0245 - sparse_categorical_accuracy: 0.9883 - val_loss: 2.1150 - val_sparse_categorical_accuracy: 0.5607\n",
            "Epoch 90/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0280 - sparse_categorical_accuracy: 0.9930\n",
            "Epoch 90: val_sparse_categorical_accuracy did not improve from 0.56075\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.0280 - sparse_categorical_accuracy: 0.9930 - val_loss: 2.5028 - val_sparse_categorical_accuracy: 0.5327\n",
            "Epoch 91/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0264 - sparse_categorical_accuracy: 0.9907\n",
            "Epoch 91: val_sparse_categorical_accuracy did not improve from 0.56075\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.0264 - sparse_categorical_accuracy: 0.9907 - val_loss: 2.5749 - val_sparse_categorical_accuracy: 0.5234\n",
            "Epoch 92/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0163 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 92: val_sparse_categorical_accuracy did not improve from 0.56075\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.0163 - sparse_categorical_accuracy: 0.9977 - val_loss: 2.5133 - val_sparse_categorical_accuracy: 0.5327\n",
            "Epoch 93/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0204 - sparse_categorical_accuracy: 0.9883\n",
            "Epoch 93: val_sparse_categorical_accuracy improved from 0.56075 to 0.57009, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 55ms/step - loss: 0.0204 - sparse_categorical_accuracy: 0.9883 - val_loss: 2.1723 - val_sparse_categorical_accuracy: 0.5701\n",
            "Epoch 94/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0424 - sparse_categorical_accuracy: 0.9883\n",
            "Epoch 94: val_sparse_categorical_accuracy did not improve from 0.57009\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.0424 - sparse_categorical_accuracy: 0.9883 - val_loss: 2.4945 - val_sparse_categorical_accuracy: 0.4953\n",
            "Epoch 95/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0785 - sparse_categorical_accuracy: 0.9720\n",
            "Epoch 95: val_sparse_categorical_accuracy improved from 0.57009 to 0.63551, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 51ms/step - loss: 0.0785 - sparse_categorical_accuracy: 0.9720 - val_loss: 2.0513 - val_sparse_categorical_accuracy: 0.6355\n",
            "Epoch 96/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0649 - sparse_categorical_accuracy: 0.9743\n",
            "Epoch 96: val_sparse_categorical_accuracy did not improve from 0.63551\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.0649 - sparse_categorical_accuracy: 0.9743 - val_loss: 1.8144 - val_sparse_categorical_accuracy: 0.5701\n",
            "Epoch 97/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0329 - sparse_categorical_accuracy: 0.9883\n",
            "Epoch 97: val_sparse_categorical_accuracy did not improve from 0.63551\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.0329 - sparse_categorical_accuracy: 0.9883 - val_loss: 1.9216 - val_sparse_categorical_accuracy: 0.5888\n",
            "Epoch 98/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0463 - sparse_categorical_accuracy: 0.9836\n",
            "Epoch 98: val_sparse_categorical_accuracy did not improve from 0.63551\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.0463 - sparse_categorical_accuracy: 0.9836 - val_loss: 1.8482 - val_sparse_categorical_accuracy: 0.6262\n",
            "Epoch 99/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0134 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 99: val_sparse_categorical_accuracy did not improve from 0.63551\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.0134 - sparse_categorical_accuracy: 0.9977 - val_loss: 1.8936 - val_sparse_categorical_accuracy: 0.6168\n",
            "Epoch 100/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0212 - sparse_categorical_accuracy: 0.9907\n",
            "Epoch 100: val_sparse_categorical_accuracy improved from 0.63551 to 0.65421, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 52ms/step - loss: 0.0212 - sparse_categorical_accuracy: 0.9907 - val_loss: 1.7316 - val_sparse_categorical_accuracy: 0.6542\n",
            "Epoch 101/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0180 - sparse_categorical_accuracy: 0.9907\n",
            "Epoch 101: val_sparse_categorical_accuracy did not improve from 0.65421\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.0180 - sparse_categorical_accuracy: 0.9907 - val_loss: 1.6520 - val_sparse_categorical_accuracy: 0.6355\n",
            "Epoch 102/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0318 - sparse_categorical_accuracy: 0.9860\n",
            "Epoch 102: val_sparse_categorical_accuracy did not improve from 0.65421\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.0318 - sparse_categorical_accuracy: 0.9860 - val_loss: 1.8444 - val_sparse_categorical_accuracy: 0.6075\n",
            "Epoch 103/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0185 - sparse_categorical_accuracy: 0.9860\n",
            "Epoch 103: val_sparse_categorical_accuracy did not improve from 0.65421\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.0185 - sparse_categorical_accuracy: 0.9860 - val_loss: 1.7362 - val_sparse_categorical_accuracy: 0.6542\n",
            "Epoch 104/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0384 - sparse_categorical_accuracy: 0.9870\n",
            "Epoch 104: val_sparse_categorical_accuracy improved from 0.65421 to 0.66355, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 70ms/step - loss: 0.0472 - sparse_categorical_accuracy: 0.9860 - val_loss: 1.8129 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 105/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0730 - sparse_categorical_accuracy: 0.9870\n",
            "Epoch 105: val_sparse_categorical_accuracy did not improve from 0.66355\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.0704 - sparse_categorical_accuracy: 0.9860 - val_loss: 1.9484 - val_sparse_categorical_accuracy: 0.6262\n",
            "Epoch 106/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0478 - sparse_categorical_accuracy: 0.9870\n",
            "Epoch 106: val_sparse_categorical_accuracy did not improve from 0.66355\n",
            "7/7 [==============================] - 0s 33ms/step - loss: 0.0442 - sparse_categorical_accuracy: 0.9883 - val_loss: 1.5897 - val_sparse_categorical_accuracy: 0.6542\n",
            "Epoch 107/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0511 - sparse_categorical_accuracy: 0.9792\n",
            "Epoch 107: val_sparse_categorical_accuracy did not improve from 0.66355\n",
            "7/7 [==============================] - 0s 33ms/step - loss: 0.0465 - sparse_categorical_accuracy: 0.9813 - val_loss: 1.5743 - val_sparse_categorical_accuracy: 0.6262\n",
            "Epoch 108/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0160 - sparse_categorical_accuracy: 0.9953\n",
            "Epoch 108: val_sparse_categorical_accuracy did not improve from 0.66355\n",
            "7/7 [==============================] - 0s 33ms/step - loss: 0.0160 - sparse_categorical_accuracy: 0.9953 - val_loss: 1.8241 - val_sparse_categorical_accuracy: 0.6075\n",
            "Epoch 109/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0228 - sparse_categorical_accuracy: 0.9948\n",
            "Epoch 109: val_sparse_categorical_accuracy did not improve from 0.66355\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 0.0219 - sparse_categorical_accuracy: 0.9953 - val_loss: 1.8825 - val_sparse_categorical_accuracy: 0.5981\n",
            "Epoch 110/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0743 - sparse_categorical_accuracy: 0.9836\n",
            "Epoch 110: val_sparse_categorical_accuracy did not improve from 0.66355\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 0.0743 - sparse_categorical_accuracy: 0.9836 - val_loss: 1.7918 - val_sparse_categorical_accuracy: 0.6262\n",
            "Epoch 111/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0228 - sparse_categorical_accuracy: 0.9883\n",
            "Epoch 111: val_sparse_categorical_accuracy did not improve from 0.66355\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.0228 - sparse_categorical_accuracy: 0.9883 - val_loss: 1.6527 - val_sparse_categorical_accuracy: 0.6262\n",
            "Epoch 112/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0222 - sparse_categorical_accuracy: 0.9948\n",
            "Epoch 112: val_sparse_categorical_accuracy did not improve from 0.66355\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.0312 - sparse_categorical_accuracy: 0.9930 - val_loss: 1.6848 - val_sparse_categorical_accuracy: 0.6262\n",
            "Epoch 113/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0382 - sparse_categorical_accuracy: 0.9844\n",
            "Epoch 113: val_sparse_categorical_accuracy did not improve from 0.66355\n",
            "7/7 [==============================] - 0s 34ms/step - loss: 0.0370 - sparse_categorical_accuracy: 0.9860 - val_loss: 1.8399 - val_sparse_categorical_accuracy: 0.6542\n",
            "Epoch 114/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0191 - sparse_categorical_accuracy: 0.9937\n",
            "Epoch 114: val_sparse_categorical_accuracy did not improve from 0.66355\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.0194 - sparse_categorical_accuracy: 0.9930 - val_loss: 1.8518 - val_sparse_categorical_accuracy: 0.6449\n",
            "Epoch 115/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0132 - sparse_categorical_accuracy: 0.9953\n",
            "Epoch 115: val_sparse_categorical_accuracy did not improve from 0.66355\n",
            "7/7 [==============================] - 0s 33ms/step - loss: 0.0132 - sparse_categorical_accuracy: 0.9953 - val_loss: 1.7503 - val_sparse_categorical_accuracy: 0.6168\n",
            "Epoch 116/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0191 - sparse_categorical_accuracy: 0.9948\n",
            "Epoch 116: val_sparse_categorical_accuracy did not improve from 0.66355\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.0176 - sparse_categorical_accuracy: 0.9953 - val_loss: 1.6566 - val_sparse_categorical_accuracy: 0.6355\n",
            "Epoch 117/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0082 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 117: val_sparse_categorical_accuracy did not improve from 0.66355\n",
            "7/7 [==============================] - 0s 34ms/step - loss: 0.0145 - sparse_categorical_accuracy: 0.9977 - val_loss: 1.6918 - val_sparse_categorical_accuracy: 0.6542\n",
            "Epoch 118/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0044 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 118: val_sparse_categorical_accuracy did not improve from 0.66355\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.0044 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.7453 - val_sparse_categorical_accuracy: 0.6449\n",
            "Epoch 119/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0052 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 119: val_sparse_categorical_accuracy did not improve from 0.66355\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.0052 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.7944 - val_sparse_categorical_accuracy: 0.6449\n",
            "Epoch 120/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0150 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 120: val_sparse_categorical_accuracy did not improve from 0.66355\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.0150 - sparse_categorical_accuracy: 0.9977 - val_loss: 1.7158 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 121/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0101 - sparse_categorical_accuracy: 0.9953\n",
            "Epoch 121: val_sparse_categorical_accuracy did not improve from 0.66355\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.0101 - sparse_categorical_accuracy: 0.9953 - val_loss: 1.7972 - val_sparse_categorical_accuracy: 0.6355\n",
            "Epoch 122/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0096 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 122: val_sparse_categorical_accuracy did not improve from 0.66355\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.0096 - sparse_categorical_accuracy: 0.9977 - val_loss: 1.7832 - val_sparse_categorical_accuracy: 0.6449\n",
            "Epoch 123/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0075 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 123: val_sparse_categorical_accuracy improved from 0.66355 to 0.67290, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 53ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9977 - val_loss: 1.7424 - val_sparse_categorical_accuracy: 0.6729\n",
            "Epoch 124/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0127 - sparse_categorical_accuracy: 0.9930\n",
            "Epoch 124: val_sparse_categorical_accuracy improved from 0.67290 to 0.69159, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 51ms/step - loss: 0.0127 - sparse_categorical_accuracy: 0.9930 - val_loss: 1.6881 - val_sparse_categorical_accuracy: 0.6916\n",
            "Epoch 125/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0246 - sparse_categorical_accuracy: 0.9930\n",
            "Epoch 125: val_sparse_categorical_accuracy did not improve from 0.69159\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.0246 - sparse_categorical_accuracy: 0.9930 - val_loss: 1.5982 - val_sparse_categorical_accuracy: 0.6822\n",
            "Epoch 126/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0140 - sparse_categorical_accuracy: 0.9953\n",
            "Epoch 126: val_sparse_categorical_accuracy improved from 0.69159 to 0.71963, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 51ms/step - loss: 0.0140 - sparse_categorical_accuracy: 0.9953 - val_loss: 1.5061 - val_sparse_categorical_accuracy: 0.7196\n",
            "Epoch 127/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0281 - sparse_categorical_accuracy: 0.9907\n",
            "Epoch 127: val_sparse_categorical_accuracy did not improve from 0.71963\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.0281 - sparse_categorical_accuracy: 0.9907 - val_loss: 1.5183 - val_sparse_categorical_accuracy: 0.6822\n",
            "Epoch 128/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0149 - sparse_categorical_accuracy: 0.9930\n",
            "Epoch 128: val_sparse_categorical_accuracy did not improve from 0.71963\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.0149 - sparse_categorical_accuracy: 0.9930 - val_loss: 1.6727 - val_sparse_categorical_accuracy: 0.6449\n",
            "Epoch 129/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0129 - sparse_categorical_accuracy: 0.9930\n",
            "Epoch 129: val_sparse_categorical_accuracy did not improve from 0.71963\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.0129 - sparse_categorical_accuracy: 0.9930 - val_loss: 1.6182 - val_sparse_categorical_accuracy: 0.6729\n",
            "Epoch 130/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0118 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 130: val_sparse_categorical_accuracy did not improve from 0.71963\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.0118 - sparse_categorical_accuracy: 0.9977 - val_loss: 1.5901 - val_sparse_categorical_accuracy: 0.6822\n",
            "Epoch 131/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0089 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 131: val_sparse_categorical_accuracy did not improve from 0.71963\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.0089 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.6412 - val_sparse_categorical_accuracy: 0.6916\n",
            "Epoch 132/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0163 - sparse_categorical_accuracy: 0.9953\n",
            "Epoch 132: val_sparse_categorical_accuracy did not improve from 0.71963\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.0163 - sparse_categorical_accuracy: 0.9953 - val_loss: 1.6754 - val_sparse_categorical_accuracy: 0.6729\n",
            "Epoch 133/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0134 - sparse_categorical_accuracy: 0.9930\n",
            "Epoch 133: val_sparse_categorical_accuracy did not improve from 0.71963\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.0134 - sparse_categorical_accuracy: 0.9930 - val_loss: 1.5429 - val_sparse_categorical_accuracy: 0.6916\n",
            "Epoch 134/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0229 - sparse_categorical_accuracy: 0.9953\n",
            "Epoch 134: val_sparse_categorical_accuracy did not improve from 0.71963\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.0229 - sparse_categorical_accuracy: 0.9953 - val_loss: 1.7640 - val_sparse_categorical_accuracy: 0.6542\n",
            "Epoch 135/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0307 - sparse_categorical_accuracy: 0.9907\n",
            "Epoch 135: val_sparse_categorical_accuracy did not improve from 0.71963\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.0307 - sparse_categorical_accuracy: 0.9907 - val_loss: 1.6113 - val_sparse_categorical_accuracy: 0.6355\n",
            "Epoch 136/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0354 - sparse_categorical_accuracy: 0.9907\n",
            "Epoch 136: val_sparse_categorical_accuracy did not improve from 0.71963\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.0354 - sparse_categorical_accuracy: 0.9907 - val_loss: 1.6578 - val_sparse_categorical_accuracy: 0.6542\n",
            "Epoch 137/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0091 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 137: val_sparse_categorical_accuracy did not improve from 0.71963\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.0091 - sparse_categorical_accuracy: 0.9977 - val_loss: 1.6564 - val_sparse_categorical_accuracy: 0.6542\n",
            "Epoch 138/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0121 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 138: val_sparse_categorical_accuracy did not improve from 0.71963\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.0121 - sparse_categorical_accuracy: 0.9977 - val_loss: 1.7142 - val_sparse_categorical_accuracy: 0.6449\n",
            "Epoch 139/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0059 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 139: val_sparse_categorical_accuracy did not improve from 0.71963\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.0059 - sparse_categorical_accuracy: 0.9977 - val_loss: 1.6216 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 140/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0042 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 140: val_sparse_categorical_accuracy did not improve from 0.71963\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.0042 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.5525 - val_sparse_categorical_accuracy: 0.6822\n",
            "Epoch 141/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0073 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 141: val_sparse_categorical_accuracy did not improve from 0.71963\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9977 - val_loss: 1.6611 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 142/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0126 - sparse_categorical_accuracy: 0.9907\n",
            "Epoch 142: val_sparse_categorical_accuracy did not improve from 0.71963\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.0126 - sparse_categorical_accuracy: 0.9907 - val_loss: 1.5288 - val_sparse_categorical_accuracy: 0.6729\n",
            "Epoch 143/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0048 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 143: val_sparse_categorical_accuracy did not improve from 0.71963\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9977 - val_loss: 1.5382 - val_sparse_categorical_accuracy: 0.6542\n",
            "Epoch 144/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0061 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 144: val_sparse_categorical_accuracy did not improve from 0.71963\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.0061 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.5595 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 145/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0092 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 145: val_sparse_categorical_accuracy did not improve from 0.71963\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.0092 - sparse_categorical_accuracy: 0.9977 - val_loss: 1.6645 - val_sparse_categorical_accuracy: 0.6916\n",
            "Epoch 146/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0029 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 146: val_sparse_categorical_accuracy did not improve from 0.71963\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.0029 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.7534 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 147/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0030 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 147: val_sparse_categorical_accuracy did not improve from 0.71963\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.0030 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.6833 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 148/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0082 - sparse_categorical_accuracy: 0.9953\n",
            "Epoch 148: val_sparse_categorical_accuracy did not improve from 0.71963\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9953 - val_loss: 1.6002 - val_sparse_categorical_accuracy: 0.6822\n",
            "Epoch 149/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0035 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 149: val_sparse_categorical_accuracy did not improve from 0.71963\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.0035 - sparse_categorical_accuracy: 0.9977 - val_loss: 1.6003 - val_sparse_categorical_accuracy: 0.6822\n",
            "Epoch 150/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0026 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 150: val_sparse_categorical_accuracy did not improve from 0.71963\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.0026 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.6308 - val_sparse_categorical_accuracy: 0.6729\n",
            "Epoch 151/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0029 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 151: val_sparse_categorical_accuracy did not improve from 0.71963\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.0029 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.6027 - val_sparse_categorical_accuracy: 0.6822\n",
            "Epoch 152/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0070 - sparse_categorical_accuracy: 0.9953\n",
            "Epoch 152: val_sparse_categorical_accuracy did not improve from 0.71963\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9953 - val_loss: 1.7999 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 153/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0113 - sparse_categorical_accuracy: 0.9953\n",
            "Epoch 153: val_sparse_categorical_accuracy did not improve from 0.71963\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.0113 - sparse_categorical_accuracy: 0.9953 - val_loss: 1.9326 - val_sparse_categorical_accuracy: 0.6355\n",
            "Epoch 154/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0037 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 154: val_sparse_categorical_accuracy did not improve from 0.71963\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.0037 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.6736 - val_sparse_categorical_accuracy: 0.7009\n",
            "Epoch 155/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0080 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 155: val_sparse_categorical_accuracy did not improve from 0.71963\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9977 - val_loss: 1.6963 - val_sparse_categorical_accuracy: 0.7196\n",
            "Epoch 156/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0030 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 156: val_sparse_categorical_accuracy did not improve from 0.71963\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.0030 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.7548 - val_sparse_categorical_accuracy: 0.6916\n",
            "Epoch 157/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0112 - sparse_categorical_accuracy: 0.9953\n",
            "Epoch 157: val_sparse_categorical_accuracy did not improve from 0.71963\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.0112 - sparse_categorical_accuracy: 0.9953 - val_loss: 1.7270 - val_sparse_categorical_accuracy: 0.6916\n",
            "Epoch 158/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0136 - sparse_categorical_accuracy: 0.9953\n",
            "Epoch 158: val_sparse_categorical_accuracy did not improve from 0.71963\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.0136 - sparse_categorical_accuracy: 0.9953 - val_loss: 1.7304 - val_sparse_categorical_accuracy: 0.7103\n",
            "Epoch 159/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0552 - sparse_categorical_accuracy: 0.9883\n",
            "Epoch 159: val_sparse_categorical_accuracy did not improve from 0.71963\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.0552 - sparse_categorical_accuracy: 0.9883 - val_loss: 1.7260 - val_sparse_categorical_accuracy: 0.6449\n",
            "Epoch 160/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0147 - sparse_categorical_accuracy: 0.9930\n",
            "Epoch 160: val_sparse_categorical_accuracy did not improve from 0.71963\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.0147 - sparse_categorical_accuracy: 0.9930 - val_loss: 1.8498 - val_sparse_categorical_accuracy: 0.6168\n",
            "Epoch 161/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0226 - sparse_categorical_accuracy: 0.9907\n",
            "Epoch 161: val_sparse_categorical_accuracy did not improve from 0.71963\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.0226 - sparse_categorical_accuracy: 0.9907 - val_loss: 1.9792 - val_sparse_categorical_accuracy: 0.6168\n",
            "Epoch 162/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0418 - sparse_categorical_accuracy: 0.9813\n",
            "Epoch 162: val_sparse_categorical_accuracy did not improve from 0.71963\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.0418 - sparse_categorical_accuracy: 0.9813 - val_loss: 1.7007 - val_sparse_categorical_accuracy: 0.6916\n",
            "Epoch 163/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0131 - sparse_categorical_accuracy: 0.9930\n",
            "Epoch 163: val_sparse_categorical_accuracy did not improve from 0.71963\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.0131 - sparse_categorical_accuracy: 0.9930 - val_loss: 1.6005 - val_sparse_categorical_accuracy: 0.7196\n",
            "Epoch 164/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0552 - sparse_categorical_accuracy: 0.9860\n",
            "Epoch 164: val_sparse_categorical_accuracy did not improve from 0.71963\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.0552 - sparse_categorical_accuracy: 0.9860 - val_loss: 1.6236 - val_sparse_categorical_accuracy: 0.6916\n",
            "Epoch 165/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0212 - sparse_categorical_accuracy: 0.9930\n",
            "Epoch 165: val_sparse_categorical_accuracy did not improve from 0.71963\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.0212 - sparse_categorical_accuracy: 0.9930 - val_loss: 1.7190 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 166/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0135 - sparse_categorical_accuracy: 0.9953\n",
            "Epoch 166: val_sparse_categorical_accuracy did not improve from 0.71963\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.0135 - sparse_categorical_accuracy: 0.9953 - val_loss: 1.7398 - val_sparse_categorical_accuracy: 0.5981\n",
            "Epoch 167/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0198 - sparse_categorical_accuracy: 0.9930\n",
            "Epoch 167: val_sparse_categorical_accuracy did not improve from 0.71963\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 0.0198 - sparse_categorical_accuracy: 0.9930 - val_loss: 1.8099 - val_sparse_categorical_accuracy: 0.6355\n",
            "Epoch 168/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0052 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 168: val_sparse_categorical_accuracy did not improve from 0.71963\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 0.0064 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.8165 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 169/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0117 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 169: val_sparse_categorical_accuracy did not improve from 0.71963\n",
            "7/7 [==============================] - 0s 33ms/step - loss: 0.0106 - sparse_categorical_accuracy: 0.9977 - val_loss: 1.6664 - val_sparse_categorical_accuracy: 0.6729\n",
            "Epoch 170/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0065 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 170: val_sparse_categorical_accuracy did not improve from 0.71963\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 0.0065 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.6309 - val_sparse_categorical_accuracy: 0.6729\n",
            "Epoch 171/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0080 - sparse_categorical_accuracy: 0.9953\n",
            "Epoch 171: val_sparse_categorical_accuracy did not improve from 0.71963\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9953 - val_loss: 1.6709 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 172/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0206 - sparse_categorical_accuracy: 0.9907\n",
            "Epoch 172: val_sparse_categorical_accuracy did not improve from 0.71963\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.0206 - sparse_categorical_accuracy: 0.9907 - val_loss: 1.8044 - val_sparse_categorical_accuracy: 0.6075\n",
            "Epoch 173/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0140 - sparse_categorical_accuracy: 0.9930\n",
            "Epoch 173: val_sparse_categorical_accuracy did not improve from 0.71963\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 0.0140 - sparse_categorical_accuracy: 0.9930 - val_loss: 1.7003 - val_sparse_categorical_accuracy: 0.6542\n",
            "Epoch 174/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0111 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 174: val_sparse_categorical_accuracy did not improve from 0.71963\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 0.0101 - sparse_categorical_accuracy: 0.9977 - val_loss: 1.4288 - val_sparse_categorical_accuracy: 0.6916\n",
            "Epoch 175/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0116 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 175: val_sparse_categorical_accuracy did not improve from 0.71963\n",
            "7/7 [==============================] - 0s 33ms/step - loss: 0.0116 - sparse_categorical_accuracy: 0.9977 - val_loss: 1.6611 - val_sparse_categorical_accuracy: 0.6916\n",
            "Epoch 176/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0071 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 176: val_sparse_categorical_accuracy did not improve from 0.71963\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.0069 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.9807 - val_sparse_categorical_accuracy: 0.6449\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 606,
      "id": "1b676d1c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "1b676d1c",
        "outputId": "1aa7d24e-ebc3-478b-a620-43a91f9ffdf4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Plot model accuracy over ephocs\n",
        "plt.plot(history.history['sparse_categorical_accuracy'])\n",
        "plt.plot(history.history['val_sparse_categorical_accuracy'])\n",
        "plt.ylim(0, 1)\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 607,
      "id": "df8c9ade",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "df8c9ade",
        "outputId": "43d15c5b-4335-4553-ca2d-4ca03eb9f077"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7a51e6b4b970>"
            ]
          },
          "metadata": {},
          "execution_count": 607
        }
      ],
      "source": [
        "model.load_weights(checkpoint_path) #to load model with highest accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 608,
      "id": "2f08c66c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f08c66c",
        "outputId": "077d6ceb-4d50-4143-ab70-581f3f6c8493"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 8ms/step - loss: 1.5061 - sparse_categorical_accuracy: 0.7196\n",
            "Pre-training accuracy: 71.9626%\n"
          ]
        }
      ],
      "source": [
        "# Calculate pre-training accuracy\n",
        "score = model.evaluate(X_test_scalled, y_test, verbose=1)\n",
        "accuracy = 100*score[1]\n",
        "\n",
        "print(\"Pre-training accuracy: %.4f%%\" % accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 609,
      "id": "1bdfcfc8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bdfcfc8",
        "outputId": "9c735834-a48b-4756-bc03-be4d29b4db65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy:  1.0\n",
            "Testing Accuracy:  0.7196261882781982\n"
          ]
        }
      ],
      "source": [
        "# Evaluating the model on the training and testing set\n",
        "score = model.evaluate(X_train_scalled, y_train, verbose=0)\n",
        "print(\"Training Accuracy: \", score[1])\n",
        "\n",
        "score = model.evaluate(X_test_scalled, y_test, verbose=0)\n",
        "print(\"Testing Accuracy: \", score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 610,
      "id": "eaac1550",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaac1550",
        "outputId": "025d01bb-4aa4-460e-d7e6-f5ded90b13b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 1s 7ms/step\n"
          ]
        }
      ],
      "source": [
        "#Get predictions from model\n",
        "y_test_predictions = model.predict(X_test_scalled) # it will give the prediction data of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 611,
      "id": "8a9df249",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a9df249",
        "outputId": "6a7af32b-64a0-4730-9677-a67dd7fd3e89"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(107, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 611
        }
      ],
      "source": [
        "y_test_predictions.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 612,
      "id": "dda064ae",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dda064ae",
        "outputId": "4f663dac-71f5-4537-8458-4dbd2d65c29a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.04617669e-04, 1.34714739e-07, 9.99884844e-01, 7.11308417e-08,\n",
              "        1.50825963e-06, 5.38218046e-07, 8.20214700e-06],\n",
              "       [9.91432786e-01, 8.47383944e-06, 8.50941148e-03, 3.18046204e-07,\n",
              "        2.99623680e-05, 1.19612132e-05, 7.04438708e-06],\n",
              "       [2.31321639e-04, 1.78201834e-03, 1.08241975e-05, 2.81646226e-05,\n",
              "        9.90811706e-01, 5.56278292e-06, 7.13036442e-03],\n",
              "       [1.35476364e-06, 1.36293427e-04, 6.54656560e-06, 9.99755085e-01,\n",
              "        4.81133138e-05, 2.17504148e-05, 3.07893497e-05],\n",
              "       [2.80651398e-06, 1.38773900e-02, 1.48457571e-06, 2.34336085e-06,\n",
              "        2.86643467e-06, 9.86112654e-01, 5.19623427e-07],\n",
              "       [3.64038572e-02, 5.05324686e-04, 3.51706913e-05, 4.60756928e-06,\n",
              "        9.62515652e-01, 3.81562904e-06, 5.31585247e-04],\n",
              "       [5.96575010e-05, 5.78365982e-01, 2.38547276e-04, 7.93908112e-05,\n",
              "        4.29301173e-04, 4.20611143e-01, 2.16055458e-04],\n",
              "       [9.99339998e-01, 7.47800641e-06, 1.01737511e-04, 3.39258435e-07,\n",
              "        5.47191710e-04, 1.35331936e-06, 1.85987403e-06],\n",
              "       [2.29962519e-04, 5.37689663e-02, 1.17683318e-03, 2.85843194e-01,\n",
              "        7.06567720e-04, 6.57817483e-01, 4.57010057e-04],\n",
              "       [4.59477233e-05, 1.00677884e-04, 7.48685608e-03, 9.66366827e-01,\n",
              "        2.47346121e-03, 1.83449243e-04, 2.33428106e-02],\n",
              "       [1.07677625e-02, 7.37800360e-01, 5.54723490e-04, 7.37986702e-05,\n",
              "        2.46353112e-02, 2.24826187e-01, 1.34185166e-03],\n",
              "       [8.88745487e-01, 7.67634809e-02, 4.12959256e-04, 1.24184025e-05,\n",
              "        1.64883938e-02, 1.73077658e-02, 2.69576296e-04],\n",
              "       [1.34264294e-04, 3.41445476e-01, 7.07718482e-06, 3.77045950e-07,\n",
              "        2.66414499e-05, 6.58384442e-01, 1.79150993e-06],\n",
              "       [5.05878450e-03, 4.09009635e-01, 1.02786999e-03, 7.21957895e-06,\n",
              "        1.07864347e-04, 5.84454536e-01, 3.34152923e-04],\n",
              "       [9.80647630e-04, 9.93074894e-01, 8.10365873e-06, 7.06867650e-06,\n",
              "        4.48922720e-03, 1.59637188e-04, 1.28043105e-03],\n",
              "       [6.71705566e-05, 9.97797370e-01, 1.06673233e-05, 2.16015178e-06,\n",
              "        1.94523072e-05, 2.05311202e-03, 5.00960414e-05],\n",
              "       [3.54608983e-06, 1.68290589e-05, 8.02129041e-04, 9.98207211e-01,\n",
              "        4.08968539e-04, 7.08156949e-05, 4.90476144e-04],\n",
              "       [9.20423269e-01, 5.71429046e-05, 5.35600148e-02, 5.03472766e-05,\n",
              "        2.54670102e-02, 3.26382287e-05, 4.09555534e-04],\n",
              "       [2.41682355e-05, 3.48985450e-05, 3.54683376e-03, 9.92799878e-01,\n",
              "        7.03491736e-04, 7.12763722e-05, 2.81946990e-03],\n",
              "       [9.99512196e-01, 2.88506817e-06, 4.68928367e-04, 1.01794576e-07,\n",
              "        1.20121113e-05, 2.65921585e-06, 1.28405873e-06],\n",
              "       [6.07863709e-04, 1.08754864e-06, 9.99344289e-01, 5.68263943e-07,\n",
              "        4.16313560e-06, 2.81259290e-05, 1.37776387e-05],\n",
              "       [1.42882473e-03, 3.76315220e-05, 6.45468950e-01, 5.50005570e-05,\n",
              "        2.30140904e-05, 2.61115529e-05, 3.52960467e-01],\n",
              "       [2.72161025e-03, 1.24348583e-06, 9.97197628e-01, 5.59308774e-07,\n",
              "        4.70432860e-06, 6.22319276e-05, 1.20471705e-05],\n",
              "       [3.81677004e-04, 1.42185260e-02, 1.05503801e-04, 3.60992840e-06,\n",
              "        6.63904182e-04, 9.84616220e-01, 1.05853078e-05],\n",
              "       [5.34729088e-06, 1.69368097e-04, 6.51673254e-05, 9.98665094e-01,\n",
              "        1.64607438e-04, 8.71299126e-04, 5.90907803e-05],\n",
              "       [3.56287770e-02, 2.09033515e-05, 9.64044392e-01, 5.86031183e-06,\n",
              "        2.70976270e-05, 5.86794340e-05, 2.14325031e-04],\n",
              "       [5.35512388e-01, 1.31714278e-05, 4.64245349e-01, 2.53405642e-06,\n",
              "        5.00025199e-05, 1.65028236e-04, 1.15427501e-05],\n",
              "       [1.23977545e-03, 3.35973050e-06, 9.95684743e-01, 2.70193209e-06,\n",
              "        2.12928583e-03, 3.89759552e-05, 9.01191961e-04],\n",
              "       [3.22159642e-04, 1.24998076e-06, 9.99601543e-01, 3.98499594e-07,\n",
              "        3.52118172e-06, 5.50516634e-05, 1.60957443e-05],\n",
              "       [2.24725882e-05, 5.86033193e-03, 1.14562041e-04, 9.86922026e-01,\n",
              "        4.07908199e-04, 6.56592753e-03, 1.06830114e-04],\n",
              "       [9.29926231e-04, 2.08626188e-05, 2.60811865e-01, 6.91593232e-05,\n",
              "        1.87013566e-01, 2.12540617e-05, 5.51133394e-01],\n",
              "       [1.64318965e-06, 9.95239097e-05, 2.47866737e-05, 8.00767793e-07,\n",
              "        6.36098639e-06, 9.99865651e-01, 1.27856811e-06],\n",
              "       [2.66054940e-07, 1.84951421e-06, 2.00016780e-06, 2.71820022e-06,\n",
              "        9.99687910e-01, 1.53565134e-06, 3.03715264e-04],\n",
              "       [1.18553053e-05, 1.44940955e-07, 9.99821961e-01, 1.18365585e-06,\n",
              "        7.96883160e-06, 1.07974813e-06, 1.55747475e-04],\n",
              "       [2.65245518e-07, 5.18555971e-05, 8.43159614e-06, 2.83735801e-07,\n",
              "        9.00762913e-08, 9.99938607e-01, 4.82741541e-07],\n",
              "       [9.69555549e-06, 9.29998620e-08, 9.99971747e-01, 9.77853460e-08,\n",
              "        5.15732836e-07, 3.51361990e-07, 1.75383284e-05],\n",
              "       [1.37110328e-04, 1.34923425e-07, 9.99852419e-01, 7.87508938e-08,\n",
              "        1.06672201e-06, 1.35375899e-06, 7.88212128e-06],\n",
              "       [9.96526182e-01, 3.11729964e-05, 3.16786091e-03, 6.23478002e-07,\n",
              "        2.07914432e-04, 6.54039031e-05, 9.13622443e-07],\n",
              "       [1.37214811e-05, 1.09747340e-07, 9.99973774e-01, 1.42853054e-07,\n",
              "        6.49512913e-07, 1.32557238e-06, 1.02436852e-05],\n",
              "       [1.57101117e-02, 1.90358013e-02, 7.31275260e-01, 3.19149606e-02,\n",
              "        1.50180403e-02, 1.57675400e-01, 2.93704737e-02],\n",
              "       [2.85111837e-05, 8.38875592e-01, 1.09123845e-04, 5.00588329e-04,\n",
              "        5.07871919e-05, 1.60373896e-01, 6.14921373e-05],\n",
              "       [9.99738395e-01, 1.61653461e-05, 6.75234041e-05, 1.64867700e-07,\n",
              "        1.73536144e-04, 3.85058502e-06, 2.56656335e-07],\n",
              "       [3.99719255e-07, 2.92932848e-04, 1.15411717e-06, 1.57232506e-07,\n",
              "        3.04483308e-07, 9.99704897e-01, 1.50396318e-07],\n",
              "       [9.82529640e-01, 2.23537372e-05, 1.63646825e-02, 3.56399983e-06,\n",
              "        1.02188147e-03, 1.75720579e-05, 4.03263912e-05],\n",
              "       [1.77535154e-02, 4.78833419e-04, 4.34763533e-05, 1.91445406e-06,\n",
              "        9.81699347e-01, 1.00222351e-05, 1.29298332e-05],\n",
              "       [1.72737055e-05, 3.71631904e-05, 3.42380663e-04, 9.99245644e-01,\n",
              "        6.91802124e-05, 8.99961378e-05, 1.98396869e-04],\n",
              "       [1.05692167e-03, 3.09839993e-06, 9.98826563e-01, 2.32077559e-06,\n",
              "        9.05062552e-06, 5.56924570e-05, 4.63744509e-05],\n",
              "       [1.96418914e-05, 6.60512745e-01, 8.27096846e-06, 2.06332561e-06,\n",
              "        9.18497426e-06, 3.39445561e-01, 2.66553661e-06],\n",
              "       [7.15409806e-06, 1.62546465e-04, 4.14168499e-05, 1.28811237e-03,\n",
              "        9.95277882e-01, 1.34385436e-05, 3.20950849e-03],\n",
              "       [5.46855063e-06, 5.75289596e-04, 5.38119930e-05, 2.73634796e-04,\n",
              "        1.24636044e-05, 9.99075413e-01, 3.84661553e-06],\n",
              "       [2.24194460e-04, 4.96375300e-02, 2.86616068e-05, 1.25112856e-04,\n",
              "        9.44527566e-01, 3.77544056e-04, 5.07942494e-03],\n",
              "       [1.08662760e-03, 9.81991112e-01, 2.78291809e-05, 2.74759759e-06,\n",
              "        2.12456638e-04, 1.65955108e-02, 8.38428823e-05],\n",
              "       [4.10859457e-06, 1.10426401e-04, 4.20209981e-05, 9.99589980e-01,\n",
              "        4.33140158e-05, 1.56833412e-04, 5.32509912e-05],\n",
              "       [5.52107811e-01, 2.33329221e-04, 4.39846605e-01, 1.32960804e-05,\n",
              "        5.24554355e-03, 5.62549467e-05, 2.49714614e-03],\n",
              "       [9.79937977e-05, 8.76497666e-07, 9.99762237e-01, 2.00937166e-06,\n",
              "        3.12215961e-05, 1.04434530e-05, 9.51018374e-05],\n",
              "       [9.99443471e-01, 4.64364075e-06, 4.87319572e-04, 1.03618572e-06,\n",
              "        5.24341231e-05, 3.70632756e-06, 7.40183668e-06],\n",
              "       [1.53764558e-05, 1.08072978e-04, 2.64661799e-06, 1.37066681e-05,\n",
              "        8.68723869e-01, 1.93342839e-06, 1.31134361e-01],\n",
              "       [4.73254971e-07, 1.51240474e-05, 3.39403050e-05, 9.99719203e-01,\n",
              "        1.02523984e-04, 5.80264023e-05, 7.06481369e-05],\n",
              "       [9.43248808e-01, 3.37618185e-05, 5.23383804e-02, 2.14554493e-05,\n",
              "        4.10559587e-03, 7.74212240e-05, 1.74637884e-04],\n",
              "       [2.18027196e-07, 2.84780363e-05, 9.22033053e-07, 2.90872748e-07,\n",
              "        6.16705108e-07, 9.99969363e-01, 7.54266907e-08],\n",
              "       [1.16280091e-06, 9.99814808e-01, 9.36179617e-07, 1.36470326e-05,\n",
              "        9.89345949e-07, 1.59676696e-04, 8.81475080e-06],\n",
              "       [2.15652122e-04, 2.48208238e-07, 9.99742568e-01, 3.45417078e-07,\n",
              "        1.49660036e-06, 2.69707880e-06, 3.69528534e-05],\n",
              "       [2.17485886e-05, 1.08709901e-05, 8.53115125e-06, 4.71343083e-06,\n",
              "        9.84408319e-01, 6.49927870e-07, 1.55450841e-02],\n",
              "       [9.93693233e-01, 3.77911856e-05, 5.13015024e-04, 5.66690824e-06,\n",
              "        5.39064175e-03, 5.23937933e-06, 3.54425400e-04],\n",
              "       [9.99935508e-01, 2.77173444e-06, 2.90819407e-05, 6.47608687e-08,\n",
              "        3.14617246e-05, 6.30531645e-07, 4.19904438e-07],\n",
              "       [4.61950060e-03, 8.50625440e-07, 9.95313168e-01, 4.18728973e-07,\n",
              "        1.64271696e-05, 3.57990248e-05, 1.37401348e-05],\n",
              "       [1.02143422e-05, 1.02234635e-05, 3.13605378e-05, 5.05740627e-06,\n",
              "        2.37383802e-06, 2.91842156e-07, 9.99940515e-01],\n",
              "       [9.33025479e-01, 1.35458813e-05, 6.68703839e-02, 2.00455816e-06,\n",
              "        2.24557170e-05, 4.68652870e-05, 1.91999552e-05],\n",
              "       [2.20772810e-04, 7.02583056e-05, 2.08100482e-05, 8.61090030e-06,\n",
              "        9.13526297e-01, 1.21606922e-06, 8.61519650e-02],\n",
              "       [9.98554051e-01, 1.04143437e-05, 4.16469265e-04, 9.85164661e-07,\n",
              "        1.01256766e-03, 3.24552184e-06, 2.30620481e-06],\n",
              "       [9.28707063e-01, 2.18457833e-04, 3.20101099e-04, 1.42757435e-05,\n",
              "        7.00136498e-02, 1.55257276e-05, 7.10907800e-04],\n",
              "       [2.16718792e-04, 4.06403214e-01, 3.27371563e-05, 2.75393177e-06,\n",
              "        1.94586057e-04, 5.93142867e-01, 7.11217263e-06],\n",
              "       [4.42044635e-04, 3.72225828e-02, 8.46468727e-04, 1.59958836e-05,\n",
              "        3.90252186e-04, 9.60987747e-01, 9.48589659e-05],\n",
              "       [3.35987170e-05, 8.44139691e-08, 9.99948382e-01, 1.18324280e-07,\n",
              "        2.14379929e-06, 5.43461283e-07, 1.51210234e-05],\n",
              "       [2.11005762e-01, 1.62630808e-04, 2.50057026e-04, 9.29025737e-06,\n",
              "        7.88457394e-01, 7.21662582e-06, 1.07604807e-04],\n",
              "       [1.17881600e-05, 6.97590709e-02, 1.55555499e-05, 2.69934662e-06,\n",
              "        3.28638157e-06, 9.30203438e-01, 4.12751342e-06],\n",
              "       [1.65934991e-02, 8.00858288e-06, 9.82950449e-01, 1.37959182e-06,\n",
              "        3.82896862e-04, 4.37936324e-05, 1.99557962e-05],\n",
              "       [3.82446615e-06, 6.70309892e-05, 3.65024134e-05, 9.99627948e-01,\n",
              "        1.01872953e-04, 1.13136004e-04, 4.96413413e-05],\n",
              "       [2.27701330e-05, 9.31575662e-04, 1.97253030e-04, 9.87891436e-01,\n",
              "        1.94512040e-03, 8.85719620e-03, 1.54586945e-04],\n",
              "       [9.10669587e-06, 3.09112038e-05, 5.18690213e-05, 3.58466859e-05,\n",
              "        6.10778952e-05, 9.10909705e-07, 9.99810278e-01],\n",
              "       [7.68425962e-05, 3.28139984e-03, 8.72265355e-06, 4.03635786e-05,\n",
              "        3.18144917e-01, 6.84308134e-06, 6.78440869e-01],\n",
              "       [4.67942983e-01, 5.86768787e-04, 7.04860955e-04, 1.04779456e-05,\n",
              "        5.30605972e-01, 1.32870646e-05, 1.35651033e-04],\n",
              "       [2.56086696e-05, 4.77078836e-03, 2.40342692e-04, 7.19561517e-01,\n",
              "        1.24603510e-03, 2.73930818e-01, 2.24856209e-04],\n",
              "       [1.40949624e-06, 8.08155710e-06, 2.64399915e-07, 7.91712012e-07,\n",
              "        9.99943137e-01, 4.90013463e-07, 4.58686118e-05],\n",
              "       [5.87627574e-06, 3.77032165e-08, 9.99981642e-01, 1.26722171e-07,\n",
              "        1.52551411e-06, 2.04856448e-07, 1.05233876e-05],\n",
              "       [2.06601653e-05, 6.08150661e-03, 3.54811113e-04, 9.76275265e-01,\n",
              "        6.88673276e-03, 3.39399488e-03, 6.98699849e-03],\n",
              "       [9.98976469e-01, 1.74954421e-05, 2.94060184e-04, 1.86542593e-06,\n",
              "        6.91111083e-04, 4.20989227e-06, 1.47803739e-05],\n",
              "       [1.07452208e-04, 8.83417726e-01, 1.88060330e-05, 1.13929948e-03,\n",
              "        1.10975035e-01, 2.11742194e-03, 2.22432869e-03],\n",
              "       [6.01028205e-06, 6.04374009e-06, 2.40499692e-04, 1.36746885e-05,\n",
              "        9.99080658e-01, 2.73630612e-05, 6.25801913e-04],\n",
              "       [2.23854986e-05, 3.79242469e-04, 3.87907348e-04, 1.10233855e-02,\n",
              "        4.97449905e-01, 4.90044147e-01, 6.93042064e-04],\n",
              "       [3.87521868e-06, 6.52261747e-08, 9.99965191e-01, 1.72430560e-07,\n",
              "        6.97495807e-07, 3.85665032e-07, 2.96986382e-05],\n",
              "       [9.99622226e-01, 7.89323622e-06, 1.59735806e-04, 4.41143328e-07,\n",
              "        2.03987860e-04, 1.92322750e-06, 3.87258979e-06],\n",
              "       [1.21070800e-04, 3.75121161e-02, 4.55422967e-04, 4.94330116e-02,\n",
              "        2.07677687e-04, 9.12105501e-01, 1.65169942e-04],\n",
              "       [4.20880569e-05, 4.90588360e-02, 2.13401057e-04, 2.49829353e-03,\n",
              "        9.57400480e-05, 9.48053122e-01, 3.85417734e-05],\n",
              "       [7.49933463e-07, 5.20093499e-06, 4.69363076e-05, 7.30313423e-06,\n",
              "        4.77826643e-06, 1.85497683e-07, 9.99934793e-01],\n",
              "       [7.10128129e-01, 9.75263756e-05, 1.14639627e-03, 8.49638400e-06,\n",
              "        2.88578749e-01, 2.05109482e-05, 2.01314651e-05],\n",
              "       [1.21843959e-05, 1.64173325e-05, 4.36355804e-05, 5.86790475e-06,\n",
              "        4.90611546e-06, 1.56076524e-07, 9.99916911e-01],\n",
              "       [2.68569420e-04, 4.99834016e-07, 9.99698281e-01, 4.94010749e-07,\n",
              "        2.37854670e-06, 4.53880693e-06, 2.52674345e-05],\n",
              "       [2.65572686e-04, 2.44485254e-05, 6.44848842e-05, 1.37055201e-06,\n",
              "        9.99615312e-01, 1.78093542e-05, 1.10416295e-05],\n",
              "       [9.67315316e-01, 1.87354768e-03, 3.42216430e-04, 1.17975460e-05,\n",
              "        2.86411569e-02, 3.96134448e-04, 1.41973468e-03],\n",
              "       [9.97609973e-01, 1.05862791e-05, 2.31706817e-03, 1.58856062e-06,\n",
              "        4.38995012e-05, 1.06521866e-05, 6.22848211e-06],\n",
              "       [2.14217562e-06, 3.22783599e-05, 6.14139162e-06, 1.49693296e-05,\n",
              "        9.99579966e-01, 1.16196483e-04, 2.48356257e-04],\n",
              "       [2.85772257e-03, 1.91592744e-06, 9.97067153e-01, 1.66474695e-06,\n",
              "        5.58576039e-06, 1.71180363e-05, 4.88422884e-05],\n",
              "       [3.21623556e-05, 3.46626295e-03, 2.31981976e-05, 1.64497337e-07,\n",
              "        1.95706434e-05, 9.96457994e-01, 5.71793692e-07],\n",
              "       [8.91329430e-04, 5.26989606e-06, 6.52604550e-03, 8.37572043e-06,\n",
              "        9.92464662e-01, 2.91445303e-05, 7.52877240e-05],\n",
              "       [5.40253415e-04, 8.64051878e-01, 2.84654016e-05, 2.21823802e-06,\n",
              "        5.31556038e-03, 1.30030572e-01, 3.10743453e-05],\n",
              "       [3.16033174e-06, 1.14251779e-04, 2.64968439e-05, 9.99667764e-01,\n",
              "        3.59481419e-05, 1.10898211e-04, 4.16093244e-05]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 612
        }
      ],
      "source": [
        "y_test_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 613,
      "id": "996eb306",
      "metadata": {
        "id": "996eb306"
      },
      "outputs": [],
      "source": [
        "y_test_predictions=np.argmax(y_test_predictions,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 614,
      "id": "5f9002eb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f9002eb",
        "outputId": "3ca9b8e8-375f-40f5-c00a-dd5469852dc4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 0, 4, 3, 5, 4, 1, 0, 5, 3, 1, 0, 5, 5, 1, 1, 3, 0, 3, 0, 2, 2,\n",
              "       2, 5, 3, 2, 0, 2, 2, 3, 6, 5, 4, 2, 5, 2, 2, 0, 2, 2, 1, 0, 5, 0,\n",
              "       4, 3, 2, 1, 4, 5, 4, 1, 3, 0, 2, 0, 4, 3, 0, 5, 1, 2, 4, 0, 0, 2,\n",
              "       6, 0, 4, 0, 0, 5, 5, 2, 4, 5, 2, 3, 3, 6, 6, 4, 3, 4, 2, 3, 0, 1,\n",
              "       4, 4, 2, 0, 5, 5, 6, 0, 6, 2, 4, 0, 0, 4, 2, 5, 4, 1, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 614
        }
      ],
      "source": [
        "y_test_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 615,
      "id": "2a98a885",
      "metadata": {
        "id": "2a98a885"
      },
      "outputs": [],
      "source": [
        "# df.replace({ 'happyness': 0, 'neutral': 1,'anger': 2,'sadness': 3, 'fear':4,'boredom':5,'disgust':6}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 616,
      "id": "d0b8e93d",
      "metadata": {
        "id": "d0b8e93d"
      },
      "outputs": [],
      "source": [
        "emotions={\n",
        " 0: 'happyness',\n",
        " 1: 'neutral',\n",
        " 2: 'anger',\n",
        " 3: 'sadness',\n",
        " 4: 'fear',\n",
        " 5: 'boredom',\n",
        " 6: 'disgust',\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 617,
      "id": "a32e6964",
      "metadata": {
        "id": "a32e6964"
      },
      "outputs": [],
      "source": [
        "label=[]\n",
        "for i in y_test_predictions:\n",
        "    label1=emotions[i]\n",
        "    label.append(label1)\n",
        "label\n",
        "y_pred_acc=np.array(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 618,
      "id": "c92b0963",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c92b0963",
        "outputId": "c0d11147-3a62-492d-d546-af0a0fad5046"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['anger', 'happyness', 'fear', 'sadness', 'boredom', 'fear',\n",
              "       'neutral', 'happyness', 'boredom', 'sadness', 'neutral',\n",
              "       'happyness', 'boredom', 'boredom', 'neutral', 'neutral', 'sadness',\n",
              "       'happyness', 'sadness', 'happyness', 'anger', 'anger', 'anger',\n",
              "       'boredom', 'sadness', 'anger', 'happyness', 'anger', 'anger',\n",
              "       'sadness', 'disgust', 'boredom', 'fear', 'anger', 'boredom',\n",
              "       'anger', 'anger', 'happyness', 'anger', 'anger', 'neutral',\n",
              "       'happyness', 'boredom', 'happyness', 'fear', 'sadness', 'anger',\n",
              "       'neutral', 'fear', 'boredom', 'fear', 'neutral', 'sadness',\n",
              "       'happyness', 'anger', 'happyness', 'fear', 'sadness', 'happyness',\n",
              "       'boredom', 'neutral', 'anger', 'fear', 'happyness', 'happyness',\n",
              "       'anger', 'disgust', 'happyness', 'fear', 'happyness', 'happyness',\n",
              "       'boredom', 'boredom', 'anger', 'fear', 'boredom', 'anger',\n",
              "       'sadness', 'sadness', 'disgust', 'disgust', 'fear', 'sadness',\n",
              "       'fear', 'anger', 'sadness', 'happyness', 'neutral', 'fear', 'fear',\n",
              "       'anger', 'happyness', 'boredom', 'boredom', 'disgust', 'happyness',\n",
              "       'disgust', 'anger', 'fear', 'happyness', 'happyness', 'fear',\n",
              "       'anger', 'boredom', 'fear', 'neutral', 'sadness'], dtype='<U9')"
            ]
          },
          "metadata": {},
          "execution_count": 618
        }
      ],
      "source": [
        "y_pred_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 619,
      "id": "59bdabc1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59bdabc1",
        "outputId": "53cd34e2-9ab0-40a6-f909-c981518e0b51"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      2\n",
              "1      0\n",
              "2      1\n",
              "3      3\n",
              "4      5\n",
              "      ..\n",
              "102    2\n",
              "103    5\n",
              "104    4\n",
              "105    5\n",
              "106    3\n",
              "Name: 0.1, Length: 107, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 619
        }
      ],
      "source": [
        "y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 620,
      "id": "0dec7231",
      "metadata": {
        "id": "0dec7231"
      },
      "outputs": [],
      "source": [
        "emotion={\n",
        " 0: 'happyness',\n",
        " 1: 'neutral',\n",
        " 2: 'anger',\n",
        " 3: 'sadness',\n",
        " 4: 'fear',\n",
        " 5: 'boredom',\n",
        " 6: 'disgust',\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 621,
      "id": "06e8caee",
      "metadata": {
        "id": "06e8caee"
      },
      "outputs": [],
      "source": [
        "label_test=[]\n",
        "for i in y_test:\n",
        "    label_test.append(emotion[i])\n",
        "label_test\n",
        "y_true_accu=np.array(label_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 622,
      "id": "9562d2b0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9562d2b0",
        "outputId": "367e2f43-cad1-4629-f3fe-218adb1897c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['anger', 'happyness', 'neutral', 'sadness', 'boredom', 'happyness',\n",
              "       'neutral', 'anger', 'boredom', 'sadness', 'neutral', 'happyness',\n",
              "       'boredom', 'happyness', 'boredom', 'neutral', 'sadness', 'anger',\n",
              "       'sadness', 'anger', 'anger', 'disgust', 'anger', 'neutral',\n",
              "       'sadness', 'anger', 'happyness', 'happyness', 'anger', 'neutral',\n",
              "       'fear', 'boredom', 'fear', 'anger', 'boredom', 'anger', 'anger',\n",
              "       'happyness', 'anger', 'neutral', 'neutral', 'fear', 'boredom',\n",
              "       'anger', 'happyness', 'sadness', 'anger', 'neutral', 'fear',\n",
              "       'boredom', 'neutral', 'boredom', 'sadness', 'fear', 'anger',\n",
              "       'happyness', 'fear', 'sadness', 'anger', 'boredom', 'neutral',\n",
              "       'anger', 'fear', 'happyness', 'happyness', 'anger', 'disgust',\n",
              "       'anger', 'fear', 'anger', 'disgust', 'boredom', 'boredom', 'anger',\n",
              "       'fear', 'neutral', 'anger', 'sadness', 'sadness', 'disgust',\n",
              "       'disgust', 'fear', 'sadness', 'fear', 'anger', 'disgust',\n",
              "       'happyness', 'neutral', 'disgust', 'fear', 'anger', 'happyness',\n",
              "       'boredom', 'neutral', 'disgust', 'happyness', 'disgust', 'anger',\n",
              "       'fear', 'boredom', 'happyness', 'neutral', 'anger', 'boredom',\n",
              "       'fear', 'boredom', 'sadness'], dtype='<U9')"
            ]
          },
          "metadata": {},
          "execution_count": 622
        }
      ],
      "source": [
        "y_true_accu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 623,
      "id": "8def2194",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8def2194",
        "outputId": "c16bfaea-d7d0-4746-9764-41b637b418d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 71.96%\n"
          ]
        }
      ],
      "source": [
        "#DataFlair - Calculate the accuracy of our model\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy=accuracy_score(y_true=y_true_accu, y_pred=y_pred_acc)\n",
        "\n",
        "#DataFlair - Print the accuracy\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 624,
      "id": "0397dc13",
      "metadata": {
        "id": "0397dc13"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm=confusion_matrix(y_true=y_true_accu, y_pred=y_pred_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 625,
      "id": "7cee98a1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cee98a1",
        "outputId": "3f53b4b4-6be7-4ab5-9314-33a1cb0826d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.86      0.73      0.79        26\n",
            "     boredom       0.75      0.75      0.75        16\n",
            "     disgust       0.83      0.56      0.67         9\n",
            "        fear       0.65      0.79      0.71        14\n",
            "   happyness       0.50      0.73      0.59        15\n",
            "     neutral       0.70      0.47      0.56        15\n",
            "     sadness       0.86      1.00      0.92        12\n",
            "\n",
            "    accuracy                           0.72       107\n",
            "   macro avg       0.74      0.72      0.71       107\n",
            "weighted avg       0.74      0.72      0.72       107\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_true_accu,y_pred_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 625,
      "id": "73b3090a",
      "metadata": {
        "id": "73b3090a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 625,
      "id": "4537d18f",
      "metadata": {
        "id": "4537d18f"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}