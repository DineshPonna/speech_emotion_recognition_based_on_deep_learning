{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "e1f95dfd",
      "metadata": {
        "id": "e1f95dfd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import seaborn as sns\n",
        "import librosa\n",
        "import librosa.display\n",
        "import IPython.display as pld\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow.keras as keras\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "c899a87f",
      "metadata": {
        "id": "c899a87f"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/DATASETS/EmoDB Dataset/max_feature_whole_speech_emodb_csvfile.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "e63e29bc",
      "metadata": {
        "id": "e63e29bc"
      },
      "outputs": [],
      "source": [
        "df=df.fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "3db85b78",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "3db85b78",
        "outputId": "66bd00dc-5eb3-42e7-a387-86cbc8bae858"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        filename          1          2          3          4          5  \\\n",
              "0    03a01Fa.wav -482.45233  62.835957  -0.348998  26.264595   2.978607   \n",
              "1    03a01Nc.wav -469.48477  88.400730  -7.127512  29.156132   5.335554   \n",
              "2    03a01Wa.wav -434.88647  41.972150 -29.416862  18.537344  -4.156565   \n",
              "3    03a02Fc.wav -454.89886  45.067265  -0.193278  15.111545   3.080835   \n",
              "4    03a02Nc.wav -447.12630  86.114920   4.772520  38.097256   8.324276   \n",
              "..           ...        ...        ...        ...        ...        ...   \n",
              "530  16b10Lb.wav -418.62490  57.015880   6.383415  47.618423  -8.051490   \n",
              "531  16b10Tb.wav -427.36716  51.473750   4.835125  40.900140   6.937289   \n",
              "532  16b10Td.wav -467.15588  52.217026  10.470471  47.414780   8.690019   \n",
              "533  16b10Wa.wav -526.19570  11.317784 -18.942173  29.540787 -28.057306   \n",
              "534  16b10Wb.wav -437.97220   5.289146 -22.667547  25.394840 -28.545520   \n",
              "\n",
              "             6          7         8          9  ...       251       252  \\\n",
              "0     6.900927 -13.006243  0.273391  -9.196591  ...  0.675823  0.684034   \n",
              "1     7.147227  -6.727572 -8.307674  -3.364513  ...  0.635522  0.544438   \n",
              "2     5.257353 -11.410935 -8.983023 -11.285996  ...  0.648380  0.675295   \n",
              "3     4.204241 -10.440731 -6.615343 -16.249382  ...  0.575784  0.523305   \n",
              "4     8.538317  -4.507682 -7.680664  -7.317249  ...  0.615263  0.566964   \n",
              "..         ...        ...       ...        ...  ...       ...       ...   \n",
              "530   4.213936 -15.029120 -2.448467 -10.805821  ...  0.569263  0.551809   \n",
              "531  13.700687  -8.331753 -0.583414  -6.279562  ...  0.638155  0.574542   \n",
              "532  15.601270  -2.032935  4.985774  -7.432734  ...  0.523647  0.509723   \n",
              "533   1.299599 -16.251814 -7.512440 -23.191568  ...  0.528861  0.501070   \n",
              "534   0.428451 -11.650926 -8.022680 -18.337156  ...  0.495079  0.539387   \n",
              "\n",
              "          253       254       255       256       257       258       259  \\\n",
              "0    0.627376 -0.001574  0.012645 -0.027069  0.019313 -0.002252 -0.006220   \n",
              "1    0.532856 -0.018488  0.011973 -0.011038  0.079758 -0.021044 -0.019445   \n",
              "2    0.560000 -0.010576 -0.000228  0.011102 -0.074188  0.012116 -0.000779   \n",
              "3    0.423375  0.009395 -0.025547 -0.035554 -0.025885  0.011198 -0.000163   \n",
              "4    0.605103 -0.008389 -0.051995 -0.056544 -0.020014  0.013964  0.008349   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "530  0.576764  0.016046 -0.025610  0.025426 -0.094371  0.008999 -0.004985   \n",
              "531  0.503516  0.019632  0.046315  0.074801  0.018078  0.022948 -0.016365   \n",
              "532  0.498566  0.051532  0.015525 -0.006052  0.018201  0.004361 -0.021649   \n",
              "533  0.496900  0.007856  0.005917 -0.045393 -0.004246 -0.001628  0.015051   \n",
              "534  0.527394 -0.001086  0.013948  0.013274 -0.056855 -0.001004 -0.001355   \n",
              "\n",
              "         Label  \n",
              "0    happyness  \n",
              "1      neutral  \n",
              "2        anger  \n",
              "3    happyness  \n",
              "4      neutral  \n",
              "..         ...  \n",
              "530    boredom  \n",
              "531    sadness  \n",
              "532    sadness  \n",
              "533      anger  \n",
              "534      anger  \n",
              "\n",
              "[535 rows x 261 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-127cdc16-5405-4ef7-9e82-8b7659ff61f2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>251</th>\n",
              "      <th>252</th>\n",
              "      <th>253</th>\n",
              "      <th>254</th>\n",
              "      <th>255</th>\n",
              "      <th>256</th>\n",
              "      <th>257</th>\n",
              "      <th>258</th>\n",
              "      <th>259</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>03a01Fa.wav</td>\n",
              "      <td>-482.45233</td>\n",
              "      <td>62.835957</td>\n",
              "      <td>-0.348998</td>\n",
              "      <td>26.264595</td>\n",
              "      <td>2.978607</td>\n",
              "      <td>6.900927</td>\n",
              "      <td>-13.006243</td>\n",
              "      <td>0.273391</td>\n",
              "      <td>-9.196591</td>\n",
              "      <td>...</td>\n",
              "      <td>0.675823</td>\n",
              "      <td>0.684034</td>\n",
              "      <td>0.627376</td>\n",
              "      <td>-0.001574</td>\n",
              "      <td>0.012645</td>\n",
              "      <td>-0.027069</td>\n",
              "      <td>0.019313</td>\n",
              "      <td>-0.002252</td>\n",
              "      <td>-0.006220</td>\n",
              "      <td>happyness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>03a01Nc.wav</td>\n",
              "      <td>-469.48477</td>\n",
              "      <td>88.400730</td>\n",
              "      <td>-7.127512</td>\n",
              "      <td>29.156132</td>\n",
              "      <td>5.335554</td>\n",
              "      <td>7.147227</td>\n",
              "      <td>-6.727572</td>\n",
              "      <td>-8.307674</td>\n",
              "      <td>-3.364513</td>\n",
              "      <td>...</td>\n",
              "      <td>0.635522</td>\n",
              "      <td>0.544438</td>\n",
              "      <td>0.532856</td>\n",
              "      <td>-0.018488</td>\n",
              "      <td>0.011973</td>\n",
              "      <td>-0.011038</td>\n",
              "      <td>0.079758</td>\n",
              "      <td>-0.021044</td>\n",
              "      <td>-0.019445</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>03a01Wa.wav</td>\n",
              "      <td>-434.88647</td>\n",
              "      <td>41.972150</td>\n",
              "      <td>-29.416862</td>\n",
              "      <td>18.537344</td>\n",
              "      <td>-4.156565</td>\n",
              "      <td>5.257353</td>\n",
              "      <td>-11.410935</td>\n",
              "      <td>-8.983023</td>\n",
              "      <td>-11.285996</td>\n",
              "      <td>...</td>\n",
              "      <td>0.648380</td>\n",
              "      <td>0.675295</td>\n",
              "      <td>0.560000</td>\n",
              "      <td>-0.010576</td>\n",
              "      <td>-0.000228</td>\n",
              "      <td>0.011102</td>\n",
              "      <td>-0.074188</td>\n",
              "      <td>0.012116</td>\n",
              "      <td>-0.000779</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>03a02Fc.wav</td>\n",
              "      <td>-454.89886</td>\n",
              "      <td>45.067265</td>\n",
              "      <td>-0.193278</td>\n",
              "      <td>15.111545</td>\n",
              "      <td>3.080835</td>\n",
              "      <td>4.204241</td>\n",
              "      <td>-10.440731</td>\n",
              "      <td>-6.615343</td>\n",
              "      <td>-16.249382</td>\n",
              "      <td>...</td>\n",
              "      <td>0.575784</td>\n",
              "      <td>0.523305</td>\n",
              "      <td>0.423375</td>\n",
              "      <td>0.009395</td>\n",
              "      <td>-0.025547</td>\n",
              "      <td>-0.035554</td>\n",
              "      <td>-0.025885</td>\n",
              "      <td>0.011198</td>\n",
              "      <td>-0.000163</td>\n",
              "      <td>happyness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>03a02Nc.wav</td>\n",
              "      <td>-447.12630</td>\n",
              "      <td>86.114920</td>\n",
              "      <td>4.772520</td>\n",
              "      <td>38.097256</td>\n",
              "      <td>8.324276</td>\n",
              "      <td>8.538317</td>\n",
              "      <td>-4.507682</td>\n",
              "      <td>-7.680664</td>\n",
              "      <td>-7.317249</td>\n",
              "      <td>...</td>\n",
              "      <td>0.615263</td>\n",
              "      <td>0.566964</td>\n",
              "      <td>0.605103</td>\n",
              "      <td>-0.008389</td>\n",
              "      <td>-0.051995</td>\n",
              "      <td>-0.056544</td>\n",
              "      <td>-0.020014</td>\n",
              "      <td>0.013964</td>\n",
              "      <td>0.008349</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>530</th>\n",
              "      <td>16b10Lb.wav</td>\n",
              "      <td>-418.62490</td>\n",
              "      <td>57.015880</td>\n",
              "      <td>6.383415</td>\n",
              "      <td>47.618423</td>\n",
              "      <td>-8.051490</td>\n",
              "      <td>4.213936</td>\n",
              "      <td>-15.029120</td>\n",
              "      <td>-2.448467</td>\n",
              "      <td>-10.805821</td>\n",
              "      <td>...</td>\n",
              "      <td>0.569263</td>\n",
              "      <td>0.551809</td>\n",
              "      <td>0.576764</td>\n",
              "      <td>0.016046</td>\n",
              "      <td>-0.025610</td>\n",
              "      <td>0.025426</td>\n",
              "      <td>-0.094371</td>\n",
              "      <td>0.008999</td>\n",
              "      <td>-0.004985</td>\n",
              "      <td>boredom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>531</th>\n",
              "      <td>16b10Tb.wav</td>\n",
              "      <td>-427.36716</td>\n",
              "      <td>51.473750</td>\n",
              "      <td>4.835125</td>\n",
              "      <td>40.900140</td>\n",
              "      <td>6.937289</td>\n",
              "      <td>13.700687</td>\n",
              "      <td>-8.331753</td>\n",
              "      <td>-0.583414</td>\n",
              "      <td>-6.279562</td>\n",
              "      <td>...</td>\n",
              "      <td>0.638155</td>\n",
              "      <td>0.574542</td>\n",
              "      <td>0.503516</td>\n",
              "      <td>0.019632</td>\n",
              "      <td>0.046315</td>\n",
              "      <td>0.074801</td>\n",
              "      <td>0.018078</td>\n",
              "      <td>0.022948</td>\n",
              "      <td>-0.016365</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>532</th>\n",
              "      <td>16b10Td.wav</td>\n",
              "      <td>-467.15588</td>\n",
              "      <td>52.217026</td>\n",
              "      <td>10.470471</td>\n",
              "      <td>47.414780</td>\n",
              "      <td>8.690019</td>\n",
              "      <td>15.601270</td>\n",
              "      <td>-2.032935</td>\n",
              "      <td>4.985774</td>\n",
              "      <td>-7.432734</td>\n",
              "      <td>...</td>\n",
              "      <td>0.523647</td>\n",
              "      <td>0.509723</td>\n",
              "      <td>0.498566</td>\n",
              "      <td>0.051532</td>\n",
              "      <td>0.015525</td>\n",
              "      <td>-0.006052</td>\n",
              "      <td>0.018201</td>\n",
              "      <td>0.004361</td>\n",
              "      <td>-0.021649</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>533</th>\n",
              "      <td>16b10Wa.wav</td>\n",
              "      <td>-526.19570</td>\n",
              "      <td>11.317784</td>\n",
              "      <td>-18.942173</td>\n",
              "      <td>29.540787</td>\n",
              "      <td>-28.057306</td>\n",
              "      <td>1.299599</td>\n",
              "      <td>-16.251814</td>\n",
              "      <td>-7.512440</td>\n",
              "      <td>-23.191568</td>\n",
              "      <td>...</td>\n",
              "      <td>0.528861</td>\n",
              "      <td>0.501070</td>\n",
              "      <td>0.496900</td>\n",
              "      <td>0.007856</td>\n",
              "      <td>0.005917</td>\n",
              "      <td>-0.045393</td>\n",
              "      <td>-0.004246</td>\n",
              "      <td>-0.001628</td>\n",
              "      <td>0.015051</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>534</th>\n",
              "      <td>16b10Wb.wav</td>\n",
              "      <td>-437.97220</td>\n",
              "      <td>5.289146</td>\n",
              "      <td>-22.667547</td>\n",
              "      <td>25.394840</td>\n",
              "      <td>-28.545520</td>\n",
              "      <td>0.428451</td>\n",
              "      <td>-11.650926</td>\n",
              "      <td>-8.022680</td>\n",
              "      <td>-18.337156</td>\n",
              "      <td>...</td>\n",
              "      <td>0.495079</td>\n",
              "      <td>0.539387</td>\n",
              "      <td>0.527394</td>\n",
              "      <td>-0.001086</td>\n",
              "      <td>0.013948</td>\n",
              "      <td>0.013274</td>\n",
              "      <td>-0.056855</td>\n",
              "      <td>-0.001004</td>\n",
              "      <td>-0.001355</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>535 rows × 261 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-127cdc16-5405-4ef7-9e82-8b7659ff61f2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-127cdc16-5405-4ef7-9e82-8b7659ff61f2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-127cdc16-5405-4ef7-9e82-8b7659ff61f2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e5506556-9bca-41ed-8b22-f67d5f0152dd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e5506556-9bca-41ed-8b22-f67d5f0152dd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e5506556-9bca-41ed-8b22-f67d5f0152dd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "38a8374f",
      "metadata": {
        "id": "38a8374f"
      },
      "outputs": [],
      "source": [
        "df.replace({ 'happyness': 0, 'neutral': 1,'anger': 2,'sadness': 3, 'fear':4,'boredom':5,'disgust':6}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "9cf4576c",
      "metadata": {
        "id": "9cf4576c"
      },
      "outputs": [],
      "source": [
        "x=df.iloc[:,1:41]\n",
        "y=df.iloc[:,-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "aa7f6b05",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "aa7f6b05",
        "outputId": "af4f12ea-63f2-449c-fd98-72aef8c77422"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             1          2          3          4          5          6  \\\n",
              "0   -482.45233  62.835957  -0.348998  26.264595   2.978607   6.900927   \n",
              "1   -469.48477  88.400730  -7.127512  29.156132   5.335554   7.147227   \n",
              "2   -434.88647  41.972150 -29.416862  18.537344  -4.156565   5.257353   \n",
              "3   -454.89886  45.067265  -0.193278  15.111545   3.080835   4.204241   \n",
              "4   -447.12630  86.114920   4.772520  38.097256   8.324276   8.538317   \n",
              "..         ...        ...        ...        ...        ...        ...   \n",
              "530 -418.62490  57.015880   6.383415  47.618423  -8.051490   4.213936   \n",
              "531 -427.36716  51.473750   4.835125  40.900140   6.937289  13.700687   \n",
              "532 -467.15588  52.217026  10.470471  47.414780   8.690019  15.601270   \n",
              "533 -526.19570  11.317784 -18.942173  29.540787 -28.057306   1.299599   \n",
              "534 -437.97220   5.289146 -22.667547  25.394840 -28.545520   0.428451   \n",
              "\n",
              "             7         8          9         10  ...        31        32  \\\n",
              "0   -13.006243  0.273391  -9.196591   1.597646  ... -3.409270 -5.413244   \n",
              "1    -6.727572 -8.307674  -3.364513   7.846351  ... -5.047899 -6.706718   \n",
              "2   -11.410935 -8.983023 -11.285996  -2.445232  ... -2.040512 -3.035521   \n",
              "3   -10.440731 -6.615343 -16.249382  -7.022445  ... -1.957219 -4.853336   \n",
              "4    -4.507682 -7.680664  -7.317249   2.848643  ... -4.924419 -8.395385   \n",
              "..         ...       ...        ...        ...  ...       ...       ...   \n",
              "530 -15.029120 -2.448467 -10.805821  -3.372870  ... -2.760351 -4.033802   \n",
              "531  -8.331753 -0.583414  -6.279562  -1.778869  ...  3.584273  0.085885   \n",
              "532  -2.032935  4.985774  -7.432734   2.523657  ... -4.083610 -4.791102   \n",
              "533 -16.251814 -7.512440 -23.191568 -13.485355  ...  1.271853 -3.008154   \n",
              "534 -11.650926 -8.022680 -18.337156 -14.782391  ...  0.051370 -1.901394   \n",
              "\n",
              "            33         34         35         36        37        38        39  \\\n",
              "0    -9.903300  -9.461795 -11.410793  -7.792785 -4.598618 -1.893468  0.230821   \n",
              "1   -10.045481 -11.882533 -12.027461 -10.450580 -6.670032 -3.885782 -0.594336   \n",
              "2    -5.395728  -6.573817  -7.666299  -6.801901 -3.527732  1.548335  0.199676   \n",
              "3    -5.930995  -6.787319  -8.053974  -7.839906 -5.059597  0.171459  1.393567   \n",
              "4   -10.831446 -12.918998 -12.387193 -11.704714 -7.736867 -4.567762 -1.578654   \n",
              "..         ...        ...        ...        ...       ...       ...       ...   \n",
              "530  -7.910801  -8.805643 -11.735242  -9.766793 -4.004450 -1.724268  1.669646   \n",
              "531  -3.021229  -6.543844  -7.785308  -8.447594 -3.718233 -2.430141 -1.299946   \n",
              "532  -7.304545  -7.000581  -8.297956  -6.995429 -3.757356 -2.086286 -0.455316   \n",
              "533  -7.199957  -6.784047  -9.184513  -4.848257 -4.094945  0.953147  0.643771   \n",
              "534  -6.514058  -6.647235  -9.270068  -6.796636 -4.169386  0.677490  1.334848   \n",
              "\n",
              "           40  \n",
              "0   -0.455839  \n",
              "1   -1.361155  \n",
              "2    2.296331  \n",
              "3   -0.334069  \n",
              "4   -2.273726  \n",
              "..        ...  \n",
              "530  2.706617  \n",
              "531 -0.641451  \n",
              "532  0.501709  \n",
              "533  3.257232  \n",
              "534  1.308542  \n",
              "\n",
              "[535 rows x 40 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9066113d-8af2-4607-8ba2-1bf6451d5ca0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>...</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-482.45233</td>\n",
              "      <td>62.835957</td>\n",
              "      <td>-0.348998</td>\n",
              "      <td>26.264595</td>\n",
              "      <td>2.978607</td>\n",
              "      <td>6.900927</td>\n",
              "      <td>-13.006243</td>\n",
              "      <td>0.273391</td>\n",
              "      <td>-9.196591</td>\n",
              "      <td>1.597646</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.409270</td>\n",
              "      <td>-5.413244</td>\n",
              "      <td>-9.903300</td>\n",
              "      <td>-9.461795</td>\n",
              "      <td>-11.410793</td>\n",
              "      <td>-7.792785</td>\n",
              "      <td>-4.598618</td>\n",
              "      <td>-1.893468</td>\n",
              "      <td>0.230821</td>\n",
              "      <td>-0.455839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-469.48477</td>\n",
              "      <td>88.400730</td>\n",
              "      <td>-7.127512</td>\n",
              "      <td>29.156132</td>\n",
              "      <td>5.335554</td>\n",
              "      <td>7.147227</td>\n",
              "      <td>-6.727572</td>\n",
              "      <td>-8.307674</td>\n",
              "      <td>-3.364513</td>\n",
              "      <td>7.846351</td>\n",
              "      <td>...</td>\n",
              "      <td>-5.047899</td>\n",
              "      <td>-6.706718</td>\n",
              "      <td>-10.045481</td>\n",
              "      <td>-11.882533</td>\n",
              "      <td>-12.027461</td>\n",
              "      <td>-10.450580</td>\n",
              "      <td>-6.670032</td>\n",
              "      <td>-3.885782</td>\n",
              "      <td>-0.594336</td>\n",
              "      <td>-1.361155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-434.88647</td>\n",
              "      <td>41.972150</td>\n",
              "      <td>-29.416862</td>\n",
              "      <td>18.537344</td>\n",
              "      <td>-4.156565</td>\n",
              "      <td>5.257353</td>\n",
              "      <td>-11.410935</td>\n",
              "      <td>-8.983023</td>\n",
              "      <td>-11.285996</td>\n",
              "      <td>-2.445232</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.040512</td>\n",
              "      <td>-3.035521</td>\n",
              "      <td>-5.395728</td>\n",
              "      <td>-6.573817</td>\n",
              "      <td>-7.666299</td>\n",
              "      <td>-6.801901</td>\n",
              "      <td>-3.527732</td>\n",
              "      <td>1.548335</td>\n",
              "      <td>0.199676</td>\n",
              "      <td>2.296331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-454.89886</td>\n",
              "      <td>45.067265</td>\n",
              "      <td>-0.193278</td>\n",
              "      <td>15.111545</td>\n",
              "      <td>3.080835</td>\n",
              "      <td>4.204241</td>\n",
              "      <td>-10.440731</td>\n",
              "      <td>-6.615343</td>\n",
              "      <td>-16.249382</td>\n",
              "      <td>-7.022445</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.957219</td>\n",
              "      <td>-4.853336</td>\n",
              "      <td>-5.930995</td>\n",
              "      <td>-6.787319</td>\n",
              "      <td>-8.053974</td>\n",
              "      <td>-7.839906</td>\n",
              "      <td>-5.059597</td>\n",
              "      <td>0.171459</td>\n",
              "      <td>1.393567</td>\n",
              "      <td>-0.334069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-447.12630</td>\n",
              "      <td>86.114920</td>\n",
              "      <td>4.772520</td>\n",
              "      <td>38.097256</td>\n",
              "      <td>8.324276</td>\n",
              "      <td>8.538317</td>\n",
              "      <td>-4.507682</td>\n",
              "      <td>-7.680664</td>\n",
              "      <td>-7.317249</td>\n",
              "      <td>2.848643</td>\n",
              "      <td>...</td>\n",
              "      <td>-4.924419</td>\n",
              "      <td>-8.395385</td>\n",
              "      <td>-10.831446</td>\n",
              "      <td>-12.918998</td>\n",
              "      <td>-12.387193</td>\n",
              "      <td>-11.704714</td>\n",
              "      <td>-7.736867</td>\n",
              "      <td>-4.567762</td>\n",
              "      <td>-1.578654</td>\n",
              "      <td>-2.273726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>530</th>\n",
              "      <td>-418.62490</td>\n",
              "      <td>57.015880</td>\n",
              "      <td>6.383415</td>\n",
              "      <td>47.618423</td>\n",
              "      <td>-8.051490</td>\n",
              "      <td>4.213936</td>\n",
              "      <td>-15.029120</td>\n",
              "      <td>-2.448467</td>\n",
              "      <td>-10.805821</td>\n",
              "      <td>-3.372870</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.760351</td>\n",
              "      <td>-4.033802</td>\n",
              "      <td>-7.910801</td>\n",
              "      <td>-8.805643</td>\n",
              "      <td>-11.735242</td>\n",
              "      <td>-9.766793</td>\n",
              "      <td>-4.004450</td>\n",
              "      <td>-1.724268</td>\n",
              "      <td>1.669646</td>\n",
              "      <td>2.706617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>531</th>\n",
              "      <td>-427.36716</td>\n",
              "      <td>51.473750</td>\n",
              "      <td>4.835125</td>\n",
              "      <td>40.900140</td>\n",
              "      <td>6.937289</td>\n",
              "      <td>13.700687</td>\n",
              "      <td>-8.331753</td>\n",
              "      <td>-0.583414</td>\n",
              "      <td>-6.279562</td>\n",
              "      <td>-1.778869</td>\n",
              "      <td>...</td>\n",
              "      <td>3.584273</td>\n",
              "      <td>0.085885</td>\n",
              "      <td>-3.021229</td>\n",
              "      <td>-6.543844</td>\n",
              "      <td>-7.785308</td>\n",
              "      <td>-8.447594</td>\n",
              "      <td>-3.718233</td>\n",
              "      <td>-2.430141</td>\n",
              "      <td>-1.299946</td>\n",
              "      <td>-0.641451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>532</th>\n",
              "      <td>-467.15588</td>\n",
              "      <td>52.217026</td>\n",
              "      <td>10.470471</td>\n",
              "      <td>47.414780</td>\n",
              "      <td>8.690019</td>\n",
              "      <td>15.601270</td>\n",
              "      <td>-2.032935</td>\n",
              "      <td>4.985774</td>\n",
              "      <td>-7.432734</td>\n",
              "      <td>2.523657</td>\n",
              "      <td>...</td>\n",
              "      <td>-4.083610</td>\n",
              "      <td>-4.791102</td>\n",
              "      <td>-7.304545</td>\n",
              "      <td>-7.000581</td>\n",
              "      <td>-8.297956</td>\n",
              "      <td>-6.995429</td>\n",
              "      <td>-3.757356</td>\n",
              "      <td>-2.086286</td>\n",
              "      <td>-0.455316</td>\n",
              "      <td>0.501709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>533</th>\n",
              "      <td>-526.19570</td>\n",
              "      <td>11.317784</td>\n",
              "      <td>-18.942173</td>\n",
              "      <td>29.540787</td>\n",
              "      <td>-28.057306</td>\n",
              "      <td>1.299599</td>\n",
              "      <td>-16.251814</td>\n",
              "      <td>-7.512440</td>\n",
              "      <td>-23.191568</td>\n",
              "      <td>-13.485355</td>\n",
              "      <td>...</td>\n",
              "      <td>1.271853</td>\n",
              "      <td>-3.008154</td>\n",
              "      <td>-7.199957</td>\n",
              "      <td>-6.784047</td>\n",
              "      <td>-9.184513</td>\n",
              "      <td>-4.848257</td>\n",
              "      <td>-4.094945</td>\n",
              "      <td>0.953147</td>\n",
              "      <td>0.643771</td>\n",
              "      <td>3.257232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>534</th>\n",
              "      <td>-437.97220</td>\n",
              "      <td>5.289146</td>\n",
              "      <td>-22.667547</td>\n",
              "      <td>25.394840</td>\n",
              "      <td>-28.545520</td>\n",
              "      <td>0.428451</td>\n",
              "      <td>-11.650926</td>\n",
              "      <td>-8.022680</td>\n",
              "      <td>-18.337156</td>\n",
              "      <td>-14.782391</td>\n",
              "      <td>...</td>\n",
              "      <td>0.051370</td>\n",
              "      <td>-1.901394</td>\n",
              "      <td>-6.514058</td>\n",
              "      <td>-6.647235</td>\n",
              "      <td>-9.270068</td>\n",
              "      <td>-6.796636</td>\n",
              "      <td>-4.169386</td>\n",
              "      <td>0.677490</td>\n",
              "      <td>1.334848</td>\n",
              "      <td>1.308542</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>535 rows × 40 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9066113d-8af2-4607-8ba2-1bf6451d5ca0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9066113d-8af2-4607-8ba2-1bf6451d5ca0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9066113d-8af2-4607-8ba2-1bf6451d5ca0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ef75dd9e-827a-4792-807f-898afe9124c2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ef75dd9e-827a-4792-807f-898afe9124c2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ef75dd9e-827a-4792-807f-898afe9124c2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "x"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "d4254451",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4254451",
        "outputId": "0155be67-bee3-4cac-dda4-ec20ecbbb2d4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      0\n",
              "1      1\n",
              "2      2\n",
              "3      0\n",
              "4      1\n",
              "      ..\n",
              "530    5\n",
              "531    3\n",
              "532    3\n",
              "533    2\n",
              "534    2\n",
              "Name: Label, Length: 535, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "7b9e0eec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "7b9e0eec",
        "outputId": "fddf527e-48b0-499a-86eb-cbea28526a13"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: ylabel='count'>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "sns.countplot(df['Label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "e5dddb1f",
      "metadata": {
        "id": "e5dddb1f"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "9c434c48",
      "metadata": {
        "id": "9c434c48"
      },
      "outputs": [],
      "source": [
        "x_train,x_test,Y_train,Y_test=train_test_split(x,y,test_size=0.2,random_state=7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "1f07cf5e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f07cf5e",
        "outputId": "16248d21-5e70-4443-8597-da23c3376f19"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "458    2\n",
              "235    3\n",
              "281    0\n",
              "55     4\n",
              "284    2\n",
              "      ..\n",
              "355    5\n",
              "392    5\n",
              "162    4\n",
              "283    1\n",
              "499    2\n",
              "Name: Label, Length: 107, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "Y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "87245499",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "87245499",
        "outputId": "fcbf0615-0cbc-4053-fad0-1fc54b47a53b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pandas.core.series.Series</b><br/>def __init__(data=None, index=None, dtype: Dtype | None=None, name=None, copy: bool | None=None, fastpath: bool=False) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/pandas/core/series.py</a>One-dimensional ndarray with axis labels (including time series).\n",
              "\n",
              "Labels need not be unique but must be a hashable type. The object\n",
              "supports both integer- and label-based indexing and provides a host of\n",
              "methods for performing operations involving the index. Statistical\n",
              "methods from ndarray have been overridden to automatically exclude\n",
              "missing data (currently represented as NaN).\n",
              "\n",
              "Operations between Series (+, -, /, \\*, \\*\\*) align values based on their\n",
              "associated index values-- they need not be the same length. The result\n",
              "index will be the sorted union of the two indexes.\n",
              "\n",
              "Parameters\n",
              "----------\n",
              "data : array-like, Iterable, dict, or scalar value\n",
              "    Contains data stored in Series. If data is a dict, argument order is\n",
              "    maintained.\n",
              "index : array-like or Index (1d)\n",
              "    Values must be hashable and have the same length as `data`.\n",
              "    Non-unique index values are allowed. Will default to\n",
              "    RangeIndex (0, 1, 2, ..., n) if not provided. If data is dict-like\n",
              "    and index is None, then the keys in the data are used as the index. If the\n",
              "    index is not None, the resulting Series is reindexed with the index values.\n",
              "dtype : str, numpy.dtype, or ExtensionDtype, optional\n",
              "    Data type for the output Series. If not specified, this will be\n",
              "    inferred from `data`.\n",
              "    See the :ref:`user guide &lt;basics.dtypes&gt;` for more usages.\n",
              "name : Hashable, default None\n",
              "    The name to give to the Series.\n",
              "copy : bool, default False\n",
              "    Copy input data. Only affects Series or 1d ndarray input. See examples.\n",
              "\n",
              "Notes\n",
              "-----\n",
              "Please reference the :ref:`User Guide &lt;basics.series&gt;` for more information.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "Constructing Series from a dictionary with an Index specified\n",
              "\n",
              "&gt;&gt;&gt; d = {&#x27;a&#x27;: 1, &#x27;b&#x27;: 2, &#x27;c&#x27;: 3}\n",
              "&gt;&gt;&gt; ser = pd.Series(data=d, index=[&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;])\n",
              "&gt;&gt;&gt; ser\n",
              "a   1\n",
              "b   2\n",
              "c   3\n",
              "dtype: int64\n",
              "\n",
              "The keys of the dictionary match with the Index values, hence the Index\n",
              "values have no effect.\n",
              "\n",
              "&gt;&gt;&gt; d = {&#x27;a&#x27;: 1, &#x27;b&#x27;: 2, &#x27;c&#x27;: 3}\n",
              "&gt;&gt;&gt; ser = pd.Series(data=d, index=[&#x27;x&#x27;, &#x27;y&#x27;, &#x27;z&#x27;])\n",
              "&gt;&gt;&gt; ser\n",
              "x   NaN\n",
              "y   NaN\n",
              "z   NaN\n",
              "dtype: float64\n",
              "\n",
              "Note that the Index is first build with the keys from the dictionary.\n",
              "After this the Series is reindexed with the given Index values, hence we\n",
              "get all NaN as a result.\n",
              "\n",
              "Constructing Series from a list with `copy=False`.\n",
              "\n",
              "&gt;&gt;&gt; r = [1, 2]\n",
              "&gt;&gt;&gt; ser = pd.Series(r, copy=False)\n",
              "&gt;&gt;&gt; ser.iloc[0] = 999\n",
              "&gt;&gt;&gt; r\n",
              "[1, 2]\n",
              "&gt;&gt;&gt; ser\n",
              "0    999\n",
              "1      2\n",
              "dtype: int64\n",
              "\n",
              "Due to input data type the Series has a `copy` of\n",
              "the original data even though `copy=False`, so\n",
              "the data is unchanged.\n",
              "\n",
              "Constructing Series from a 1d ndarray with `copy=False`.\n",
              "\n",
              "&gt;&gt;&gt; r = np.array([1, 2])\n",
              "&gt;&gt;&gt; ser = pd.Series(r, copy=False)\n",
              "&gt;&gt;&gt; ser.iloc[0] = 999\n",
              "&gt;&gt;&gt; r\n",
              "array([999,   2])\n",
              "&gt;&gt;&gt; ser\n",
              "0    999\n",
              "1      2\n",
              "dtype: int64\n",
              "\n",
              "Due to input data type the Series has a `view` on\n",
              "the original data, so\n",
              "the data is changed as well.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 244);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "type(Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "f3d1f20e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3d1f20e",
        "outputId": "9408b6a3-f085-4d45-a927-07aeb0495c52"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 6, 5, 0, 4, 1, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "#Check unique values for y_train\n",
        "Y_train.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "d0000d77",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0000d77",
        "outputId": "155cca9d-5ab8-486d-fbc5-b8d0fff3981e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "np.unique(Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "380b37eb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "380b37eb",
        "outputId": "e9c525f9-d719-4250-8ab2-a53025e08274"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 3, 0, 4, 5, 6, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "Y_test.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "e6b04d17",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6b04d17",
        "outputId": "907e8917-83a5-477a-eb46-ef97d3caf4a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "np.unique(Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "f8c656e1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8c656e1",
        "outputId": "03e9a234-c427-483f-b0c2-4b1dee61831b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 1.1116883116883116,\n",
              " 1: 0.9705215419501134,\n",
              " 2: 0.5661375661375662,\n",
              " 3: 1.2478134110787171,\n",
              " 4: 1.1116883116883116,\n",
              " 5: 0.9705215419501134,\n",
              " 6: 1.7469387755102042}"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "from sklearn.utils import compute_class_weight\n",
        "class_weights = compute_class_weight(\n",
        "                                        class_weight = \"balanced\",\n",
        "                                        classes = np.unique(Y_train),\n",
        "                                        y = Y_train\n",
        "                                    )\n",
        "class_weights = dict(zip(np.unique(Y_train), class_weights))\n",
        "class_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "51fc2efb",
      "metadata": {
        "id": "51fc2efb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "1508fc4d",
      "metadata": {
        "id": "1508fc4d"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "#Normalize the data\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(x_train)\n",
        "X_train_scalled = scaler.transform(x_train)\n",
        "X_test_scalled = scaler.transform(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "a31159c2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a31159c2",
        "outputId": "a6f2fe3e-2ad7-4bb1-fe02-f9dd04263989"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(428, 40, 1)\n",
            "(107, 40, 1)\n"
          ]
        }
      ],
      "source": [
        "#Add dimension for CNN\n",
        "x_traincnn = np.expand_dims(X_train_scalled, axis=2)\n",
        "x_testcnn = np.expand_dims(X_test_scalled, axis=2)\n",
        "\n",
        "#Check shapes of dataframes\n",
        "print(x_traincnn.shape)\n",
        "print(x_testcnn.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "ef5a1dfd",
      "metadata": {
        "id": "ef5a1dfd"
      },
      "outputs": [],
      "source": [
        "#Import packages for CNN\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Conv1D\n",
        "from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM, BatchNormalization, Flatten, MaxPooling1D\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from keras.regularizers import l2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "50b04b34",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50b04b34",
        "outputId": "c2ef0612-2e59-44fb-91d4-145be0025a68"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "(x_train.shape[1], 1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu', input_shape=(40, 1)))\n",
        "model.add(MaxPooling1D(pool_size=2, strides = 2, padding = 'same'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2, strides = 2, padding = 'same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2, strides = 2, padding = 'same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv1D(128, kernel_size=5, strides=1, padding='same', activation='sigmoid'))\n",
        "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# model.add(Conv1D(128, kernel_size=5, strides=1, padding='same', activation='sigmoid'))\n",
        "# model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Dropout(0.2))\n",
        "\n",
        "# model.add(Conv1D(64, kernel_size=5, strides=1, padding='same', activation='sigmoid'))\n",
        "# model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Dropout(0.3))\n",
        "##\n",
        "model.add(LSTM(256, return_sequences=True))\n",
        "model.add(LSTM(256))\n",
        "\n",
        "\n",
        "model.add(Dense(256, activation='relu'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(256, activation='relu'))\n",
        "# model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "##\n",
        "# model.add(Dense(64, activation='sigmoid'))\n",
        "# # model.add(BatchNormalization())\n",
        "# model.add(Dropout(0.3))\n",
        "\n",
        "# model.add(Dense(32, activation='sigmoid'))\n",
        "# # model.add(BatchNormalization())\n",
        "# model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(7, activation='softmax'))\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_l_oFFA2H_fy",
        "outputId": "54a0e463-10da-408f-c779-ae7d1bb6687f"
      },
      "id": "_l_oFFA2H_fy",
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_4 (Conv1D)           (None, 40, 256)           1536      \n",
            "                                                                 \n",
            " max_pooling1d_4 (MaxPoolin  (None, 20, 256)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_4 (Bat  (None, 20, 256)           1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv1d_5 (Conv1D)           (None, 20, 256)           327936    \n",
            "                                                                 \n",
            " max_pooling1d_5 (MaxPoolin  (None, 10, 256)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_5 (Bat  (None, 10, 256)           1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 10, 256)           0         \n",
            "                                                                 \n",
            " conv1d_6 (Conv1D)           (None, 10, 256)           327936    \n",
            "                                                                 \n",
            " max_pooling1d_6 (MaxPoolin  (None, 5, 256)            0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_6 (Bat  (None, 5, 256)            1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 5, 256)            0         \n",
            "                                                                 \n",
            " conv1d_7 (Conv1D)           (None, 5, 128)            163968    \n",
            "                                                                 \n",
            " max_pooling1d_7 (MaxPoolin  (None, 3, 128)            0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_7 (Bat  (None, 3, 128)            512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 3, 128)            0         \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 3, 256)            394240    \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 256)               525312    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 7)                 1799      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1877895 (7.16 MB)\n",
            "Trainable params: 1876103 (7.16 MB)\n",
            "Non-trainable params: 1792 (7.00 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e51-Xy0j25tM",
        "outputId": "4fb6b230-b98c-4f61-a84a-6da4b384d0eb"
      },
      "id": "e51-Xy0j25tM",
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "18b4b87c",
      "metadata": {
        "id": "18b4b87c"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tempfile\n",
        "initial_weights = os.path.join(tempfile.mkdtemp(), 'initial_weights')\n",
        "model.save_weights(initial_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "29d33a4a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29d33a4a",
        "outputId": "90cb5381-306b-4ca3-ec92-8a9b4d5c3a72"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7c4bed871e70>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "model.load_weights(initial_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "f3ea11c6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3ea11c6",
        "outputId": "0deba14f-dde8-4893-cc39-3609d9147d46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_4 (Conv1D)           (None, 40, 256)           1536      \n",
            "                                                                 \n",
            " max_pooling1d_4 (MaxPoolin  (None, 20, 256)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_4 (Bat  (None, 20, 256)           1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv1d_5 (Conv1D)           (None, 20, 256)           327936    \n",
            "                                                                 \n",
            " max_pooling1d_5 (MaxPoolin  (None, 10, 256)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_5 (Bat  (None, 10, 256)           1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 10, 256)           0         \n",
            "                                                                 \n",
            " conv1d_6 (Conv1D)           (None, 10, 256)           327936    \n",
            "                                                                 \n",
            " max_pooling1d_6 (MaxPoolin  (None, 5, 256)            0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_6 (Bat  (None, 5, 256)            1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 5, 256)            0         \n",
            "                                                                 \n",
            " conv1d_7 (Conv1D)           (None, 5, 128)            163968    \n",
            "                                                                 \n",
            " max_pooling1d_7 (MaxPoolin  (None, 3, 128)            0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_7 (Bat  (None, 3, 128)            512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 3, 128)            0         \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 3, 256)            394240    \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 256)               525312    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 7)                 1799      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1877895 (7.16 MB)\n",
            "Trainable params: 1876103 (7.16 MB)\n",
            "Non-trainable params: 1792 (7.00 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "optimiser = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=optimiser,\n",
        "              loss='sparse_categorical_crossentropy',                             #CategoricalCrossentropy\n",
        "              metrics=['SparseCategoricalAccuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "5c99effc",
      "metadata": {
        "id": "5c99effc"
      },
      "outputs": [],
      "source": [
        "checkpoint_path='cnn_lstm_emodb3.ckpt'\n",
        "checkpoint_dir=os.path.dirname(checkpoint_path)\n",
        "callback1=tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, monitor='val_sparse_categorical_accuracy', verbose=1,\n",
        "   save_best_only=True,save_weights_only=True,)\n",
        "callback2=tf.keras.callbacks.EarlyStopping(monitor='val_sparse_categorical_accuracy',min_delta=0, patience=50, verbose=0, mode='auto',baseline=None,restore_best_weights=True)\n",
        "cp_callback=[callback1,callback2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "f78fabd7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f78fabd7",
        "outputId": "6c2cfcb4-006a-491a-96e3-7f263adf5718"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.9330 - sparse_categorical_accuracy: 0.1636\n",
            "Epoch 1: val_sparse_categorical_accuracy improved from -inf to 0.10280, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 14s 299ms/step - loss: 1.9330 - sparse_categorical_accuracy: 0.1636 - val_loss: 1.9471 - val_sparse_categorical_accuracy: 0.1028\n",
            "Epoch 2/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 1.8849 - sparse_categorical_accuracy: 0.3255\n",
            "Epoch 2: val_sparse_categorical_accuracy did not improve from 0.10280\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 1.8958 - sparse_categorical_accuracy: 0.3248 - val_loss: 1.9465 - val_sparse_categorical_accuracy: 0.1028\n",
            "Epoch 3/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 1.8560 - sparse_categorical_accuracy: 0.3984\n",
            "Epoch 3: val_sparse_categorical_accuracy improved from 0.10280 to 0.17757, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 43ms/step - loss: 1.8533 - sparse_categorical_accuracy: 0.4042 - val_loss: 1.9456 - val_sparse_categorical_accuracy: 0.1776\n",
            "Epoch 4/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 1.8092 - sparse_categorical_accuracy: 0.4141\n",
            "Epoch 4: val_sparse_categorical_accuracy did not improve from 0.17757\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 1.7947 - sparse_categorical_accuracy: 0.4182 - val_loss: 1.9438 - val_sparse_categorical_accuracy: 0.1776\n",
            "Epoch 5/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 1.7112 - sparse_categorical_accuracy: 0.4583\n",
            "Epoch 5: val_sparse_categorical_accuracy did not improve from 0.17757\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 1.7184 - sparse_categorical_accuracy: 0.4439 - val_loss: 1.9409 - val_sparse_categorical_accuracy: 0.1776\n",
            "Epoch 6/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 1.6361 - sparse_categorical_accuracy: 0.4609\n",
            "Epoch 6: val_sparse_categorical_accuracy did not improve from 0.17757\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 1.6278 - sparse_categorical_accuracy: 0.4673 - val_loss: 1.9368 - val_sparse_categorical_accuracy: 0.1776\n",
            "Epoch 7/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 1.5422 - sparse_categorical_accuracy: 0.4818\n",
            "Epoch 7: val_sparse_categorical_accuracy did not improve from 0.17757\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 1.5481 - sparse_categorical_accuracy: 0.4743 - val_loss: 1.9324 - val_sparse_categorical_accuracy: 0.1776\n",
            "Epoch 8/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 1.4417 - sparse_categorical_accuracy: 0.5521\n",
            "Epoch 8: val_sparse_categorical_accuracy did not improve from 0.17757\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 1.4568 - sparse_categorical_accuracy: 0.5350 - val_loss: 1.9311 - val_sparse_categorical_accuracy: 0.1776\n",
            "Epoch 9/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 1.3553 - sparse_categorical_accuracy: 0.5469\n",
            "Epoch 9: val_sparse_categorical_accuracy improved from 0.17757 to 0.20561, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 44ms/step - loss: 1.3484 - sparse_categorical_accuracy: 0.5421 - val_loss: 1.9318 - val_sparse_categorical_accuracy: 0.2056\n",
            "Epoch 10/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 1.2377 - sparse_categorical_accuracy: 0.6068\n",
            "Epoch 10: val_sparse_categorical_accuracy improved from 0.20561 to 0.22430, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 44ms/step - loss: 1.2368 - sparse_categorical_accuracy: 0.5958 - val_loss: 1.9330 - val_sparse_categorical_accuracy: 0.2243\n",
            "Epoch 11/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 1.1509 - sparse_categorical_accuracy: 0.6198\n",
            "Epoch 11: val_sparse_categorical_accuracy did not improve from 0.22430\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 1.1358 - sparse_categorical_accuracy: 0.6238 - val_loss: 1.9337 - val_sparse_categorical_accuracy: 0.2243\n",
            "Epoch 12/900\n",
            "4/7 [================>.............] - ETA: 0s - loss: 1.0242 - sparse_categorical_accuracy: 0.6328\n",
            "Epoch 12: val_sparse_categorical_accuracy did not improve from 0.22430\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 0.9869 - sparse_categorical_accuracy: 0.6425 - val_loss: 1.9465 - val_sparse_categorical_accuracy: 0.1215\n",
            "Epoch 13/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.9117 - sparse_categorical_accuracy: 0.6531\n",
            "Epoch 13: val_sparse_categorical_accuracy did not improve from 0.22430\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.8826 - sparse_categorical_accuracy: 0.6636 - val_loss: 1.9559 - val_sparse_categorical_accuracy: 0.1028\n",
            "Epoch 14/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.7668 - sparse_categorical_accuracy: 0.7344\n",
            "Epoch 14: val_sparse_categorical_accuracy did not improve from 0.22430\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.7751 - sparse_categorical_accuracy: 0.7126 - val_loss: 1.9728 - val_sparse_categorical_accuracy: 0.1028\n",
            "Epoch 15/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.6814 - sparse_categorical_accuracy: 0.7290\n",
            "Epoch 15: val_sparse_categorical_accuracy did not improve from 0.22430\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.6814 - sparse_categorical_accuracy: 0.7290 - val_loss: 2.0112 - val_sparse_categorical_accuracy: 0.1028\n",
            "Epoch 16/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.6123 - sparse_categorical_accuracy: 0.7656\n",
            "Epoch 16: val_sparse_categorical_accuracy did not improve from 0.22430\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 0.6148 - sparse_categorical_accuracy: 0.7687 - val_loss: 2.0381 - val_sparse_categorical_accuracy: 0.1028\n",
            "Epoch 17/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.5403 - sparse_categorical_accuracy: 0.7844\n",
            "Epoch 17: val_sparse_categorical_accuracy did not improve from 0.22430\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.5448 - sparse_categorical_accuracy: 0.7921 - val_loss: 2.1257 - val_sparse_categorical_accuracy: 0.1028\n",
            "Epoch 18/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.5008 - sparse_categorical_accuracy: 0.8375\n",
            "Epoch 18: val_sparse_categorical_accuracy did not improve from 0.22430\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.4829 - sparse_categorical_accuracy: 0.8318 - val_loss: 2.1420 - val_sparse_categorical_accuracy: 0.1028\n",
            "Epoch 19/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.4587 - sparse_categorical_accuracy: 0.8375\n",
            "Epoch 19: val_sparse_categorical_accuracy did not improve from 0.22430\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.4360 - sparse_categorical_accuracy: 0.8505 - val_loss: 2.1968 - val_sparse_categorical_accuracy: 0.1028\n",
            "Epoch 20/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.3600 - sparse_categorical_accuracy: 0.8969\n",
            "Epoch 20: val_sparse_categorical_accuracy did not improve from 0.22430\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.3675 - sparse_categorical_accuracy: 0.8879 - val_loss: 2.2458 - val_sparse_categorical_accuracy: 0.1028\n",
            "Epoch 21/900\n",
            "4/7 [================>.............] - ETA: 0s - loss: 0.2898 - sparse_categorical_accuracy: 0.9258\n",
            "Epoch 21: val_sparse_categorical_accuracy did not improve from 0.22430\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 0.2996 - sparse_categorical_accuracy: 0.9159 - val_loss: 2.2885 - val_sparse_categorical_accuracy: 0.1028\n",
            "Epoch 22/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.2653 - sparse_categorical_accuracy: 0.9344\n",
            "Epoch 22: val_sparse_categorical_accuracy did not improve from 0.22430\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.2681 - sparse_categorical_accuracy: 0.9322 - val_loss: 2.4770 - val_sparse_categorical_accuracy: 0.1028\n",
            "Epoch 23/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.2000 - sparse_categorical_accuracy: 0.9500\n",
            "Epoch 23: val_sparse_categorical_accuracy did not improve from 0.22430\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.2104 - sparse_categorical_accuracy: 0.9416 - val_loss: 2.5471 - val_sparse_categorical_accuracy: 0.1028\n",
            "Epoch 24/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.1547 - sparse_categorical_accuracy: 0.9750\n",
            "Epoch 24: val_sparse_categorical_accuracy did not improve from 0.22430\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.1509 - sparse_categorical_accuracy: 0.9720 - val_loss: 2.4215 - val_sparse_categorical_accuracy: 0.1028\n",
            "Epoch 25/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.1296 - sparse_categorical_accuracy: 0.9743\n",
            "Epoch 25: val_sparse_categorical_accuracy did not improve from 0.22430\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.1296 - sparse_categorical_accuracy: 0.9743 - val_loss: 2.5338 - val_sparse_categorical_accuracy: 0.1028\n",
            "Epoch 26/900\n",
            "4/7 [================>.............] - ETA: 0s - loss: 0.1050 - sparse_categorical_accuracy: 0.9727\n",
            "Epoch 26: val_sparse_categorical_accuracy did not improve from 0.22430\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.1084 - sparse_categorical_accuracy: 0.9766 - val_loss: 2.5280 - val_sparse_categorical_accuracy: 0.1028\n",
            "Epoch 27/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0814 - sparse_categorical_accuracy: 0.9860\n",
            "Epoch 27: val_sparse_categorical_accuracy did not improve from 0.22430\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.0814 - sparse_categorical_accuracy: 0.9860 - val_loss: 2.5324 - val_sparse_categorical_accuracy: 0.1308\n",
            "Epoch 28/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0559 - sparse_categorical_accuracy: 0.9953\n",
            "Epoch 28: val_sparse_categorical_accuracy did not improve from 0.22430\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.0559 - sparse_categorical_accuracy: 0.9953 - val_loss: 2.8106 - val_sparse_categorical_accuracy: 0.1308\n",
            "Epoch 29/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0454 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 29: val_sparse_categorical_accuracy did not improve from 0.22430\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 0.0461 - sparse_categorical_accuracy: 0.9977 - val_loss: 2.9021 - val_sparse_categorical_accuracy: 0.1589\n",
            "Epoch 30/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0620 - sparse_categorical_accuracy: 0.9844\n",
            "Epoch 30: val_sparse_categorical_accuracy did not improve from 0.22430\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.0556 - sparse_categorical_accuracy: 0.9883 - val_loss: 2.7459 - val_sparse_categorical_accuracy: 0.1963\n",
            "Epoch 31/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0421 - sparse_categorical_accuracy: 0.9870\n",
            "Epoch 31: val_sparse_categorical_accuracy did not improve from 0.22430\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0413 - sparse_categorical_accuracy: 0.9860 - val_loss: 2.7953 - val_sparse_categorical_accuracy: 0.2243\n",
            "Epoch 32/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0374 - sparse_categorical_accuracy: 0.9906\n",
            "Epoch 32: val_sparse_categorical_accuracy did not improve from 0.22430\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.0406 - sparse_categorical_accuracy: 0.9883 - val_loss: 2.7522 - val_sparse_categorical_accuracy: 0.2243\n",
            "Epoch 33/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0229 - sparse_categorical_accuracy: 0.9906\n",
            "Epoch 33: val_sparse_categorical_accuracy did not improve from 0.22430\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.0257 - sparse_categorical_accuracy: 0.9907 - val_loss: 2.5470 - val_sparse_categorical_accuracy: 0.2056\n",
            "Epoch 34/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0303 - sparse_categorical_accuracy: 0.9948\n",
            "Epoch 34: val_sparse_categorical_accuracy did not improve from 0.22430\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0289 - sparse_categorical_accuracy: 0.9953 - val_loss: 2.6270 - val_sparse_categorical_accuracy: 0.1776\n",
            "Epoch 35/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0216 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 35: val_sparse_categorical_accuracy did not improve from 0.22430\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0229 - sparse_categorical_accuracy: 0.9953 - val_loss: 2.4859 - val_sparse_categorical_accuracy: 0.2056\n",
            "Epoch 36/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0271 - sparse_categorical_accuracy: 0.9922\n",
            "Epoch 36: val_sparse_categorical_accuracy did not improve from 0.22430\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0250 - sparse_categorical_accuracy: 0.9930 - val_loss: 2.4033 - val_sparse_categorical_accuracy: 0.2150\n",
            "Epoch 37/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0187 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 37: val_sparse_categorical_accuracy did not improve from 0.22430\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0291 - sparse_categorical_accuracy: 0.9907 - val_loss: 2.6042 - val_sparse_categorical_accuracy: 0.2150\n",
            "Epoch 38/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0181 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 38: val_sparse_categorical_accuracy did not improve from 0.22430\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0384 - sparse_categorical_accuracy: 0.9883 - val_loss: 2.5045 - val_sparse_categorical_accuracy: 0.2150\n",
            "Epoch 39/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0418 - sparse_categorical_accuracy: 0.9896\n",
            "Epoch 39: val_sparse_categorical_accuracy did not improve from 0.22430\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.0553 - sparse_categorical_accuracy: 0.9860 - val_loss: 2.8406 - val_sparse_categorical_accuracy: 0.2056\n",
            "Epoch 40/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0574 - sparse_categorical_accuracy: 0.9870\n",
            "Epoch 40: val_sparse_categorical_accuracy did not improve from 0.22430\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0560 - sparse_categorical_accuracy: 0.9860 - val_loss: 2.7769 - val_sparse_categorical_accuracy: 0.2243\n",
            "Epoch 41/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0215 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 41: val_sparse_categorical_accuracy improved from 0.22430 to 0.24299, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0325 - sparse_categorical_accuracy: 0.9883 - val_loss: 2.5487 - val_sparse_categorical_accuracy: 0.2430\n",
            "Epoch 42/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0228 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 42: val_sparse_categorical_accuracy did not improve from 0.24299\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.0250 - sparse_categorical_accuracy: 0.9953 - val_loss: 2.7263 - val_sparse_categorical_accuracy: 0.2243\n",
            "Epoch 43/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0381 - sparse_categorical_accuracy: 0.9906\n",
            "Epoch 43: val_sparse_categorical_accuracy did not improve from 0.24299\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0402 - sparse_categorical_accuracy: 0.9883 - val_loss: 2.8994 - val_sparse_categorical_accuracy: 0.2150\n",
            "Epoch 44/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0467 - sparse_categorical_accuracy: 0.9870\n",
            "Epoch 44: val_sparse_categorical_accuracy did not improve from 0.24299\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.0437 - sparse_categorical_accuracy: 0.9883 - val_loss: 3.1127 - val_sparse_categorical_accuracy: 0.2056\n",
            "Epoch 45/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0214 - sparse_categorical_accuracy: 0.9948\n",
            "Epoch 45: val_sparse_categorical_accuracy did not improve from 0.24299\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0221 - sparse_categorical_accuracy: 0.9953 - val_loss: 3.4212 - val_sparse_categorical_accuracy: 0.1963\n",
            "Epoch 46/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0478 - sparse_categorical_accuracy: 0.9812\n",
            "Epoch 46: val_sparse_categorical_accuracy improved from 0.24299 to 0.27103, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 43ms/step - loss: 0.0377 - sparse_categorical_accuracy: 0.9860 - val_loss: 3.0022 - val_sparse_categorical_accuracy: 0.2710\n",
            "Epoch 47/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0370 - sparse_categorical_accuracy: 0.9896\n",
            "Epoch 47: val_sparse_categorical_accuracy improved from 0.27103 to 0.31776, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 44ms/step - loss: 0.0446 - sparse_categorical_accuracy: 0.9860 - val_loss: 2.6513 - val_sparse_categorical_accuracy: 0.3178\n",
            "Epoch 48/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0337 - sparse_categorical_accuracy: 0.9812\n",
            "Epoch 48: val_sparse_categorical_accuracy did not improve from 0.31776\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0453 - sparse_categorical_accuracy: 0.9766 - val_loss: 2.8510 - val_sparse_categorical_accuracy: 0.2804\n",
            "Epoch 49/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0417 - sparse_categorical_accuracy: 0.9818\n",
            "Epoch 49: val_sparse_categorical_accuracy did not improve from 0.31776\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0485 - sparse_categorical_accuracy: 0.9790 - val_loss: 2.8897 - val_sparse_categorical_accuracy: 0.3084\n",
            "Epoch 50/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0515 - sparse_categorical_accuracy: 0.9896\n",
            "Epoch 50: val_sparse_categorical_accuracy improved from 0.31776 to 0.32710, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 42ms/step - loss: 0.0482 - sparse_categorical_accuracy: 0.9907 - val_loss: 2.5205 - val_sparse_categorical_accuracy: 0.3271\n",
            "Epoch 51/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0446 - sparse_categorical_accuracy: 0.9844\n",
            "Epoch 51: val_sparse_categorical_accuracy improved from 0.32710 to 0.34579, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 42ms/step - loss: 0.0414 - sparse_categorical_accuracy: 0.9860 - val_loss: 2.7273 - val_sparse_categorical_accuracy: 0.3458\n",
            "Epoch 52/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0288 - sparse_categorical_accuracy: 0.9937\n",
            "Epoch 52: val_sparse_categorical_accuracy did not improve from 0.34579\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.0238 - sparse_categorical_accuracy: 0.9953 - val_loss: 2.7053 - val_sparse_categorical_accuracy: 0.3458\n",
            "Epoch 53/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0167 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 53: val_sparse_categorical_accuracy did not improve from 0.34579\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0170 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.7174 - val_sparse_categorical_accuracy: 0.3364\n",
            "Epoch 54/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0103 - sparse_categorical_accuracy: 0.9948\n",
            "Epoch 54: val_sparse_categorical_accuracy did not improve from 0.34579\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0102 - sparse_categorical_accuracy: 0.9953 - val_loss: 2.7218 - val_sparse_categorical_accuracy: 0.3271\n",
            "Epoch 55/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0132 - sparse_categorical_accuracy: 0.9948\n",
            "Epoch 55: val_sparse_categorical_accuracy improved from 0.34579 to 0.35514, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0126 - sparse_categorical_accuracy: 0.9953 - val_loss: 2.5221 - val_sparse_categorical_accuracy: 0.3551\n",
            "Epoch 56/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0043 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 56: val_sparse_categorical_accuracy improved from 0.35514 to 0.37383, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9977 - val_loss: 2.4261 - val_sparse_categorical_accuracy: 0.3738\n",
            "Epoch 57/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0098 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 57: val_sparse_categorical_accuracy did not improve from 0.37383\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0151 - sparse_categorical_accuracy: 0.9953 - val_loss: 2.5795 - val_sparse_categorical_accuracy: 0.3551\n",
            "Epoch 58/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0222 - sparse_categorical_accuracy: 0.9922\n",
            "Epoch 58: val_sparse_categorical_accuracy did not improve from 0.37383\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0205 - sparse_categorical_accuracy: 0.9930 - val_loss: 2.6969 - val_sparse_categorical_accuracy: 0.3645\n",
            "Epoch 59/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0059 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 59: val_sparse_categorical_accuracy did not improve from 0.37383\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0063 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.6871 - val_sparse_categorical_accuracy: 0.3738\n",
            "Epoch 60/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0087 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 60: val_sparse_categorical_accuracy improved from 0.37383 to 0.38318, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0098 - sparse_categorical_accuracy: 0.9977 - val_loss: 2.6092 - val_sparse_categorical_accuracy: 0.3832\n",
            "Epoch 61/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0064 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 61: val_sparse_categorical_accuracy improved from 0.38318 to 0.41121, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0076 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.5138 - val_sparse_categorical_accuracy: 0.4112\n",
            "Epoch 62/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0072 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 62: val_sparse_categorical_accuracy improved from 0.41121 to 0.42056, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0065 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.4185 - val_sparse_categorical_accuracy: 0.4206\n",
            "Epoch 63/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0071 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 63: val_sparse_categorical_accuracy improved from 0.42056 to 0.42991, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0059 - sparse_categorical_accuracy: 0.9977 - val_loss: 2.4453 - val_sparse_categorical_accuracy: 0.4299\n",
            "Epoch 64/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0090 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 64: val_sparse_categorical_accuracy did not improve from 0.42991\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.0112 - sparse_categorical_accuracy: 0.9953 - val_loss: 2.3357 - val_sparse_categorical_accuracy: 0.4299\n",
            "Epoch 65/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0105 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 65: val_sparse_categorical_accuracy improved from 0.42991 to 0.43925, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 44ms/step - loss: 0.0096 - sparse_categorical_accuracy: 0.9977 - val_loss: 2.2477 - val_sparse_categorical_accuracy: 0.4393\n",
            "Epoch 66/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0042 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 66: val_sparse_categorical_accuracy did not improve from 0.43925\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.0039 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.1753 - val_sparse_categorical_accuracy: 0.4393\n",
            "Epoch 67/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0038 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 67: val_sparse_categorical_accuracy did not improve from 0.43925\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0049 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.1867 - val_sparse_categorical_accuracy: 0.4393\n",
            "Epoch 68/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0061 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 68: val_sparse_categorical_accuracy did not improve from 0.43925\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0058 - sparse_categorical_accuracy: 0.9977 - val_loss: 2.1899 - val_sparse_categorical_accuracy: 0.4393\n",
            "Epoch 69/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0069 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 69: val_sparse_categorical_accuracy improved from 0.43925 to 0.51402, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0063 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.9477 - val_sparse_categorical_accuracy: 0.5140\n",
            "Epoch 70/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0140 - sparse_categorical_accuracy: 0.9937\n",
            "Epoch 70: val_sparse_categorical_accuracy improved from 0.51402 to 0.53271, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 44ms/step - loss: 0.0130 - sparse_categorical_accuracy: 0.9953 - val_loss: 1.9212 - val_sparse_categorical_accuracy: 0.5327\n",
            "Epoch 71/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0133 - sparse_categorical_accuracy: 0.9937\n",
            "Epoch 71: val_sparse_categorical_accuracy did not improve from 0.53271\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.0158 - sparse_categorical_accuracy: 0.9930 - val_loss: 2.0281 - val_sparse_categorical_accuracy: 0.5140\n",
            "Epoch 72/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0047 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 72: val_sparse_categorical_accuracy improved from 0.53271 to 0.54206, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9977 - val_loss: 2.1028 - val_sparse_categorical_accuracy: 0.5421\n",
            "Epoch 73/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0118 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 73: val_sparse_categorical_accuracy did not improve from 0.54206\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0096 - sparse_categorical_accuracy: 0.9977 - val_loss: 2.1786 - val_sparse_categorical_accuracy: 0.5140\n",
            "Epoch 74/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0084 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 74: val_sparse_categorical_accuracy did not improve from 0.54206\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0122 - sparse_categorical_accuracy: 0.9977 - val_loss: 2.1168 - val_sparse_categorical_accuracy: 0.5234\n",
            "Epoch 75/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0047 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 75: val_sparse_categorical_accuracy did not improve from 0.54206\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.0040 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.0050 - val_sparse_categorical_accuracy: 0.5421\n",
            "Epoch 76/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0066 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 76: val_sparse_categorical_accuracy did not improve from 0.54206\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0062 - sparse_categorical_accuracy: 0.9977 - val_loss: 1.9296 - val_sparse_categorical_accuracy: 0.5421\n",
            "Epoch 77/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0090 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 77: val_sparse_categorical_accuracy improved from 0.54206 to 0.56075, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 49ms/step - loss: 0.0134 - sparse_categorical_accuracy: 0.9953 - val_loss: 1.9725 - val_sparse_categorical_accuracy: 0.5607\n",
            "Epoch 78/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0059 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 78: val_sparse_categorical_accuracy did not improve from 0.56075\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0055 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.9909 - val_sparse_categorical_accuracy: 0.5421\n",
            "Epoch 79/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0152 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 79: val_sparse_categorical_accuracy improved from 0.56075 to 0.58879, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.0145 - sparse_categorical_accuracy: 0.9977 - val_loss: 1.9837 - val_sparse_categorical_accuracy: 0.5888\n",
            "Epoch 80/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0213 - sparse_categorical_accuracy: 0.9922\n",
            "Epoch 80: val_sparse_categorical_accuracy improved from 0.58879 to 0.60748, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 43ms/step - loss: 0.0205 - sparse_categorical_accuracy: 0.9930 - val_loss: 1.8943 - val_sparse_categorical_accuracy: 0.6075\n",
            "Epoch 81/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0184 - sparse_categorical_accuracy: 0.9948\n",
            "Epoch 81: val_sparse_categorical_accuracy did not improve from 0.60748\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.0169 - sparse_categorical_accuracy: 0.9953 - val_loss: 1.9760 - val_sparse_categorical_accuracy: 0.5981\n",
            "Epoch 82/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0193 - sparse_categorical_accuracy: 0.9948\n",
            "Epoch 82: val_sparse_categorical_accuracy did not improve from 0.60748\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0196 - sparse_categorical_accuracy: 0.9930 - val_loss: 2.0072 - val_sparse_categorical_accuracy: 0.5888\n",
            "Epoch 83/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0088 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 83: val_sparse_categorical_accuracy did not improve from 0.60748\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0116 - sparse_categorical_accuracy: 0.9953 - val_loss: 2.0310 - val_sparse_categorical_accuracy: 0.5794\n",
            "Epoch 84/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0090 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 84: val_sparse_categorical_accuracy improved from 0.60748 to 0.63551, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 68ms/step - loss: 0.0090 - sparse_categorical_accuracy: 0.9977 - val_loss: 1.6935 - val_sparse_categorical_accuracy: 0.6355\n",
            "Epoch 85/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0124 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 85: val_sparse_categorical_accuracy improved from 0.63551 to 0.68224, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 63ms/step - loss: 0.0115 - sparse_categorical_accuracy: 0.9977 - val_loss: 1.5944 - val_sparse_categorical_accuracy: 0.6822\n",
            "Epoch 86/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0126 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 86: val_sparse_categorical_accuracy did not improve from 0.68224\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.0133 - sparse_categorical_accuracy: 0.9977 - val_loss: 1.6591 - val_sparse_categorical_accuracy: 0.6449\n",
            "Epoch 87/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0079 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 87: val_sparse_categorical_accuracy improved from 0.68224 to 0.69159, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 57ms/step - loss: 0.0135 - sparse_categorical_accuracy: 0.9953 - val_loss: 1.4424 - val_sparse_categorical_accuracy: 0.6916\n",
            "Epoch 88/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0254 - sparse_categorical_accuracy: 0.9953\n",
            "Epoch 88: val_sparse_categorical_accuracy did not improve from 0.69159\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.0254 - sparse_categorical_accuracy: 0.9953 - val_loss: 1.3441 - val_sparse_categorical_accuracy: 0.6822\n",
            "Epoch 89/900\n",
            "4/7 [================>.............] - ETA: 0s - loss: 0.0510 - sparse_categorical_accuracy: 0.9805\n",
            "Epoch 89: val_sparse_categorical_accuracy did not improve from 0.69159\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.0334 - sparse_categorical_accuracy: 0.9860 - val_loss: 1.4916 - val_sparse_categorical_accuracy: 0.6542\n",
            "Epoch 90/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0100 - sparse_categorical_accuracy: 0.9953\n",
            "Epoch 90: val_sparse_categorical_accuracy did not improve from 0.69159\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.0100 - sparse_categorical_accuracy: 0.9953 - val_loss: 1.4144 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 91/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0110 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 91: val_sparse_categorical_accuracy improved from 0.69159 to 0.71028, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 55ms/step - loss: 0.0095 - sparse_categorical_accuracy: 0.9977 - val_loss: 1.2796 - val_sparse_categorical_accuracy: 0.7103\n",
            "Epoch 92/900\n",
            "4/7 [================>.............] - ETA: 0s - loss: 0.0081 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 92: val_sparse_categorical_accuracy improved from 0.71028 to 0.71963, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 63ms/step - loss: 0.0106 - sparse_categorical_accuracy: 0.9977 - val_loss: 1.1422 - val_sparse_categorical_accuracy: 0.7196\n",
            "Epoch 93/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0156 - sparse_categorical_accuracy: 0.9953\n",
            "Epoch 93: val_sparse_categorical_accuracy improved from 0.71963 to 0.72897, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 63ms/step - loss: 0.0156 - sparse_categorical_accuracy: 0.9953 - val_loss: 1.2308 - val_sparse_categorical_accuracy: 0.7290\n",
            "Epoch 94/900\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0164 - sparse_categorical_accuracy: 0.9953\n",
            "Epoch 94: val_sparse_categorical_accuracy improved from 0.72897 to 0.74766, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 59ms/step - loss: 0.0164 - sparse_categorical_accuracy: 0.9953 - val_loss: 1.1103 - val_sparse_categorical_accuracy: 0.7477\n",
            "Epoch 95/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0129 - sparse_categorical_accuracy: 0.9937\n",
            "Epoch 95: val_sparse_categorical_accuracy did not improve from 0.74766\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.0290 - sparse_categorical_accuracy: 0.9930 - val_loss: 1.2220 - val_sparse_categorical_accuracy: 0.7477\n",
            "Epoch 96/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0370 - sparse_categorical_accuracy: 0.9875\n",
            "Epoch 96: val_sparse_categorical_accuracy did not improve from 0.74766\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.0287 - sparse_categorical_accuracy: 0.9907 - val_loss: 1.2409 - val_sparse_categorical_accuracy: 0.7290\n",
            "Epoch 97/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0266 - sparse_categorical_accuracy: 0.9906\n",
            "Epoch 97: val_sparse_categorical_accuracy did not improve from 0.74766\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0236 - sparse_categorical_accuracy: 0.9907 - val_loss: 1.1930 - val_sparse_categorical_accuracy: 0.7383\n",
            "Epoch 98/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0179 - sparse_categorical_accuracy: 0.9922\n",
            "Epoch 98: val_sparse_categorical_accuracy did not improve from 0.74766\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0167 - sparse_categorical_accuracy: 0.9930 - val_loss: 1.2645 - val_sparse_categorical_accuracy: 0.7477\n",
            "Epoch 99/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0084 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 99: val_sparse_categorical_accuracy did not improve from 0.74766\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0082 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.2830 - val_sparse_categorical_accuracy: 0.7383\n",
            "Epoch 100/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0306 - sparse_categorical_accuracy: 0.9870\n",
            "Epoch 100: val_sparse_categorical_accuracy improved from 0.74766 to 0.76636, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 43ms/step - loss: 0.0280 - sparse_categorical_accuracy: 0.9883 - val_loss: 1.3026 - val_sparse_categorical_accuracy: 0.7664\n",
            "Epoch 101/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0107 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 101: val_sparse_categorical_accuracy did not improve from 0.76636\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0102 - sparse_categorical_accuracy: 0.9977 - val_loss: 1.2966 - val_sparse_categorical_accuracy: 0.7477\n",
            "Epoch 102/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0075 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 102: val_sparse_categorical_accuracy improved from 0.76636 to 0.77570, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9977 - val_loss: 1.2981 - val_sparse_categorical_accuracy: 0.7757\n",
            "Epoch 103/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0074 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 103: val_sparse_categorical_accuracy did not improve from 0.77570\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9977 - val_loss: 1.1922 - val_sparse_categorical_accuracy: 0.7570\n",
            "Epoch 104/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0032 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 104: val_sparse_categorical_accuracy did not improve from 0.77570\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.0030 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.1518 - val_sparse_categorical_accuracy: 0.7477\n",
            "Epoch 105/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0017 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 105: val_sparse_categorical_accuracy did not improve from 0.77570\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0017 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.1258 - val_sparse_categorical_accuracy: 0.7664\n",
            "Epoch 106/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0062 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 106: val_sparse_categorical_accuracy did not improve from 0.77570\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9977 - val_loss: 1.0649 - val_sparse_categorical_accuracy: 0.7664\n",
            "Epoch 107/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0107 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 107: val_sparse_categorical_accuracy improved from 0.77570 to 0.79439, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 42ms/step - loss: 0.0104 - sparse_categorical_accuracy: 0.9977 - val_loss: 1.0388 - val_sparse_categorical_accuracy: 0.7944\n",
            "Epoch 108/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0035 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 108: val_sparse_categorical_accuracy improved from 0.79439 to 0.80374, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0033 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.0026 - val_sparse_categorical_accuracy: 0.8037\n",
            "Epoch 109/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0038 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 109: val_sparse_categorical_accuracy did not improve from 0.80374\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0033 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.9800 - val_sparse_categorical_accuracy: 0.7850\n",
            "Epoch 110/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0031 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 110: val_sparse_categorical_accuracy improved from 0.80374 to 0.81308, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 44ms/step - loss: 0.0027 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.9529 - val_sparse_categorical_accuracy: 0.8131\n",
            "Epoch 111/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0033 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 111: val_sparse_categorical_accuracy did not improve from 0.81308\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9977 - val_loss: 0.9815 - val_sparse_categorical_accuracy: 0.7944\n",
            "Epoch 112/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0012 - sparse_categorical_accuracy: 1.0000    \n",
            "Epoch 112: val_sparse_categorical_accuracy did not improve from 0.81308\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0013 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.0995 - val_sparse_categorical_accuracy: 0.7757\n",
            "Epoch 113/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0044 - sparse_categorical_accuracy: 0.9974    \n",
            "Epoch 113: val_sparse_categorical_accuracy did not improve from 0.81308\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9977 - val_loss: 1.2230 - val_sparse_categorical_accuracy: 0.7850\n",
            "Epoch 114/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0130 - sparse_categorical_accuracy: 0.9969    \n",
            "Epoch 114: val_sparse_categorical_accuracy did not improve from 0.81308\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0111 - sparse_categorical_accuracy: 0.9977 - val_loss: 1.3641 - val_sparse_categorical_accuracy: 0.7477\n",
            "Epoch 115/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0034 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 115: val_sparse_categorical_accuracy did not improve from 0.81308\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0059 - sparse_categorical_accuracy: 0.9977 - val_loss: 1.3947 - val_sparse_categorical_accuracy: 0.7850\n",
            "Epoch 116/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0084 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 116: val_sparse_categorical_accuracy did not improve from 0.81308\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9977 - val_loss: 1.2076 - val_sparse_categorical_accuracy: 0.8037\n",
            "Epoch 117/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0056 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 117: val_sparse_categorical_accuracy did not improve from 0.81308\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0196 - sparse_categorical_accuracy: 0.9930 - val_loss: 1.0705 - val_sparse_categorical_accuracy: 0.8037\n",
            "Epoch 118/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0041 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 118: val_sparse_categorical_accuracy did not improve from 0.81308\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.0065 - sparse_categorical_accuracy: 0.9953 - val_loss: 1.3251 - val_sparse_categorical_accuracy: 0.7570\n",
            "Epoch 119/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0188 - sparse_categorical_accuracy: 0.9937\n",
            "Epoch 119: val_sparse_categorical_accuracy did not improve from 0.81308\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0158 - sparse_categorical_accuracy: 0.9953 - val_loss: 1.1174 - val_sparse_categorical_accuracy: 0.7757\n",
            "Epoch 120/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0376 - sparse_categorical_accuracy: 0.9896\n",
            "Epoch 120: val_sparse_categorical_accuracy did not improve from 0.81308\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0340 - sparse_categorical_accuracy: 0.9907 - val_loss: 1.3789 - val_sparse_categorical_accuracy: 0.7290\n",
            "Epoch 121/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0141 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 121: val_sparse_categorical_accuracy did not improve from 0.81308\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0137 - sparse_categorical_accuracy: 0.9977 - val_loss: 1.3786 - val_sparse_categorical_accuracy: 0.7290\n",
            "Epoch 122/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0455 - sparse_categorical_accuracy: 0.9875\n",
            "Epoch 122: val_sparse_categorical_accuracy did not improve from 0.81308\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0460 - sparse_categorical_accuracy: 0.9860 - val_loss: 1.2816 - val_sparse_categorical_accuracy: 0.7757\n",
            "Epoch 123/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0099 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 123: val_sparse_categorical_accuracy did not improve from 0.81308\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0354 - sparse_categorical_accuracy: 0.9743 - val_loss: 1.3016 - val_sparse_categorical_accuracy: 0.7570\n",
            "Epoch 124/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0173 - sparse_categorical_accuracy: 0.9922\n",
            "Epoch 124: val_sparse_categorical_accuracy did not improve from 0.81308\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.0176 - sparse_categorical_accuracy: 0.9907 - val_loss: 1.5444 - val_sparse_categorical_accuracy: 0.7383\n",
            "Epoch 125/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0598 - sparse_categorical_accuracy: 0.9870\n",
            "Epoch 125: val_sparse_categorical_accuracy did not improve from 0.81308\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0540 - sparse_categorical_accuracy: 0.9883 - val_loss: 1.2076 - val_sparse_categorical_accuracy: 0.7570\n",
            "Epoch 126/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0291 - sparse_categorical_accuracy: 0.9875\n",
            "Epoch 126: val_sparse_categorical_accuracy did not improve from 0.81308\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0315 - sparse_categorical_accuracy: 0.9836 - val_loss: 1.2097 - val_sparse_categorical_accuracy: 0.7290\n",
            "Epoch 127/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0092 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 127: val_sparse_categorical_accuracy did not improve from 0.81308\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0091 - sparse_categorical_accuracy: 0.9977 - val_loss: 1.1087 - val_sparse_categorical_accuracy: 0.7757\n",
            "Epoch 128/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0077 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 128: val_sparse_categorical_accuracy did not improve from 0.81308\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9977 - val_loss: 1.1989 - val_sparse_categorical_accuracy: 0.7850\n",
            "Epoch 129/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0210 - sparse_categorical_accuracy: 0.9922\n",
            "Epoch 129: val_sparse_categorical_accuracy did not improve from 0.81308\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.0192 - sparse_categorical_accuracy: 0.9930 - val_loss: 1.2092 - val_sparse_categorical_accuracy: 0.7757\n",
            "Epoch 130/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0093 - sparse_categorical_accuracy: 0.9937\n",
            "Epoch 130: val_sparse_categorical_accuracy did not improve from 0.81308\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9953 - val_loss: 1.3263 - val_sparse_categorical_accuracy: 0.7477\n",
            "Epoch 131/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0086 - sparse_categorical_accuracy: 0.9948\n",
            "Epoch 131: val_sparse_categorical_accuracy did not improve from 0.81308\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.0100 - sparse_categorical_accuracy: 0.9930 - val_loss: 1.3362 - val_sparse_categorical_accuracy: 0.7383\n",
            "Epoch 132/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0132 - sparse_categorical_accuracy: 0.9974    \n",
            "Epoch 132: val_sparse_categorical_accuracy did not improve from 0.81308\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.0120 - sparse_categorical_accuracy: 0.9977 - val_loss: 1.2524 - val_sparse_categorical_accuracy: 0.7477\n",
            "Epoch 133/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0084 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 133: val_sparse_categorical_accuracy did not improve from 0.81308\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9977 - val_loss: 1.3964 - val_sparse_categorical_accuracy: 0.7383\n",
            "Epoch 134/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0038 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 134: val_sparse_categorical_accuracy did not improve from 0.81308\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.0060 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.4075 - val_sparse_categorical_accuracy: 0.7383\n",
            "Epoch 135/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0113 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 135: val_sparse_categorical_accuracy did not improve from 0.81308\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0109 - sparse_categorical_accuracy: 0.9977 - val_loss: 1.3258 - val_sparse_categorical_accuracy: 0.7570\n",
            "Epoch 136/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0174 - sparse_categorical_accuracy: 0.9922\n",
            "Epoch 136: val_sparse_categorical_accuracy did not improve from 0.81308\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0159 - sparse_categorical_accuracy: 0.9930 - val_loss: 1.3020 - val_sparse_categorical_accuracy: 0.7103\n",
            "Epoch 137/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0051 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 137: val_sparse_categorical_accuracy did not improve from 0.81308\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.0062 - sparse_categorical_accuracy: 0.9977 - val_loss: 1.3792 - val_sparse_categorical_accuracy: 0.7196\n",
            "Epoch 138/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0170 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 138: val_sparse_categorical_accuracy did not improve from 0.81308\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.0155 - sparse_categorical_accuracy: 0.9977 - val_loss: 1.3599 - val_sparse_categorical_accuracy: 0.7290\n",
            "Epoch 139/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0231 - sparse_categorical_accuracy: 0.9875    \n",
            "Epoch 139: val_sparse_categorical_accuracy did not improve from 0.81308\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0220 - sparse_categorical_accuracy: 0.9883 - val_loss: 1.2808 - val_sparse_categorical_accuracy: 0.7290\n",
            "Epoch 140/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 6.5293e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 140: val_sparse_categorical_accuracy did not improve from 0.81308\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 6.5439e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.4209 - val_sparse_categorical_accuracy: 0.7196\n",
            "Epoch 141/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0139 - sparse_categorical_accuracy: 0.9948\n",
            "Epoch 141: val_sparse_categorical_accuracy did not improve from 0.81308\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0196 - sparse_categorical_accuracy: 0.9930 - val_loss: 1.3398 - val_sparse_categorical_accuracy: 0.7664\n",
            "Epoch 142/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0051 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 142: val_sparse_categorical_accuracy did not improve from 0.81308\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9977 - val_loss: 1.1413 - val_sparse_categorical_accuracy: 0.7383\n",
            "Epoch 143/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0171 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 143: val_sparse_categorical_accuracy did not improve from 0.81308\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0155 - sparse_categorical_accuracy: 0.9977 - val_loss: 1.2377 - val_sparse_categorical_accuracy: 0.7196\n",
            "Epoch 144/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0013 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 144: val_sparse_categorical_accuracy did not improve from 0.81308\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.0012 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.2602 - val_sparse_categorical_accuracy: 0.7290\n",
            "Epoch 145/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0078 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 145: val_sparse_categorical_accuracy did not improve from 0.81308\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9977 - val_loss: 1.0795 - val_sparse_categorical_accuracy: 0.7570\n",
            "Epoch 146/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0292 - sparse_categorical_accuracy: 0.9896\n",
            "Epoch 146: val_sparse_categorical_accuracy did not improve from 0.81308\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.0267 - sparse_categorical_accuracy: 0.9907 - val_loss: 1.1371 - val_sparse_categorical_accuracy: 0.7570\n",
            "Epoch 147/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0034 - sparse_categorical_accuracy: 1.0000    \n",
            "Epoch 147: val_sparse_categorical_accuracy did not improve from 0.81308\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0116 - sparse_categorical_accuracy: 0.9953 - val_loss: 1.1784 - val_sparse_categorical_accuracy: 0.7664\n",
            "Epoch 148/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0072 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 148: val_sparse_categorical_accuracy did not improve from 0.81308\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0104 - sparse_categorical_accuracy: 0.9953 - val_loss: 1.2759 - val_sparse_categorical_accuracy: 0.7757\n",
            "Epoch 149/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0088 - sparse_categorical_accuracy: 0.9948\n",
            "Epoch 149: val_sparse_categorical_accuracy did not improve from 0.81308\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9953 - val_loss: 1.2433 - val_sparse_categorical_accuracy: 0.7570\n",
            "Epoch 150/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0269 - sparse_categorical_accuracy: 0.9937    \n",
            "Epoch 150: val_sparse_categorical_accuracy did not improve from 0.81308\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0231 - sparse_categorical_accuracy: 0.9930 - val_loss: 1.2173 - val_sparse_categorical_accuracy: 0.7290\n",
            "Epoch 151/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0091 - sparse_categorical_accuracy: 0.9948\n",
            "Epoch 151: val_sparse_categorical_accuracy did not improve from 0.81308\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0094 - sparse_categorical_accuracy: 0.9953 - val_loss: 1.3068 - val_sparse_categorical_accuracy: 0.7570\n",
            "Epoch 152/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0153 - sparse_categorical_accuracy: 0.9937\n",
            "Epoch 152: val_sparse_categorical_accuracy did not improve from 0.81308\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0130 - sparse_categorical_accuracy: 0.9953 - val_loss: 1.4069 - val_sparse_categorical_accuracy: 0.7664\n",
            "Epoch 153/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0085 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 153: val_sparse_categorical_accuracy did not improve from 0.81308\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9977 - val_loss: 1.4730 - val_sparse_categorical_accuracy: 0.7477\n",
            "Epoch 154/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0068 - sparse_categorical_accuracy: 0.9969    \n",
            "Epoch 154: val_sparse_categorical_accuracy did not improve from 0.81308\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9977 - val_loss: 1.3218 - val_sparse_categorical_accuracy: 0.7570\n",
            "Epoch 155/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0038 - sparse_categorical_accuracy: 1.0000    \n",
            "Epoch 155: val_sparse_categorical_accuracy did not improve from 0.81308\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0037 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.2864 - val_sparse_categorical_accuracy: 0.7570\n",
            "Epoch 156/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0159 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 156: val_sparse_categorical_accuracy did not improve from 0.81308\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0127 - sparse_categorical_accuracy: 0.9977 - val_loss: 1.2047 - val_sparse_categorical_accuracy: 0.7477\n",
            "Epoch 157/900\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0084 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 157: val_sparse_categorical_accuracy did not improve from 0.81308\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0137 - sparse_categorical_accuracy: 0.9953 - val_loss: 1.0664 - val_sparse_categorical_accuracy: 0.7383\n",
            "Epoch 158/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0029 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 158: val_sparse_categorical_accuracy did not improve from 0.81308\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0026 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.0674 - val_sparse_categorical_accuracy: 0.7570\n",
            "Epoch 159/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0230 - sparse_categorical_accuracy: 0.9974    \n",
            "Epoch 159: val_sparse_categorical_accuracy did not improve from 0.81308\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0229 - sparse_categorical_accuracy: 0.9977 - val_loss: 1.1974 - val_sparse_categorical_accuracy: 0.7850\n",
            "Epoch 160/900\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0137 - sparse_categorical_accuracy: 0.9896    \n",
            "Epoch 160: val_sparse_categorical_accuracy did not improve from 0.81308\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.0124 - sparse_categorical_accuracy: 0.9907 - val_loss: 1.4020 - val_sparse_categorical_accuracy: 0.7664\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(x_traincnn, Y_train, validation_data=(x_testcnn, Y_test), batch_size=64, epochs=900, verbose=1,class_weight=class_weights,callbacks=cp_callback)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "07734eee",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07734eee",
        "outputId": "6770fc1a-bd0f-4c95-8726-d7326ead5b14"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7c4c7e97cb80>"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "model.load_weights(checkpoint_path) #to load model with highest accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "432f2bf6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "432f2bf6",
        "outputId": "c773e01b-8597-40d7-ad27-86c2ee3c0961"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Plot model accuracy over ephocs\n",
        "plt.plot(history.history['sparse_categorical_accuracy'])\n",
        "plt.plot(history.history['val_sparse_categorical_accuracy'])\n",
        "plt.ylim(0, 1)\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "1f25db3c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f25db3c",
        "outputId": "c978d1fe-6b6a-4a78-dc59-b87d0341a6f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 65ms/step - loss: 0.9529 - sparse_categorical_accuracy: 0.8131\n",
            "Pre-training accuracy: 81.3084%\n"
          ]
        }
      ],
      "source": [
        "# Calculate pre-training accuracy\n",
        "score = model.evaluate(x_testcnn, Y_test, verbose=1)\n",
        "accuracy = 100*score[1]\n",
        "\n",
        "print(\"Pre-training accuracy: %.4f%%\" % accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "6a416548",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6a416548",
        "outputId": "814dacd4-6187-4cd9-cac2-4441b7f42d75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy:  1.0\n",
            "Testing Accuracy:  0.8130841255187988\n"
          ]
        }
      ],
      "source": [
        "# Evaluating the model on the training and testing set\n",
        "score = model.evaluate(x_traincnn, Y_train, verbose=0)\n",
        "print(\"Training Accuracy: \", score[1])\n",
        "\n",
        "score = model.evaluate(x_testcnn, Y_test, verbose=0)\n",
        "print(\"Testing Accuracy: \", score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "ad9c9346",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad9c9346",
        "outputId": "6ca1f58a-f9e1-4a66-841a-cd7182adf52b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 1s 5ms/step\n"
          ]
        }
      ],
      "source": [
        "#Get predictions from model\n",
        "y_test_predictions = model.predict(x_testcnn) # it will give the prediction data of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "196ef800",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "196ef800",
        "outputId": "9538c727-c03e-49bb-8d04-f665aadbe0d9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(107, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "y_test_predictions.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "id": "9b052414",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b052414",
        "outputId": "679da432-8c31-41ba-8276-8e68da5e4490"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 3, 0, 4, 2, 0, 3, 5, 4, 3, 6, 1, 0, 1, 1, 3, 0, 1, 4, 4, 2, 1,\n",
              "       1, 6, 5, 2, 2, 3, 6, 0, 5, 1, 5, 2, 4, 1, 0, 1, 0, 2, 2, 0, 4, 1,\n",
              "       3, 0, 6, 5, 5, 3, 5, 1, 5, 6, 2, 5, 0, 2, 5, 1, 5, 4, 4, 1, 5, 3,\n",
              "       0, 3, 1, 1, 3, 1, 5, 2, 2, 1, 6, 2, 0, 4, 1, 3, 5, 0, 6, 6, 5, 2,\n",
              "       4, 3, 2, 2, 5, 2, 2, 3, 2, 0, 6, 3, 4, 1, 5, 5, 4, 1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ],
      "source": [
        "y_test_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "id": "4162138e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4162138e",
        "outputId": "72f48bd5-f42f-4f44-ac0b-2d18ab768149"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 3, 0, 4, 2, 0, 3, 5, 4, 3, 6, 1, 0, 1, 1, 3, 0, 1, 4, 4, 2, 1,\n",
              "       1, 6, 5, 2, 2, 3, 6, 0, 5, 1, 5, 2, 4, 1, 0, 1, 0, 2, 2, 0, 4, 1,\n",
              "       3, 0, 6, 5, 5, 3, 5, 1, 5, 6, 2, 5, 0, 2, 5, 1, 5, 4, 4, 1, 5, 3,\n",
              "       0, 3, 1, 1, 3, 1, 5, 2, 2, 1, 6, 2, 0, 4, 1, 3, 5, 0, 6, 6, 5, 2,\n",
              "       4, 3, 2, 2, 5, 2, 2, 3, 2, 0, 6, 3, 4, 1, 5, 5, 4, 1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ],
      "source": [
        "y_test_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "33de2d8e",
      "metadata": {
        "id": "33de2d8e"
      },
      "outputs": [],
      "source": [
        "#df.replace({ 'neutral': 0, 'calm': 1,'happy': 2,'sad': 3, 'angry':4,'fearful':5,'disgust':6,'surprised':7}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "a7ee95c4",
      "metadata": {
        "id": "a7ee95c4"
      },
      "outputs": [],
      "source": [
        "emotions={\n",
        " 0: 'happyness',\n",
        " 1: 'neutral',\n",
        " 2: 'anger',\n",
        " 3: 'sadness',\n",
        " 4: 'fear',\n",
        " 5: 'boredom',\n",
        " 6: 'disgust',\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "c48c660c",
      "metadata": {
        "id": "c48c660c"
      },
      "outputs": [],
      "source": [
        "label=[]\n",
        "for i in y_test_predictions:\n",
        "    label1=emotions[i]\n",
        "    label.append(label1)\n",
        "label\n",
        "y_pred_acc=np.array(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "fe27f0ca",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe27f0ca",
        "outputId": "61f59d23-d9e0-46b1-ac89-9d11bf1440c2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['anger', 'sadness', 'happyness', 'fear', 'anger', 'happyness',\n",
              "       'sadness', 'boredom', 'fear', 'sadness', 'disgust', 'neutral',\n",
              "       'happyness', 'neutral', 'neutral', 'sadness', 'happyness',\n",
              "       'neutral', 'fear', 'fear', 'anger', 'neutral', 'neutral',\n",
              "       'disgust', 'boredom', 'anger', 'anger', 'sadness', 'disgust',\n",
              "       'happyness', 'boredom', 'neutral', 'boredom', 'anger', 'fear',\n",
              "       'neutral', 'happyness', 'neutral', 'happyness', 'anger', 'anger',\n",
              "       'happyness', 'fear', 'neutral', 'sadness', 'happyness', 'disgust',\n",
              "       'boredom', 'boredom', 'sadness', 'boredom', 'neutral', 'boredom',\n",
              "       'disgust', 'anger', 'boredom', 'happyness', 'anger', 'boredom',\n",
              "       'neutral', 'boredom', 'fear', 'fear', 'neutral', 'boredom',\n",
              "       'sadness', 'happyness', 'sadness', 'neutral', 'neutral', 'sadness',\n",
              "       'neutral', 'boredom', 'anger', 'anger', 'neutral', 'disgust',\n",
              "       'anger', 'happyness', 'fear', 'neutral', 'sadness', 'boredom',\n",
              "       'happyness', 'disgust', 'disgust', 'boredom', 'anger', 'fear',\n",
              "       'sadness', 'anger', 'anger', 'boredom', 'anger', 'anger',\n",
              "       'sadness', 'anger', 'happyness', 'disgust', 'sadness', 'fear',\n",
              "       'neutral', 'boredom', 'boredom', 'fear', 'neutral', 'anger'],\n",
              "      dtype='<U9')"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "y_pred_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "c11f7f56",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c11f7f56",
        "outputId": "b39e4148-8ffb-4c55-8579-16684df6a421"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "458    2\n",
              "235    3\n",
              "281    0\n",
              "55     4\n",
              "284    2\n",
              "      ..\n",
              "355    5\n",
              "392    5\n",
              "162    4\n",
              "283    1\n",
              "499    2\n",
              "Name: Label, Length: 107, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "Y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "f1ef42f3",
      "metadata": {
        "id": "f1ef42f3"
      },
      "outputs": [],
      "source": [
        "#df.replace({ 'neutral': 0, 'calm': 1,'happy': 2,'sad': 3, 'angry':4,'fearful':5,'disgust':6,'surprised':7}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "185d8266",
      "metadata": {
        "id": "185d8266"
      },
      "outputs": [],
      "source": [
        "emotion={\n",
        " 0: 'happyness',\n",
        " 1: 'neutral',\n",
        " 2: 'anger',\n",
        " 3: 'sadness',\n",
        " 4: 'fear',\n",
        " 5: 'boredom',\n",
        " 6: 'disgust',\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "f19f7ff3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "f19f7ff3",
        "outputId": "fe4c566d-a706-4ffe-9440-d22f2cc018cf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'happyness'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 84
        }
      ],
      "source": [
        "emotion[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "8fd2ffee",
      "metadata": {
        "id": "8fd2ffee"
      },
      "outputs": [],
      "source": [
        "label_test=[]\n",
        "for i in Y_test:\n",
        "    label_test.append(emotion[i])\n",
        "label_test\n",
        "y_true_accu=np.array(label_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "31a3449b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31a3449b",
        "outputId": "973321bf-a69e-4ff4-e6da-192635fe6985"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['anger', 'sadness', 'happyness', 'fear', 'anger', 'happyness',\n",
              "       'sadness', 'boredom', 'fear', 'sadness', 'disgust', 'neutral',\n",
              "       'happyness', 'happyness', 'neutral', 'sadness', 'anger', 'neutral',\n",
              "       'fear', 'fear', 'anger', 'boredom', 'boredom', 'disgust',\n",
              "       'boredom', 'anger', 'anger', 'sadness', 'disgust', 'happyness',\n",
              "       'boredom', 'neutral', 'boredom', 'anger', 'fear', 'neutral',\n",
              "       'happyness', 'neutral', 'anger', 'happyness', 'anger', 'happyness',\n",
              "       'fear', 'neutral', 'boredom', 'happyness', 'disgust', 'neutral',\n",
              "       'boredom', 'sadness', 'neutral', 'neutral', 'boredom', 'disgust',\n",
              "       'anger', 'boredom', 'happyness', 'anger', 'boredom', 'neutral',\n",
              "       'neutral', 'fear', 'fear', 'disgust', 'sadness', 'sadness',\n",
              "       'happyness', 'sadness', 'neutral', 'neutral', 'sadness', 'boredom',\n",
              "       'boredom', 'happyness', 'anger', 'neutral', 'happyness', 'anger',\n",
              "       'fear', 'fear', 'disgust', 'fear', 'boredom', 'happyness',\n",
              "       'disgust', 'disgust', 'boredom', 'happyness', 'fear', 'sadness',\n",
              "       'anger', 'anger', 'boredom', 'anger', 'anger', 'sadness', 'anger',\n",
              "       'happyness', 'disgust', 'sadness', 'fear', 'disgust', 'boredom',\n",
              "       'boredom', 'fear', 'neutral', 'anger'], dtype='<U9')"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ],
      "source": [
        "y_true_accu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "id": "5807d3ec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5807d3ec",
        "outputId": "ecbc298f-f7a0-4295-f76f-0598242e4539"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 81.31%\n"
          ]
        }
      ],
      "source": [
        "#DataFlair - Calculate the accuracy of our model\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy=accuracy_score(y_true=y_true_accu, y_pred=y_pred_acc)\n",
        "\n",
        "#DataFlair - Print the accuracy\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "6635c085",
      "metadata": {
        "id": "6635c085"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm=confusion_matrix(y_true=y_true_accu, y_pred=y_pred_acc)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nD8Eq0d-OcaZ",
        "outputId": "04b4e2f7-804f-4f72-f7ae-b5d08b497c27"
      },
      "id": "nD8Eq0d-OcaZ",
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[17  0  0  0  2  0  0]\n",
            " [ 0 14  0  0  0  3  1]\n",
            " [ 0  0  8  0  0  3  0]\n",
            " [ 0  0  0 12  1  0  1]\n",
            " [ 3  0  1  0 11  1  0]\n",
            " [ 0  3  0  0  0 13  0]\n",
            " [ 0  1  0  0  0  0 12]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "id": "2f781089",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f781089",
        "outputId": "591a51d7-0b22-46ae-ec8b-0c02407edb24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.85      0.89      0.87        19\n",
            "     boredom       0.78      0.78      0.78        18\n",
            "     disgust       0.89      0.73      0.80        11\n",
            "        fear       1.00      0.86      0.92        14\n",
            "   happyness       0.79      0.69      0.73        16\n",
            "     neutral       0.65      0.81      0.72        16\n",
            "     sadness       0.86      0.92      0.89        13\n",
            "\n",
            "    accuracy                           0.81       107\n",
            "   macro avg       0.83      0.81      0.82       107\n",
            "weighted avg       0.82      0.81      0.81       107\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_true_accu,y_pred_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "id": "673530e6",
      "metadata": {
        "id": "673530e6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "id": "ae5cce6c",
      "metadata": {
        "id": "ae5cce6c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "id": "964855f9",
      "metadata": {
        "id": "964855f9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "id": "5f2c0e1a",
      "metadata": {
        "id": "5f2c0e1a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "id": "112a6c83",
      "metadata": {
        "id": "112a6c83"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}