{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e1f95dfd",
      "metadata": {
        "id": "e1f95dfd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import seaborn as sns\n",
        "import librosa\n",
        "import librosa.display\n",
        "import IPython.display as pld\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow.keras as keras\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c899a87f",
      "metadata": {
        "id": "c899a87f"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/DATASETS/EmoDB Dataset/max_feature_whole_speech_emodb_csvfile.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e63e29bc",
      "metadata": {
        "id": "e63e29bc"
      },
      "outputs": [],
      "source": [
        "df=df.fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "3db85b78",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "3db85b78",
        "outputId": "809945a7-677f-44da-d5ac-b8e079a42fd8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        filename          1          2          3          4          5  \\\n",
              "0    03a01Fa.wav -482.45233  62.835957  -0.348998  26.264595   2.978607   \n",
              "1    03a01Nc.wav -469.48477  88.400730  -7.127512  29.156132   5.335554   \n",
              "2    03a01Wa.wav -434.88647  41.972150 -29.416862  18.537344  -4.156565   \n",
              "3    03a02Fc.wav -454.89886  45.067265  -0.193278  15.111545   3.080835   \n",
              "4    03a02Nc.wav -447.12630  86.114920   4.772520  38.097256   8.324276   \n",
              "..           ...        ...        ...        ...        ...        ...   \n",
              "530  16b10Lb.wav -418.62490  57.015880   6.383415  47.618423  -8.051490   \n",
              "531  16b10Tb.wav -427.36716  51.473750   4.835125  40.900140   6.937289   \n",
              "532  16b10Td.wav -467.15588  52.217026  10.470471  47.414780   8.690019   \n",
              "533  16b10Wa.wav -526.19570  11.317784 -18.942173  29.540787 -28.057306   \n",
              "534  16b10Wb.wav -437.97220   5.289146 -22.667547  25.394840 -28.545520   \n",
              "\n",
              "             6          7         8          9  ...       251       252  \\\n",
              "0     6.900927 -13.006243  0.273391  -9.196591  ...  0.675823  0.684034   \n",
              "1     7.147227  -6.727572 -8.307674  -3.364513  ...  0.635522  0.544438   \n",
              "2     5.257353 -11.410935 -8.983023 -11.285996  ...  0.648380  0.675295   \n",
              "3     4.204241 -10.440731 -6.615343 -16.249382  ...  0.575784  0.523305   \n",
              "4     8.538317  -4.507682 -7.680664  -7.317249  ...  0.615263  0.566964   \n",
              "..         ...        ...       ...        ...  ...       ...       ...   \n",
              "530   4.213936 -15.029120 -2.448467 -10.805821  ...  0.569263  0.551809   \n",
              "531  13.700687  -8.331753 -0.583414  -6.279562  ...  0.638155  0.574542   \n",
              "532  15.601270  -2.032935  4.985774  -7.432734  ...  0.523647  0.509723   \n",
              "533   1.299599 -16.251814 -7.512440 -23.191568  ...  0.528861  0.501070   \n",
              "534   0.428451 -11.650926 -8.022680 -18.337156  ...  0.495079  0.539387   \n",
              "\n",
              "          253       254       255       256       257       258       259  \\\n",
              "0    0.627376 -0.001574  0.012645 -0.027069  0.019313 -0.002252 -0.006220   \n",
              "1    0.532856 -0.018488  0.011973 -0.011038  0.079758 -0.021044 -0.019445   \n",
              "2    0.560000 -0.010576 -0.000228  0.011102 -0.074188  0.012116 -0.000779   \n",
              "3    0.423375  0.009395 -0.025547 -0.035554 -0.025885  0.011198 -0.000163   \n",
              "4    0.605103 -0.008389 -0.051995 -0.056544 -0.020014  0.013964  0.008349   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "530  0.576764  0.016046 -0.025610  0.025426 -0.094371  0.008999 -0.004985   \n",
              "531  0.503516  0.019632  0.046315  0.074801  0.018078  0.022948 -0.016365   \n",
              "532  0.498566  0.051532  0.015525 -0.006052  0.018201  0.004361 -0.021649   \n",
              "533  0.496900  0.007856  0.005917 -0.045393 -0.004246 -0.001628  0.015051   \n",
              "534  0.527394 -0.001086  0.013948  0.013274 -0.056855 -0.001004 -0.001355   \n",
              "\n",
              "         Label  \n",
              "0    happyness  \n",
              "1      neutral  \n",
              "2        anger  \n",
              "3    happyness  \n",
              "4      neutral  \n",
              "..         ...  \n",
              "530    boredom  \n",
              "531    sadness  \n",
              "532    sadness  \n",
              "533      anger  \n",
              "534      anger  \n",
              "\n",
              "[535 rows x 261 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6d556c9f-2594-4d33-b16b-828f4743d1a8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>251</th>\n",
              "      <th>252</th>\n",
              "      <th>253</th>\n",
              "      <th>254</th>\n",
              "      <th>255</th>\n",
              "      <th>256</th>\n",
              "      <th>257</th>\n",
              "      <th>258</th>\n",
              "      <th>259</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>03a01Fa.wav</td>\n",
              "      <td>-482.45233</td>\n",
              "      <td>62.835957</td>\n",
              "      <td>-0.348998</td>\n",
              "      <td>26.264595</td>\n",
              "      <td>2.978607</td>\n",
              "      <td>6.900927</td>\n",
              "      <td>-13.006243</td>\n",
              "      <td>0.273391</td>\n",
              "      <td>-9.196591</td>\n",
              "      <td>...</td>\n",
              "      <td>0.675823</td>\n",
              "      <td>0.684034</td>\n",
              "      <td>0.627376</td>\n",
              "      <td>-0.001574</td>\n",
              "      <td>0.012645</td>\n",
              "      <td>-0.027069</td>\n",
              "      <td>0.019313</td>\n",
              "      <td>-0.002252</td>\n",
              "      <td>-0.006220</td>\n",
              "      <td>happyness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>03a01Nc.wav</td>\n",
              "      <td>-469.48477</td>\n",
              "      <td>88.400730</td>\n",
              "      <td>-7.127512</td>\n",
              "      <td>29.156132</td>\n",
              "      <td>5.335554</td>\n",
              "      <td>7.147227</td>\n",
              "      <td>-6.727572</td>\n",
              "      <td>-8.307674</td>\n",
              "      <td>-3.364513</td>\n",
              "      <td>...</td>\n",
              "      <td>0.635522</td>\n",
              "      <td>0.544438</td>\n",
              "      <td>0.532856</td>\n",
              "      <td>-0.018488</td>\n",
              "      <td>0.011973</td>\n",
              "      <td>-0.011038</td>\n",
              "      <td>0.079758</td>\n",
              "      <td>-0.021044</td>\n",
              "      <td>-0.019445</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>03a01Wa.wav</td>\n",
              "      <td>-434.88647</td>\n",
              "      <td>41.972150</td>\n",
              "      <td>-29.416862</td>\n",
              "      <td>18.537344</td>\n",
              "      <td>-4.156565</td>\n",
              "      <td>5.257353</td>\n",
              "      <td>-11.410935</td>\n",
              "      <td>-8.983023</td>\n",
              "      <td>-11.285996</td>\n",
              "      <td>...</td>\n",
              "      <td>0.648380</td>\n",
              "      <td>0.675295</td>\n",
              "      <td>0.560000</td>\n",
              "      <td>-0.010576</td>\n",
              "      <td>-0.000228</td>\n",
              "      <td>0.011102</td>\n",
              "      <td>-0.074188</td>\n",
              "      <td>0.012116</td>\n",
              "      <td>-0.000779</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>03a02Fc.wav</td>\n",
              "      <td>-454.89886</td>\n",
              "      <td>45.067265</td>\n",
              "      <td>-0.193278</td>\n",
              "      <td>15.111545</td>\n",
              "      <td>3.080835</td>\n",
              "      <td>4.204241</td>\n",
              "      <td>-10.440731</td>\n",
              "      <td>-6.615343</td>\n",
              "      <td>-16.249382</td>\n",
              "      <td>...</td>\n",
              "      <td>0.575784</td>\n",
              "      <td>0.523305</td>\n",
              "      <td>0.423375</td>\n",
              "      <td>0.009395</td>\n",
              "      <td>-0.025547</td>\n",
              "      <td>-0.035554</td>\n",
              "      <td>-0.025885</td>\n",
              "      <td>0.011198</td>\n",
              "      <td>-0.000163</td>\n",
              "      <td>happyness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>03a02Nc.wav</td>\n",
              "      <td>-447.12630</td>\n",
              "      <td>86.114920</td>\n",
              "      <td>4.772520</td>\n",
              "      <td>38.097256</td>\n",
              "      <td>8.324276</td>\n",
              "      <td>8.538317</td>\n",
              "      <td>-4.507682</td>\n",
              "      <td>-7.680664</td>\n",
              "      <td>-7.317249</td>\n",
              "      <td>...</td>\n",
              "      <td>0.615263</td>\n",
              "      <td>0.566964</td>\n",
              "      <td>0.605103</td>\n",
              "      <td>-0.008389</td>\n",
              "      <td>-0.051995</td>\n",
              "      <td>-0.056544</td>\n",
              "      <td>-0.020014</td>\n",
              "      <td>0.013964</td>\n",
              "      <td>0.008349</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>530</th>\n",
              "      <td>16b10Lb.wav</td>\n",
              "      <td>-418.62490</td>\n",
              "      <td>57.015880</td>\n",
              "      <td>6.383415</td>\n",
              "      <td>47.618423</td>\n",
              "      <td>-8.051490</td>\n",
              "      <td>4.213936</td>\n",
              "      <td>-15.029120</td>\n",
              "      <td>-2.448467</td>\n",
              "      <td>-10.805821</td>\n",
              "      <td>...</td>\n",
              "      <td>0.569263</td>\n",
              "      <td>0.551809</td>\n",
              "      <td>0.576764</td>\n",
              "      <td>0.016046</td>\n",
              "      <td>-0.025610</td>\n",
              "      <td>0.025426</td>\n",
              "      <td>-0.094371</td>\n",
              "      <td>0.008999</td>\n",
              "      <td>-0.004985</td>\n",
              "      <td>boredom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>531</th>\n",
              "      <td>16b10Tb.wav</td>\n",
              "      <td>-427.36716</td>\n",
              "      <td>51.473750</td>\n",
              "      <td>4.835125</td>\n",
              "      <td>40.900140</td>\n",
              "      <td>6.937289</td>\n",
              "      <td>13.700687</td>\n",
              "      <td>-8.331753</td>\n",
              "      <td>-0.583414</td>\n",
              "      <td>-6.279562</td>\n",
              "      <td>...</td>\n",
              "      <td>0.638155</td>\n",
              "      <td>0.574542</td>\n",
              "      <td>0.503516</td>\n",
              "      <td>0.019632</td>\n",
              "      <td>0.046315</td>\n",
              "      <td>0.074801</td>\n",
              "      <td>0.018078</td>\n",
              "      <td>0.022948</td>\n",
              "      <td>-0.016365</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>532</th>\n",
              "      <td>16b10Td.wav</td>\n",
              "      <td>-467.15588</td>\n",
              "      <td>52.217026</td>\n",
              "      <td>10.470471</td>\n",
              "      <td>47.414780</td>\n",
              "      <td>8.690019</td>\n",
              "      <td>15.601270</td>\n",
              "      <td>-2.032935</td>\n",
              "      <td>4.985774</td>\n",
              "      <td>-7.432734</td>\n",
              "      <td>...</td>\n",
              "      <td>0.523647</td>\n",
              "      <td>0.509723</td>\n",
              "      <td>0.498566</td>\n",
              "      <td>0.051532</td>\n",
              "      <td>0.015525</td>\n",
              "      <td>-0.006052</td>\n",
              "      <td>0.018201</td>\n",
              "      <td>0.004361</td>\n",
              "      <td>-0.021649</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>533</th>\n",
              "      <td>16b10Wa.wav</td>\n",
              "      <td>-526.19570</td>\n",
              "      <td>11.317784</td>\n",
              "      <td>-18.942173</td>\n",
              "      <td>29.540787</td>\n",
              "      <td>-28.057306</td>\n",
              "      <td>1.299599</td>\n",
              "      <td>-16.251814</td>\n",
              "      <td>-7.512440</td>\n",
              "      <td>-23.191568</td>\n",
              "      <td>...</td>\n",
              "      <td>0.528861</td>\n",
              "      <td>0.501070</td>\n",
              "      <td>0.496900</td>\n",
              "      <td>0.007856</td>\n",
              "      <td>0.005917</td>\n",
              "      <td>-0.045393</td>\n",
              "      <td>-0.004246</td>\n",
              "      <td>-0.001628</td>\n",
              "      <td>0.015051</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>534</th>\n",
              "      <td>16b10Wb.wav</td>\n",
              "      <td>-437.97220</td>\n",
              "      <td>5.289146</td>\n",
              "      <td>-22.667547</td>\n",
              "      <td>25.394840</td>\n",
              "      <td>-28.545520</td>\n",
              "      <td>0.428451</td>\n",
              "      <td>-11.650926</td>\n",
              "      <td>-8.022680</td>\n",
              "      <td>-18.337156</td>\n",
              "      <td>...</td>\n",
              "      <td>0.495079</td>\n",
              "      <td>0.539387</td>\n",
              "      <td>0.527394</td>\n",
              "      <td>-0.001086</td>\n",
              "      <td>0.013948</td>\n",
              "      <td>0.013274</td>\n",
              "      <td>-0.056855</td>\n",
              "      <td>-0.001004</td>\n",
              "      <td>-0.001355</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>535 rows × 261 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6d556c9f-2594-4d33-b16b-828f4743d1a8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6d556c9f-2594-4d33-b16b-828f4743d1a8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6d556c9f-2594-4d33-b16b-828f4743d1a8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-477be043-3a51-4e23-afdb-9a8370359ddd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-477be043-3a51-4e23-afdb-9a8370359ddd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-477be043-3a51-4e23-afdb-9a8370359ddd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "38a8374f",
      "metadata": {
        "id": "38a8374f"
      },
      "outputs": [],
      "source": [
        "df.replace({ 'happyness': 0, 'neutral': 1,'anger': 2,'sadness': 3, 'fear':4,'boredom':5,'disgust':6}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "9cf4576c",
      "metadata": {
        "id": "9cf4576c"
      },
      "outputs": [],
      "source": [
        "x=df.iloc[:,1:41]\n",
        "y=df.iloc[:,-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "aa7f6b05",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "aa7f6b05",
        "outputId": "21a7fac6-3783-4052-b982-aeffcbfa4aa8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             1          2          3          4          5          6  \\\n",
              "0   -482.45233  62.835957  -0.348998  26.264595   2.978607   6.900927   \n",
              "1   -469.48477  88.400730  -7.127512  29.156132   5.335554   7.147227   \n",
              "2   -434.88647  41.972150 -29.416862  18.537344  -4.156565   5.257353   \n",
              "3   -454.89886  45.067265  -0.193278  15.111545   3.080835   4.204241   \n",
              "4   -447.12630  86.114920   4.772520  38.097256   8.324276   8.538317   \n",
              "..         ...        ...        ...        ...        ...        ...   \n",
              "530 -418.62490  57.015880   6.383415  47.618423  -8.051490   4.213936   \n",
              "531 -427.36716  51.473750   4.835125  40.900140   6.937289  13.700687   \n",
              "532 -467.15588  52.217026  10.470471  47.414780   8.690019  15.601270   \n",
              "533 -526.19570  11.317784 -18.942173  29.540787 -28.057306   1.299599   \n",
              "534 -437.97220   5.289146 -22.667547  25.394840 -28.545520   0.428451   \n",
              "\n",
              "             7         8          9         10  ...        31        32  \\\n",
              "0   -13.006243  0.273391  -9.196591   1.597646  ... -3.409270 -5.413244   \n",
              "1    -6.727572 -8.307674  -3.364513   7.846351  ... -5.047899 -6.706718   \n",
              "2   -11.410935 -8.983023 -11.285996  -2.445232  ... -2.040512 -3.035521   \n",
              "3   -10.440731 -6.615343 -16.249382  -7.022445  ... -1.957219 -4.853336   \n",
              "4    -4.507682 -7.680664  -7.317249   2.848643  ... -4.924419 -8.395385   \n",
              "..         ...       ...        ...        ...  ...       ...       ...   \n",
              "530 -15.029120 -2.448467 -10.805821  -3.372870  ... -2.760351 -4.033802   \n",
              "531  -8.331753 -0.583414  -6.279562  -1.778869  ...  3.584273  0.085885   \n",
              "532  -2.032935  4.985774  -7.432734   2.523657  ... -4.083610 -4.791102   \n",
              "533 -16.251814 -7.512440 -23.191568 -13.485355  ...  1.271853 -3.008154   \n",
              "534 -11.650926 -8.022680 -18.337156 -14.782391  ...  0.051370 -1.901394   \n",
              "\n",
              "            33         34         35         36        37        38        39  \\\n",
              "0    -9.903300  -9.461795 -11.410793  -7.792785 -4.598618 -1.893468  0.230821   \n",
              "1   -10.045481 -11.882533 -12.027461 -10.450580 -6.670032 -3.885782 -0.594336   \n",
              "2    -5.395728  -6.573817  -7.666299  -6.801901 -3.527732  1.548335  0.199676   \n",
              "3    -5.930995  -6.787319  -8.053974  -7.839906 -5.059597  0.171459  1.393567   \n",
              "4   -10.831446 -12.918998 -12.387193 -11.704714 -7.736867 -4.567762 -1.578654   \n",
              "..         ...        ...        ...        ...       ...       ...       ...   \n",
              "530  -7.910801  -8.805643 -11.735242  -9.766793 -4.004450 -1.724268  1.669646   \n",
              "531  -3.021229  -6.543844  -7.785308  -8.447594 -3.718233 -2.430141 -1.299946   \n",
              "532  -7.304545  -7.000581  -8.297956  -6.995429 -3.757356 -2.086286 -0.455316   \n",
              "533  -7.199957  -6.784047  -9.184513  -4.848257 -4.094945  0.953147  0.643771   \n",
              "534  -6.514058  -6.647235  -9.270068  -6.796636 -4.169386  0.677490  1.334848   \n",
              "\n",
              "           40  \n",
              "0   -0.455839  \n",
              "1   -1.361155  \n",
              "2    2.296331  \n",
              "3   -0.334069  \n",
              "4   -2.273726  \n",
              "..        ...  \n",
              "530  2.706617  \n",
              "531 -0.641451  \n",
              "532  0.501709  \n",
              "533  3.257232  \n",
              "534  1.308542  \n",
              "\n",
              "[535 rows x 40 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-89ba590a-2ffe-4d89-a524-64e0b349747f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>...</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-482.45233</td>\n",
              "      <td>62.835957</td>\n",
              "      <td>-0.348998</td>\n",
              "      <td>26.264595</td>\n",
              "      <td>2.978607</td>\n",
              "      <td>6.900927</td>\n",
              "      <td>-13.006243</td>\n",
              "      <td>0.273391</td>\n",
              "      <td>-9.196591</td>\n",
              "      <td>1.597646</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.409270</td>\n",
              "      <td>-5.413244</td>\n",
              "      <td>-9.903300</td>\n",
              "      <td>-9.461795</td>\n",
              "      <td>-11.410793</td>\n",
              "      <td>-7.792785</td>\n",
              "      <td>-4.598618</td>\n",
              "      <td>-1.893468</td>\n",
              "      <td>0.230821</td>\n",
              "      <td>-0.455839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-469.48477</td>\n",
              "      <td>88.400730</td>\n",
              "      <td>-7.127512</td>\n",
              "      <td>29.156132</td>\n",
              "      <td>5.335554</td>\n",
              "      <td>7.147227</td>\n",
              "      <td>-6.727572</td>\n",
              "      <td>-8.307674</td>\n",
              "      <td>-3.364513</td>\n",
              "      <td>7.846351</td>\n",
              "      <td>...</td>\n",
              "      <td>-5.047899</td>\n",
              "      <td>-6.706718</td>\n",
              "      <td>-10.045481</td>\n",
              "      <td>-11.882533</td>\n",
              "      <td>-12.027461</td>\n",
              "      <td>-10.450580</td>\n",
              "      <td>-6.670032</td>\n",
              "      <td>-3.885782</td>\n",
              "      <td>-0.594336</td>\n",
              "      <td>-1.361155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-434.88647</td>\n",
              "      <td>41.972150</td>\n",
              "      <td>-29.416862</td>\n",
              "      <td>18.537344</td>\n",
              "      <td>-4.156565</td>\n",
              "      <td>5.257353</td>\n",
              "      <td>-11.410935</td>\n",
              "      <td>-8.983023</td>\n",
              "      <td>-11.285996</td>\n",
              "      <td>-2.445232</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.040512</td>\n",
              "      <td>-3.035521</td>\n",
              "      <td>-5.395728</td>\n",
              "      <td>-6.573817</td>\n",
              "      <td>-7.666299</td>\n",
              "      <td>-6.801901</td>\n",
              "      <td>-3.527732</td>\n",
              "      <td>1.548335</td>\n",
              "      <td>0.199676</td>\n",
              "      <td>2.296331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-454.89886</td>\n",
              "      <td>45.067265</td>\n",
              "      <td>-0.193278</td>\n",
              "      <td>15.111545</td>\n",
              "      <td>3.080835</td>\n",
              "      <td>4.204241</td>\n",
              "      <td>-10.440731</td>\n",
              "      <td>-6.615343</td>\n",
              "      <td>-16.249382</td>\n",
              "      <td>-7.022445</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.957219</td>\n",
              "      <td>-4.853336</td>\n",
              "      <td>-5.930995</td>\n",
              "      <td>-6.787319</td>\n",
              "      <td>-8.053974</td>\n",
              "      <td>-7.839906</td>\n",
              "      <td>-5.059597</td>\n",
              "      <td>0.171459</td>\n",
              "      <td>1.393567</td>\n",
              "      <td>-0.334069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-447.12630</td>\n",
              "      <td>86.114920</td>\n",
              "      <td>4.772520</td>\n",
              "      <td>38.097256</td>\n",
              "      <td>8.324276</td>\n",
              "      <td>8.538317</td>\n",
              "      <td>-4.507682</td>\n",
              "      <td>-7.680664</td>\n",
              "      <td>-7.317249</td>\n",
              "      <td>2.848643</td>\n",
              "      <td>...</td>\n",
              "      <td>-4.924419</td>\n",
              "      <td>-8.395385</td>\n",
              "      <td>-10.831446</td>\n",
              "      <td>-12.918998</td>\n",
              "      <td>-12.387193</td>\n",
              "      <td>-11.704714</td>\n",
              "      <td>-7.736867</td>\n",
              "      <td>-4.567762</td>\n",
              "      <td>-1.578654</td>\n",
              "      <td>-2.273726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>530</th>\n",
              "      <td>-418.62490</td>\n",
              "      <td>57.015880</td>\n",
              "      <td>6.383415</td>\n",
              "      <td>47.618423</td>\n",
              "      <td>-8.051490</td>\n",
              "      <td>4.213936</td>\n",
              "      <td>-15.029120</td>\n",
              "      <td>-2.448467</td>\n",
              "      <td>-10.805821</td>\n",
              "      <td>-3.372870</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.760351</td>\n",
              "      <td>-4.033802</td>\n",
              "      <td>-7.910801</td>\n",
              "      <td>-8.805643</td>\n",
              "      <td>-11.735242</td>\n",
              "      <td>-9.766793</td>\n",
              "      <td>-4.004450</td>\n",
              "      <td>-1.724268</td>\n",
              "      <td>1.669646</td>\n",
              "      <td>2.706617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>531</th>\n",
              "      <td>-427.36716</td>\n",
              "      <td>51.473750</td>\n",
              "      <td>4.835125</td>\n",
              "      <td>40.900140</td>\n",
              "      <td>6.937289</td>\n",
              "      <td>13.700687</td>\n",
              "      <td>-8.331753</td>\n",
              "      <td>-0.583414</td>\n",
              "      <td>-6.279562</td>\n",
              "      <td>-1.778869</td>\n",
              "      <td>...</td>\n",
              "      <td>3.584273</td>\n",
              "      <td>0.085885</td>\n",
              "      <td>-3.021229</td>\n",
              "      <td>-6.543844</td>\n",
              "      <td>-7.785308</td>\n",
              "      <td>-8.447594</td>\n",
              "      <td>-3.718233</td>\n",
              "      <td>-2.430141</td>\n",
              "      <td>-1.299946</td>\n",
              "      <td>-0.641451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>532</th>\n",
              "      <td>-467.15588</td>\n",
              "      <td>52.217026</td>\n",
              "      <td>10.470471</td>\n",
              "      <td>47.414780</td>\n",
              "      <td>8.690019</td>\n",
              "      <td>15.601270</td>\n",
              "      <td>-2.032935</td>\n",
              "      <td>4.985774</td>\n",
              "      <td>-7.432734</td>\n",
              "      <td>2.523657</td>\n",
              "      <td>...</td>\n",
              "      <td>-4.083610</td>\n",
              "      <td>-4.791102</td>\n",
              "      <td>-7.304545</td>\n",
              "      <td>-7.000581</td>\n",
              "      <td>-8.297956</td>\n",
              "      <td>-6.995429</td>\n",
              "      <td>-3.757356</td>\n",
              "      <td>-2.086286</td>\n",
              "      <td>-0.455316</td>\n",
              "      <td>0.501709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>533</th>\n",
              "      <td>-526.19570</td>\n",
              "      <td>11.317784</td>\n",
              "      <td>-18.942173</td>\n",
              "      <td>29.540787</td>\n",
              "      <td>-28.057306</td>\n",
              "      <td>1.299599</td>\n",
              "      <td>-16.251814</td>\n",
              "      <td>-7.512440</td>\n",
              "      <td>-23.191568</td>\n",
              "      <td>-13.485355</td>\n",
              "      <td>...</td>\n",
              "      <td>1.271853</td>\n",
              "      <td>-3.008154</td>\n",
              "      <td>-7.199957</td>\n",
              "      <td>-6.784047</td>\n",
              "      <td>-9.184513</td>\n",
              "      <td>-4.848257</td>\n",
              "      <td>-4.094945</td>\n",
              "      <td>0.953147</td>\n",
              "      <td>0.643771</td>\n",
              "      <td>3.257232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>534</th>\n",
              "      <td>-437.97220</td>\n",
              "      <td>5.289146</td>\n",
              "      <td>-22.667547</td>\n",
              "      <td>25.394840</td>\n",
              "      <td>-28.545520</td>\n",
              "      <td>0.428451</td>\n",
              "      <td>-11.650926</td>\n",
              "      <td>-8.022680</td>\n",
              "      <td>-18.337156</td>\n",
              "      <td>-14.782391</td>\n",
              "      <td>...</td>\n",
              "      <td>0.051370</td>\n",
              "      <td>-1.901394</td>\n",
              "      <td>-6.514058</td>\n",
              "      <td>-6.647235</td>\n",
              "      <td>-9.270068</td>\n",
              "      <td>-6.796636</td>\n",
              "      <td>-4.169386</td>\n",
              "      <td>0.677490</td>\n",
              "      <td>1.334848</td>\n",
              "      <td>1.308542</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>535 rows × 40 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-89ba590a-2ffe-4d89-a524-64e0b349747f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-89ba590a-2ffe-4d89-a524-64e0b349747f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-89ba590a-2ffe-4d89-a524-64e0b349747f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d748e0e8-366a-48f6-a0db-44f46b696e04\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d748e0e8-366a-48f6-a0db-44f46b696e04')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d748e0e8-366a-48f6-a0db-44f46b696e04 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "x"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "d4254451",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4254451",
        "outputId": "701d5d9a-3be6-4773-905d-5956f4160741"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      0\n",
              "1      1\n",
              "2      2\n",
              "3      0\n",
              "4      1\n",
              "      ..\n",
              "530    5\n",
              "531    3\n",
              "532    3\n",
              "533    2\n",
              "534    2\n",
              "Name: Label, Length: 535, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "7b9e0eec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "7b9e0eec",
        "outputId": "c13cc441-3ce1-4c63-f3ea-5174f59c0086"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: ylabel='count'>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "sns.countplot(df['Label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "e5dddb1f",
      "metadata": {
        "id": "e5dddb1f"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "9c434c48",
      "metadata": {
        "id": "9c434c48"
      },
      "outputs": [],
      "source": [
        "x_train,x_test,Y_train,Y_test=train_test_split(x,y,test_size=0.2,random_state=7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "1f07cf5e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f07cf5e",
        "outputId": "9a8e27f4-ca38-4a78-be44-10d5adfab6fc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "458    2\n",
              "235    3\n",
              "281    0\n",
              "55     4\n",
              "284    2\n",
              "      ..\n",
              "355    5\n",
              "392    5\n",
              "162    4\n",
              "283    1\n",
              "499    2\n",
              "Name: Label, Length: 107, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "Y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "87245499",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "87245499",
        "outputId": "5a2791df-371d-4f41-c36d-9c3d75ad8380"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pandas.core.series.Series</b><br/>def __init__(data=None, index=None, dtype: Dtype | None=None, name=None, copy: bool | None=None, fastpath: bool=False) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/pandas/core/series.py</a>One-dimensional ndarray with axis labels (including time series).\n",
              "\n",
              "Labels need not be unique but must be a hashable type. The object\n",
              "supports both integer- and label-based indexing and provides a host of\n",
              "methods for performing operations involving the index. Statistical\n",
              "methods from ndarray have been overridden to automatically exclude\n",
              "missing data (currently represented as NaN).\n",
              "\n",
              "Operations between Series (+, -, /, \\*, \\*\\*) align values based on their\n",
              "associated index values-- they need not be the same length. The result\n",
              "index will be the sorted union of the two indexes.\n",
              "\n",
              "Parameters\n",
              "----------\n",
              "data : array-like, Iterable, dict, or scalar value\n",
              "    Contains data stored in Series. If data is a dict, argument order is\n",
              "    maintained.\n",
              "index : array-like or Index (1d)\n",
              "    Values must be hashable and have the same length as `data`.\n",
              "    Non-unique index values are allowed. Will default to\n",
              "    RangeIndex (0, 1, 2, ..., n) if not provided. If data is dict-like\n",
              "    and index is None, then the keys in the data are used as the index. If the\n",
              "    index is not None, the resulting Series is reindexed with the index values.\n",
              "dtype : str, numpy.dtype, or ExtensionDtype, optional\n",
              "    Data type for the output Series. If not specified, this will be\n",
              "    inferred from `data`.\n",
              "    See the :ref:`user guide &lt;basics.dtypes&gt;` for more usages.\n",
              "name : Hashable, default None\n",
              "    The name to give to the Series.\n",
              "copy : bool, default False\n",
              "    Copy input data. Only affects Series or 1d ndarray input. See examples.\n",
              "\n",
              "Notes\n",
              "-----\n",
              "Please reference the :ref:`User Guide &lt;basics.series&gt;` for more information.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "Constructing Series from a dictionary with an Index specified\n",
              "\n",
              "&gt;&gt;&gt; d = {&#x27;a&#x27;: 1, &#x27;b&#x27;: 2, &#x27;c&#x27;: 3}\n",
              "&gt;&gt;&gt; ser = pd.Series(data=d, index=[&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;])\n",
              "&gt;&gt;&gt; ser\n",
              "a   1\n",
              "b   2\n",
              "c   3\n",
              "dtype: int64\n",
              "\n",
              "The keys of the dictionary match with the Index values, hence the Index\n",
              "values have no effect.\n",
              "\n",
              "&gt;&gt;&gt; d = {&#x27;a&#x27;: 1, &#x27;b&#x27;: 2, &#x27;c&#x27;: 3}\n",
              "&gt;&gt;&gt; ser = pd.Series(data=d, index=[&#x27;x&#x27;, &#x27;y&#x27;, &#x27;z&#x27;])\n",
              "&gt;&gt;&gt; ser\n",
              "x   NaN\n",
              "y   NaN\n",
              "z   NaN\n",
              "dtype: float64\n",
              "\n",
              "Note that the Index is first build with the keys from the dictionary.\n",
              "After this the Series is reindexed with the given Index values, hence we\n",
              "get all NaN as a result.\n",
              "\n",
              "Constructing Series from a list with `copy=False`.\n",
              "\n",
              "&gt;&gt;&gt; r = [1, 2]\n",
              "&gt;&gt;&gt; ser = pd.Series(r, copy=False)\n",
              "&gt;&gt;&gt; ser.iloc[0] = 999\n",
              "&gt;&gt;&gt; r\n",
              "[1, 2]\n",
              "&gt;&gt;&gt; ser\n",
              "0    999\n",
              "1      2\n",
              "dtype: int64\n",
              "\n",
              "Due to input data type the Series has a `copy` of\n",
              "the original data even though `copy=False`, so\n",
              "the data is unchanged.\n",
              "\n",
              "Constructing Series from a 1d ndarray with `copy=False`.\n",
              "\n",
              "&gt;&gt;&gt; r = np.array([1, 2])\n",
              "&gt;&gt;&gt; ser = pd.Series(r, copy=False)\n",
              "&gt;&gt;&gt; ser.iloc[0] = 999\n",
              "&gt;&gt;&gt; r\n",
              "array([999,   2])\n",
              "&gt;&gt;&gt; ser\n",
              "0    999\n",
              "1      2\n",
              "dtype: int64\n",
              "\n",
              "Due to input data type the Series has a `view` on\n",
              "the original data, so\n",
              "the data is changed as well.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 244);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "type(Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "f3d1f20e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3d1f20e",
        "outputId": "91744220-d397-46ec-8111-db67efb1c605"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 6, 5, 0, 4, 1, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "#Check unique values for y_train\n",
        "Y_train.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "d0000d77",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0000d77",
        "outputId": "6bafac1f-08ab-496c-bd73-d69614e37e5d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "np.unique(Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "380b37eb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "380b37eb",
        "outputId": "81391384-cae4-4464-dec3-c0b169d8ab53"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 3, 0, 4, 5, 6, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "Y_test.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "e6b04d17",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6b04d17",
        "outputId": "59215118-0010-4569-e226-285af946919e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "np.unique(Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "f8c656e1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8c656e1",
        "outputId": "04ad617d-08ea-41c5-b523-5b94cca4bab5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 1.1116883116883116,\n",
              " 1: 0.9705215419501134,\n",
              " 2: 0.5661375661375662,\n",
              " 3: 1.2478134110787171,\n",
              " 4: 1.1116883116883116,\n",
              " 5: 0.9705215419501134,\n",
              " 6: 1.7469387755102042}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "from sklearn.utils import compute_class_weight\n",
        "class_weights = compute_class_weight(\n",
        "                                        class_weight = \"balanced\",\n",
        "                                        classes = np.unique(Y_train),\n",
        "                                        y = Y_train\n",
        "                                    )\n",
        "class_weights = dict(zip(np.unique(Y_train), class_weights))\n",
        "class_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "51fc2efb",
      "metadata": {
        "id": "51fc2efb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "1508fc4d",
      "metadata": {
        "id": "1508fc4d"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "#Normalize the data\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(x_train)\n",
        "X_train_scalled = scaler.transform(x_train)\n",
        "X_test_scalled = scaler.transform(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "a31159c2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a31159c2",
        "outputId": "0a6d267d-cbab-4d54-e5aa-7b2499eb5cdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(428, 40, 1)\n",
            "(107, 40, 1)\n"
          ]
        }
      ],
      "source": [
        "#Add dimension for CNN\n",
        "x_traincnn = np.expand_dims(X_train_scalled, axis=2)\n",
        "x_testcnn = np.expand_dims(X_test_scalled, axis=2)\n",
        "\n",
        "#Check shapes of dataframes\n",
        "print(x_traincnn.shape)\n",
        "print(x_testcnn.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "ef5a1dfd",
      "metadata": {
        "id": "ef5a1dfd"
      },
      "outputs": [],
      "source": [
        "#Import packages for CNN\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Conv1D\n",
        "from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM, BatchNormalization, Flatten, MaxPooling1D\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from keras.regularizers import l2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "50b04b34",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50b04b34",
        "outputId": "a088d772-b046-4b85-ee01-e64f6c4ff1f4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "(x_train.shape[1], 1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ANN_model = Sequential()\n",
        "\n",
        "ANN_model.add(Dense(999,input_shape=(X_train_scalled.shape[1],),activation='elu')),\n",
        "ANN_model.add(BatchNormalization()),\n",
        "ANN_model.add(Dropout(0.1)),\n",
        "#LAYER1\n",
        "ANN_model.add(Dense(785,activation='elu')),\n",
        "#kernel_regularizer=l2(0.01),bias_regularizer=l2(0.01),\n",
        "#kernel_regularizer=l2(0.001)\n",
        "ANN_model.add(BatchNormalization()),\n",
        "ANN_model.add(Dropout(0.2)),\n",
        "\n",
        "#LAYER2\n",
        "ANN_model.add(Dense(865,activation='elu')),\n",
        "#kernel_regularizer=l2(0.01),bias_regularizer=l2(0.01),\n",
        "ANN_model.add(BatchNormalization()),\n",
        "ANN_model.add(Dropout(0.2)),\n",
        "\n",
        "#LAYER3\n",
        "ANN_model.add(Dense(672,activation='elu')),\n",
        "#kernel_regularizer=l2(0.01),bias_regularizer=l2(0.01),\n",
        "ANN_model.add(BatchNormalization()),\n",
        "ANN_model.add(Dropout(0.3)),\n",
        "ANN_model.add(Dense(7,activation='softmax')),\n",
        "ANN_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_l_oFFA2H_fy",
        "outputId": "76fdb066-e3f6-47ed-c332-5c427903d352"
      },
      "id": "_l_oFFA2H_fy",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 999)               40959     \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 999)               3996      \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 999)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 785)               785000    \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 785)               3140      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 785)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 865)               679890    \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 865)               3460      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 865)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 672)               581952    \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 672)               2688      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 672)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 7)                 4711      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2105796 (8.03 MB)\n",
            "Trainable params: 2099154 (8.01 MB)\n",
            "Non-trainable params: 6642 (25.95 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e51-Xy0j25tM",
        "outputId": "42bc9ad2-615c-410f-9a87-428a2768799e"
      },
      "id": "e51-Xy0j25tM",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "18b4b87c",
      "metadata": {
        "id": "18b4b87c"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tempfile\n",
        "initial_weights = os.path.join(tempfile.mkdtemp(), 'initial_weights')\n",
        "ANN_model.save_weights(initial_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "29d33a4a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29d33a4a",
        "outputId": "4a6efe36-60b5-4d9f-84d9-9a7697da1899"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7966fc733460>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "ANN_model.load_weights(initial_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "f3ea11c6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3ea11c6",
        "outputId": "56d8b285-fe8f-413e-ca73-e66df2183a58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 999)               40959     \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 999)               3996      \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 999)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 785)               785000    \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 785)               3140      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 785)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 865)               679890    \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 865)               3460      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 865)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 672)               581952    \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 672)               2688      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 672)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 7)                 4711      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2105796 (8.03 MB)\n",
            "Trainable params: 2099154 (8.01 MB)\n",
            "Non-trainable params: 6642 (25.95 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "optimiser = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "ANN_model.compile(optimizer=optimiser,\n",
        "              loss='sparse_categorical_crossentropy',                             #CategoricalCrossentropy\n",
        "              metrics=['SparseCategoricalAccuracy'])\n",
        "ANN_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "5c99effc",
      "metadata": {
        "id": "5c99effc"
      },
      "outputs": [],
      "source": [
        "checkpoint_path='cnn_lstm_emodb3.ckpt'\n",
        "checkpoint_dir=os.path.dirname(checkpoint_path)\n",
        "callback1=tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, monitor='val_sparse_categorical_accuracy', verbose=1,\n",
        "   save_best_only=True,save_weights_only=True,)\n",
        "callback2=tf.keras.callbacks.EarlyStopping(monitor='val_sparse_categorical_accuracy',min_delta=0, patience=50, verbose=0, mode='auto',baseline=None,restore_best_weights=True)\n",
        "cp_callback=[callback1,callback2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "f78fabd7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f78fabd7",
        "outputId": "149718f7-1156-40bb-a4c5-8050e4db9a4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/600\n",
            "1/7 [===>..........................] - ETA: 36s - loss: 2.8228 - sparse_categorical_accuracy: 0.1562\n",
            "Epoch 1: val_sparse_categorical_accuracy improved from -inf to 0.54206, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 7s 76ms/step - loss: 1.9800 - sparse_categorical_accuracy: 0.3551 - val_loss: 1.3398 - val_sparse_categorical_accuracy: 0.5421\n",
            "Epoch 2/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 1.3064 - sparse_categorical_accuracy: 0.4844\n",
            "Epoch 2: val_sparse_categorical_accuracy improved from 0.54206 to 0.57944, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 33ms/step - loss: 1.2594 - sparse_categorical_accuracy: 0.5280 - val_loss: 1.1560 - val_sparse_categorical_accuracy: 0.5794\n",
            "Epoch 3/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.9425 - sparse_categorical_accuracy: 0.6406\n",
            "Epoch 3: val_sparse_categorical_accuracy improved from 0.57944 to 0.65421, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 34ms/step - loss: 0.9883 - sparse_categorical_accuracy: 0.6636 - val_loss: 1.0584 - val_sparse_categorical_accuracy: 0.6542\n",
            "Epoch 4/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.7670 - sparse_categorical_accuracy: 0.6562\n",
            "Epoch 4: val_sparse_categorical_accuracy improved from 0.65421 to 0.68224, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 33ms/step - loss: 0.8681 - sparse_categorical_accuracy: 0.6776 - val_loss: 0.9910 - val_sparse_categorical_accuracy: 0.6822\n",
            "Epoch 5/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.4853 - sparse_categorical_accuracy: 0.7969\n",
            "Epoch 5: val_sparse_categorical_accuracy improved from 0.68224 to 0.71963, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 0.7327 - sparse_categorical_accuracy: 0.7477 - val_loss: 0.9279 - val_sparse_categorical_accuracy: 0.7196\n",
            "Epoch 6/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.5610 - sparse_categorical_accuracy: 0.7656\n",
            "Epoch 6: val_sparse_categorical_accuracy did not improve from 0.71963\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.6915 - sparse_categorical_accuracy: 0.7243 - val_loss: 0.9019 - val_sparse_categorical_accuracy: 0.7196\n",
            "Epoch 7/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.6860 - sparse_categorical_accuracy: 0.7500\n",
            "Epoch 7: val_sparse_categorical_accuracy did not improve from 0.71963\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.6839 - sparse_categorical_accuracy: 0.7593 - val_loss: 0.8769 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 8/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.6209 - sparse_categorical_accuracy: 0.7188\n",
            "Epoch 8: val_sparse_categorical_accuracy did not improve from 0.71963\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.5659 - sparse_categorical_accuracy: 0.7523 - val_loss: 0.8521 - val_sparse_categorical_accuracy: 0.7103\n",
            "Epoch 9/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.4793 - sparse_categorical_accuracy: 0.8594\n",
            "Epoch 9: val_sparse_categorical_accuracy did not improve from 0.71963\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.4763 - sparse_categorical_accuracy: 0.8061 - val_loss: 0.8412 - val_sparse_categorical_accuracy: 0.7196\n",
            "Epoch 10/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.5474 - sparse_categorical_accuracy: 0.7812\n",
            "Epoch 10: val_sparse_categorical_accuracy did not improve from 0.71963\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5164 - sparse_categorical_accuracy: 0.7967 - val_loss: 0.8386 - val_sparse_categorical_accuracy: 0.6822\n",
            "Epoch 11/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.3906 - sparse_categorical_accuracy: 0.8750\n",
            "Epoch 11: val_sparse_categorical_accuracy did not improve from 0.71963\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.5316 - sparse_categorical_accuracy: 0.7897 - val_loss: 0.7989 - val_sparse_categorical_accuracy: 0.7009\n",
            "Epoch 12/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.5258 - sparse_categorical_accuracy: 0.8438\n",
            "Epoch 12: val_sparse_categorical_accuracy did not improve from 0.71963\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.4817 - sparse_categorical_accuracy: 0.8107 - val_loss: 0.7905 - val_sparse_categorical_accuracy: 0.6729\n",
            "Epoch 13/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.6695 - sparse_categorical_accuracy: 0.7812\n",
            "Epoch 13: val_sparse_categorical_accuracy did not improve from 0.71963\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.4899 - sparse_categorical_accuracy: 0.8154 - val_loss: 0.8167 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 14/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.3132 - sparse_categorical_accuracy: 0.8594\n",
            "Epoch 14: val_sparse_categorical_accuracy did not improve from 0.71963\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.3781 - sparse_categorical_accuracy: 0.8458 - val_loss: 0.7916 - val_sparse_categorical_accuracy: 0.6916\n",
            "Epoch 15/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.3429 - sparse_categorical_accuracy: 0.8750\n",
            "Epoch 15: val_sparse_categorical_accuracy improved from 0.71963 to 0.72897, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.4316 - sparse_categorical_accuracy: 0.8294 - val_loss: 0.7237 - val_sparse_categorical_accuracy: 0.7290\n",
            "Epoch 16/600\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.3662 - sparse_categorical_accuracy: 0.8531\n",
            "Epoch 16: val_sparse_categorical_accuracy did not improve from 0.72897\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.3555 - sparse_categorical_accuracy: 0.8481 - val_loss: 0.7028 - val_sparse_categorical_accuracy: 0.7196\n",
            "Epoch 17/600\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.3576 - sparse_categorical_accuracy: 0.8542\n",
            "Epoch 17: val_sparse_categorical_accuracy did not improve from 0.72897\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.3669 - sparse_categorical_accuracy: 0.8458 - val_loss: 0.7123 - val_sparse_categorical_accuracy: 0.7103\n",
            "Epoch 18/600\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.3426 - sparse_categorical_accuracy: 0.8621\n",
            "Epoch 18: val_sparse_categorical_accuracy did not improve from 0.72897\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.3426 - sparse_categorical_accuracy: 0.8621 - val_loss: 0.6783 - val_sparse_categorical_accuracy: 0.7290\n",
            "Epoch 19/600\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.3852 - sparse_categorical_accuracy: 0.8785\n",
            "Epoch 19: val_sparse_categorical_accuracy did not improve from 0.72897\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.3852 - sparse_categorical_accuracy: 0.8785 - val_loss: 0.7175 - val_sparse_categorical_accuracy: 0.7290\n",
            "Epoch 20/600\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.3029 - sparse_categorical_accuracy: 0.8854\n",
            "Epoch 20: val_sparse_categorical_accuracy did not improve from 0.72897\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.3016 - sparse_categorical_accuracy: 0.8832 - val_loss: 0.7038 - val_sparse_categorical_accuracy: 0.7290\n",
            "Epoch 21/600\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.3185 - sparse_categorical_accuracy: 0.8724\n",
            "Epoch 21: val_sparse_categorical_accuracy improved from 0.72897 to 0.73832, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 52ms/step - loss: 0.3486 - sparse_categorical_accuracy: 0.8692 - val_loss: 0.6660 - val_sparse_categorical_accuracy: 0.7383\n",
            "Epoch 22/600\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.3008 - sparse_categorical_accuracy: 0.8802\n",
            "Epoch 22: val_sparse_categorical_accuracy improved from 0.73832 to 0.76636, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.2897 - sparse_categorical_accuracy: 0.8855 - val_loss: 0.6382 - val_sparse_categorical_accuracy: 0.7664\n",
            "Epoch 23/600\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.2324 - sparse_categorical_accuracy: 0.9042\n",
            "Epoch 23: val_sparse_categorical_accuracy did not improve from 0.76636\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.2324 - sparse_categorical_accuracy: 0.9042 - val_loss: 0.6789 - val_sparse_categorical_accuracy: 0.7290\n",
            "Epoch 24/600\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.2746 - sparse_categorical_accuracy: 0.8958\n",
            "Epoch 24: val_sparse_categorical_accuracy did not improve from 0.76636\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.2709 - sparse_categorical_accuracy: 0.8949 - val_loss: 0.7165 - val_sparse_categorical_accuracy: 0.7103\n",
            "Epoch 25/600\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.2995 - sparse_categorical_accuracy: 0.8958\n",
            "Epoch 25: val_sparse_categorical_accuracy improved from 0.76636 to 0.78505, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 52ms/step - loss: 0.2883 - sparse_categorical_accuracy: 0.8995 - val_loss: 0.6315 - val_sparse_categorical_accuracy: 0.7850\n",
            "Epoch 26/600\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.2862 - sparse_categorical_accuracy: 0.8879\n",
            "Epoch 26: val_sparse_categorical_accuracy did not improve from 0.78505\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.2862 - sparse_categorical_accuracy: 0.8879 - val_loss: 0.6435 - val_sparse_categorical_accuracy: 0.7477\n",
            "Epoch 27/600\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.2173 - sparse_categorical_accuracy: 0.9136\n",
            "Epoch 27: val_sparse_categorical_accuracy did not improve from 0.78505\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.2173 - sparse_categorical_accuracy: 0.9136 - val_loss: 0.6477 - val_sparse_categorical_accuracy: 0.7570\n",
            "Epoch 28/600\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.2391 - sparse_categorical_accuracy: 0.9042\n",
            "Epoch 28: val_sparse_categorical_accuracy did not improve from 0.78505\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.2391 - sparse_categorical_accuracy: 0.9042 - val_loss: 0.6238 - val_sparse_categorical_accuracy: 0.7850\n",
            "Epoch 29/600\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.2147 - sparse_categorical_accuracy: 0.9229\n",
            "Epoch 29: val_sparse_categorical_accuracy improved from 0.78505 to 0.80374, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 54ms/step - loss: 0.2147 - sparse_categorical_accuracy: 0.9229 - val_loss: 0.5877 - val_sparse_categorical_accuracy: 0.8037\n",
            "Epoch 30/600\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.2162 - sparse_categorical_accuracy: 0.9193\n",
            "Epoch 30: val_sparse_categorical_accuracy did not improve from 0.80374\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.2145 - sparse_categorical_accuracy: 0.9182 - val_loss: 0.5651 - val_sparse_categorical_accuracy: 0.8037\n",
            "Epoch 31/600\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.1940 - sparse_categorical_accuracy: 0.9271\n",
            "Epoch 31: val_sparse_categorical_accuracy did not improve from 0.80374\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.2050 - sparse_categorical_accuracy: 0.9229 - val_loss: 0.5768 - val_sparse_categorical_accuracy: 0.7850\n",
            "Epoch 32/600\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.2130 - sparse_categorical_accuracy: 0.9167\n",
            "Epoch 32: val_sparse_categorical_accuracy did not improve from 0.80374\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.2168 - sparse_categorical_accuracy: 0.9182 - val_loss: 0.6111 - val_sparse_categorical_accuracy: 0.7477\n",
            "Epoch 33/600\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.2161 - sparse_categorical_accuracy: 0.9469\n",
            "Epoch 33: val_sparse_categorical_accuracy did not improve from 0.80374\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.2129 - sparse_categorical_accuracy: 0.9416 - val_loss: 0.6454 - val_sparse_categorical_accuracy: 0.7664\n",
            "Epoch 34/600\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.1905 - sparse_categorical_accuracy: 0.9401\n",
            "Epoch 34: val_sparse_categorical_accuracy did not improve from 0.80374\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.1875 - sparse_categorical_accuracy: 0.9393 - val_loss: 0.6278 - val_sparse_categorical_accuracy: 0.7850\n",
            "Epoch 35/600\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.2191 - sparse_categorical_accuracy: 0.9141\n",
            "Epoch 35: val_sparse_categorical_accuracy did not improve from 0.80374\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.2180 - sparse_categorical_accuracy: 0.9112 - val_loss: 0.5860 - val_sparse_categorical_accuracy: 0.7944\n",
            "Epoch 36/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.1343 - sparse_categorical_accuracy: 0.9688\n",
            "Epoch 36: val_sparse_categorical_accuracy did not improve from 0.80374\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.1799 - sparse_categorical_accuracy: 0.9463 - val_loss: 0.5738 - val_sparse_categorical_accuracy: 0.7944\n",
            "Epoch 37/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.1387 - sparse_categorical_accuracy: 0.9531\n",
            "Epoch 37: val_sparse_categorical_accuracy did not improve from 0.80374\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.1775 - sparse_categorical_accuracy: 0.9416 - val_loss: 0.5331 - val_sparse_categorical_accuracy: 0.8037\n",
            "Epoch 38/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.1090 - sparse_categorical_accuracy: 0.9688\n",
            "Epoch 38: val_sparse_categorical_accuracy did not improve from 0.80374\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2082 - sparse_categorical_accuracy: 0.9182 - val_loss: 0.6111 - val_sparse_categorical_accuracy: 0.7944\n",
            "Epoch 39/600\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.1843 - sparse_categorical_accuracy: 0.9206\n",
            "Epoch 39: val_sparse_categorical_accuracy did not improve from 0.80374\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.1843 - sparse_categorical_accuracy: 0.9206 - val_loss: 0.6496 - val_sparse_categorical_accuracy: 0.7944\n",
            "Epoch 40/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0754 - sparse_categorical_accuracy: 0.9844\n",
            "Epoch 40: val_sparse_categorical_accuracy did not improve from 0.80374\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.1549 - sparse_categorical_accuracy: 0.9299 - val_loss: 0.6266 - val_sparse_categorical_accuracy: 0.7850\n",
            "Epoch 41/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.1801 - sparse_categorical_accuracy: 0.9375\n",
            "Epoch 41: val_sparse_categorical_accuracy improved from 0.80374 to 0.81308, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 33ms/step - loss: 0.1777 - sparse_categorical_accuracy: 0.9393 - val_loss: 0.6015 - val_sparse_categorical_accuracy: 0.8131\n",
            "Epoch 42/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.1325 - sparse_categorical_accuracy: 0.9531\n",
            "Epoch 42: val_sparse_categorical_accuracy did not improve from 0.81308\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.1530 - sparse_categorical_accuracy: 0.9439 - val_loss: 0.6499 - val_sparse_categorical_accuracy: 0.8131\n",
            "Epoch 43/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.1878 - sparse_categorical_accuracy: 0.9219\n",
            "Epoch 43: val_sparse_categorical_accuracy did not improve from 0.81308\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.1625 - sparse_categorical_accuracy: 0.9299 - val_loss: 0.6908 - val_sparse_categorical_accuracy: 0.7944\n",
            "Epoch 44/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.1328 - sparse_categorical_accuracy: 0.9531\n",
            "Epoch 44: val_sparse_categorical_accuracy improved from 0.81308 to 0.82243, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 42ms/step - loss: 0.1761 - sparse_categorical_accuracy: 0.9159 - val_loss: 0.5850 - val_sparse_categorical_accuracy: 0.8224\n",
            "Epoch 45/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.1379 - sparse_categorical_accuracy: 0.9688\n",
            "Epoch 45: val_sparse_categorical_accuracy did not improve from 0.82243\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.1490 - sparse_categorical_accuracy: 0.9486 - val_loss: 0.5821 - val_sparse_categorical_accuracy: 0.8224\n",
            "Epoch 46/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.1352 - sparse_categorical_accuracy: 0.9844\n",
            "Epoch 46: val_sparse_categorical_accuracy did not improve from 0.82243\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.1352 - sparse_categorical_accuracy: 0.9579 - val_loss: 0.6061 - val_sparse_categorical_accuracy: 0.8037\n",
            "Epoch 47/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.1196 - sparse_categorical_accuracy: 0.9688\n",
            "Epoch 47: val_sparse_categorical_accuracy did not improve from 0.82243\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.1393 - sparse_categorical_accuracy: 0.9603 - val_loss: 0.6413 - val_sparse_categorical_accuracy: 0.8224\n",
            "Epoch 48/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.2024 - sparse_categorical_accuracy: 0.9531\n",
            "Epoch 48: val_sparse_categorical_accuracy did not improve from 0.82243\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.1269 - sparse_categorical_accuracy: 0.9579 - val_loss: 0.6272 - val_sparse_categorical_accuracy: 0.8224\n",
            "Epoch 49/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.1168 - sparse_categorical_accuracy: 0.9219\n",
            "Epoch 49: val_sparse_categorical_accuracy did not improve from 0.82243\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.1515 - sparse_categorical_accuracy: 0.9322 - val_loss: 0.6052 - val_sparse_categorical_accuracy: 0.8131\n",
            "Epoch 50/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0608 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 50: val_sparse_categorical_accuracy did not improve from 0.82243\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.1278 - sparse_categorical_accuracy: 0.9696 - val_loss: 0.6304 - val_sparse_categorical_accuracy: 0.8131\n",
            "Epoch 51/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.1662 - sparse_categorical_accuracy: 0.9219\n",
            "Epoch 51: val_sparse_categorical_accuracy did not improve from 0.82243\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.1558 - sparse_categorical_accuracy: 0.9486 - val_loss: 0.6251 - val_sparse_categorical_accuracy: 0.8131\n",
            "Epoch 52/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.1495 - sparse_categorical_accuracy: 0.9531\n",
            "Epoch 52: val_sparse_categorical_accuracy did not improve from 0.82243\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.1163 - sparse_categorical_accuracy: 0.9626 - val_loss: 0.6215 - val_sparse_categorical_accuracy: 0.8224\n",
            "Epoch 53/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.1633 - sparse_categorical_accuracy: 0.9375\n",
            "Epoch 53: val_sparse_categorical_accuracy did not improve from 0.82243\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.1164 - sparse_categorical_accuracy: 0.9603 - val_loss: 0.6406 - val_sparse_categorical_accuracy: 0.8224\n",
            "Epoch 54/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0955 - sparse_categorical_accuracy: 0.9531\n",
            "Epoch 54: val_sparse_categorical_accuracy did not improve from 0.82243\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.1246 - sparse_categorical_accuracy: 0.9579 - val_loss: 0.6494 - val_sparse_categorical_accuracy: 0.8131\n",
            "Epoch 55/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0797 - sparse_categorical_accuracy: 0.9688\n",
            "Epoch 55: val_sparse_categorical_accuracy improved from 0.82243 to 0.84112, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 0.1174 - sparse_categorical_accuracy: 0.9579 - val_loss: 0.6207 - val_sparse_categorical_accuracy: 0.8411\n",
            "Epoch 56/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.1804 - sparse_categorical_accuracy: 0.8906\n",
            "Epoch 56: val_sparse_categorical_accuracy improved from 0.84112 to 0.85047, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 0.1375 - sparse_categorical_accuracy: 0.9416 - val_loss: 0.6362 - val_sparse_categorical_accuracy: 0.8505\n",
            "Epoch 57/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0540 - sparse_categorical_accuracy: 0.9844\n",
            "Epoch 57: val_sparse_categorical_accuracy did not improve from 0.85047\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.1277 - sparse_categorical_accuracy: 0.9486 - val_loss: 0.6443 - val_sparse_categorical_accuracy: 0.8318\n",
            "Epoch 58/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.1938 - sparse_categorical_accuracy: 0.9062\n",
            "Epoch 58: val_sparse_categorical_accuracy did not improve from 0.85047\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.1296 - sparse_categorical_accuracy: 0.9463 - val_loss: 0.6512 - val_sparse_categorical_accuracy: 0.8037\n",
            "Epoch 59/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.1050 - sparse_categorical_accuracy: 0.9688\n",
            "Epoch 59: val_sparse_categorical_accuracy did not improve from 0.85047\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0990 - sparse_categorical_accuracy: 0.9579 - val_loss: 0.6482 - val_sparse_categorical_accuracy: 0.8224\n",
            "Epoch 60/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0625 - sparse_categorical_accuracy: 0.9844\n",
            "Epoch 60: val_sparse_categorical_accuracy did not improve from 0.85047\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.1089 - sparse_categorical_accuracy: 0.9579 - val_loss: 0.6593 - val_sparse_categorical_accuracy: 0.8131\n",
            "Epoch 61/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.2866 - sparse_categorical_accuracy: 0.8906\n",
            "Epoch 61: val_sparse_categorical_accuracy did not improve from 0.85047\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.1301 - sparse_categorical_accuracy: 0.9533 - val_loss: 0.6811 - val_sparse_categorical_accuracy: 0.8131\n",
            "Epoch 62/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.1599 - sparse_categorical_accuracy: 0.9219\n",
            "Epoch 62: val_sparse_categorical_accuracy did not improve from 0.85047\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.1293 - sparse_categorical_accuracy: 0.9533 - val_loss: 0.6994 - val_sparse_categorical_accuracy: 0.8411\n",
            "Epoch 63/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.1220 - sparse_categorical_accuracy: 0.9375\n",
            "Epoch 63: val_sparse_categorical_accuracy did not improve from 0.85047\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.1623 - sparse_categorical_accuracy: 0.9299 - val_loss: 0.6756 - val_sparse_categorical_accuracy: 0.8318\n",
            "Epoch 64/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.1265 - sparse_categorical_accuracy: 0.9531\n",
            "Epoch 64: val_sparse_categorical_accuracy did not improve from 0.85047\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0929 - sparse_categorical_accuracy: 0.9626 - val_loss: 0.6693 - val_sparse_categorical_accuracy: 0.8505\n",
            "Epoch 65/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0685 - sparse_categorical_accuracy: 0.9688\n",
            "Epoch 65: val_sparse_categorical_accuracy did not improve from 0.85047\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0966 - sparse_categorical_accuracy: 0.9556 - val_loss: 0.6654 - val_sparse_categorical_accuracy: 0.8224\n",
            "Epoch 66/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.1133 - sparse_categorical_accuracy: 0.9688\n",
            "Epoch 66: val_sparse_categorical_accuracy did not improve from 0.85047\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0961 - sparse_categorical_accuracy: 0.9720 - val_loss: 0.6968 - val_sparse_categorical_accuracy: 0.8224\n",
            "Epoch 67/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.1064 - sparse_categorical_accuracy: 0.9531\n",
            "Epoch 67: val_sparse_categorical_accuracy did not improve from 0.85047\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0987 - sparse_categorical_accuracy: 0.9720 - val_loss: 0.7052 - val_sparse_categorical_accuracy: 0.7944\n",
            "Epoch 68/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0732 - sparse_categorical_accuracy: 0.9531\n",
            "Epoch 68: val_sparse_categorical_accuracy did not improve from 0.85047\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.1251 - sparse_categorical_accuracy: 0.9486 - val_loss: 0.7124 - val_sparse_categorical_accuracy: 0.8318\n",
            "Epoch 69/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.1928 - sparse_categorical_accuracy: 0.9531\n",
            "Epoch 69: val_sparse_categorical_accuracy did not improve from 0.85047\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0900 - sparse_categorical_accuracy: 0.9696 - val_loss: 0.7397 - val_sparse_categorical_accuracy: 0.8131\n",
            "Epoch 70/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0680 - sparse_categorical_accuracy: 0.9688\n",
            "Epoch 70: val_sparse_categorical_accuracy did not improve from 0.85047\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0753 - sparse_categorical_accuracy: 0.9766 - val_loss: 0.7099 - val_sparse_categorical_accuracy: 0.8505\n",
            "Epoch 71/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.1070 - sparse_categorical_accuracy: 0.9375\n",
            "Epoch 71: val_sparse_categorical_accuracy improved from 0.85047 to 0.85981, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.0894 - sparse_categorical_accuracy: 0.9603 - val_loss: 0.7316 - val_sparse_categorical_accuracy: 0.8598\n",
            "Epoch 72/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0702 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 72: val_sparse_categorical_accuracy did not improve from 0.85981\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0707 - sparse_categorical_accuracy: 0.9743 - val_loss: 0.7246 - val_sparse_categorical_accuracy: 0.8505\n",
            "Epoch 73/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0873 - sparse_categorical_accuracy: 0.9688\n",
            "Epoch 73: val_sparse_categorical_accuracy did not improve from 0.85981\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0877 - sparse_categorical_accuracy: 0.9720 - val_loss: 0.7149 - val_sparse_categorical_accuracy: 0.8505\n",
            "Epoch 74/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0929 - sparse_categorical_accuracy: 0.9531\n",
            "Epoch 74: val_sparse_categorical_accuracy did not improve from 0.85981\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0793 - sparse_categorical_accuracy: 0.9650 - val_loss: 0.7119 - val_sparse_categorical_accuracy: 0.8131\n",
            "Epoch 75/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.1492 - sparse_categorical_accuracy: 0.9219\n",
            "Epoch 75: val_sparse_categorical_accuracy did not improve from 0.85981\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0964 - sparse_categorical_accuracy: 0.9579 - val_loss: 0.7169 - val_sparse_categorical_accuracy: 0.8037\n",
            "Epoch 76/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0783 - sparse_categorical_accuracy: 0.9844\n",
            "Epoch 76: val_sparse_categorical_accuracy did not improve from 0.85981\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0775 - sparse_categorical_accuracy: 0.9720 - val_loss: 0.7187 - val_sparse_categorical_accuracy: 0.8037\n",
            "Epoch 77/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0628 - sparse_categorical_accuracy: 0.9844\n",
            "Epoch 77: val_sparse_categorical_accuracy did not improve from 0.85981\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0813 - sparse_categorical_accuracy: 0.9696 - val_loss: 0.7462 - val_sparse_categorical_accuracy: 0.8131\n",
            "Epoch 78/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0732 - sparse_categorical_accuracy: 0.9688\n",
            "Epoch 78: val_sparse_categorical_accuracy did not improve from 0.85981\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0615 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.7444 - val_sparse_categorical_accuracy: 0.8224\n",
            "Epoch 79/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.1115 - sparse_categorical_accuracy: 0.9375\n",
            "Epoch 79: val_sparse_categorical_accuracy did not improve from 0.85981\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.1064 - sparse_categorical_accuracy: 0.9626 - val_loss: 0.7254 - val_sparse_categorical_accuracy: 0.8131\n",
            "Epoch 80/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0420 - sparse_categorical_accuracy: 0.9688\n",
            "Epoch 80: val_sparse_categorical_accuracy did not improve from 0.85981\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0762 - sparse_categorical_accuracy: 0.9696 - val_loss: 0.7360 - val_sparse_categorical_accuracy: 0.8037\n",
            "Epoch 81/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0709 - sparse_categorical_accuracy: 0.9688\n",
            "Epoch 81: val_sparse_categorical_accuracy did not improve from 0.85981\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0892 - sparse_categorical_accuracy: 0.9720 - val_loss: 0.7265 - val_sparse_categorical_accuracy: 0.8318\n",
            "Epoch 82/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0602 - sparse_categorical_accuracy: 0.9844\n",
            "Epoch 82: val_sparse_categorical_accuracy did not improve from 0.85981\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0774 - sparse_categorical_accuracy: 0.9790 - val_loss: 0.7474 - val_sparse_categorical_accuracy: 0.8037\n",
            "Epoch 83/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0858 - sparse_categorical_accuracy: 0.9531\n",
            "Epoch 83: val_sparse_categorical_accuracy did not improve from 0.85981\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0780 - sparse_categorical_accuracy: 0.9673 - val_loss: 0.7825 - val_sparse_categorical_accuracy: 0.8037\n",
            "Epoch 84/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0748 - sparse_categorical_accuracy: 0.9688\n",
            "Epoch 84: val_sparse_categorical_accuracy did not improve from 0.85981\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0623 - sparse_categorical_accuracy: 0.9743 - val_loss: 0.7499 - val_sparse_categorical_accuracy: 0.8037\n",
            "Epoch 85/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.1150 - sparse_categorical_accuracy: 0.9375\n",
            "Epoch 85: val_sparse_categorical_accuracy did not improve from 0.85981\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0806 - sparse_categorical_accuracy: 0.9720 - val_loss: 0.7379 - val_sparse_categorical_accuracy: 0.8411\n",
            "Epoch 86/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0422 - sparse_categorical_accuracy: 0.9688\n",
            "Epoch 86: val_sparse_categorical_accuracy did not improve from 0.85981\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0858 - sparse_categorical_accuracy: 0.9673 - val_loss: 0.7675 - val_sparse_categorical_accuracy: 0.8505\n",
            "Epoch 87/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.1008 - sparse_categorical_accuracy: 0.9219\n",
            "Epoch 87: val_sparse_categorical_accuracy did not improve from 0.85981\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0765 - sparse_categorical_accuracy: 0.9673 - val_loss: 0.7681 - val_sparse_categorical_accuracy: 0.8131\n",
            "Epoch 88/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.1037 - sparse_categorical_accuracy: 0.9531\n",
            "Epoch 88: val_sparse_categorical_accuracy did not improve from 0.85981\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0706 - sparse_categorical_accuracy: 0.9696 - val_loss: 0.7773 - val_sparse_categorical_accuracy: 0.8224\n",
            "Epoch 89/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0315 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 89: val_sparse_categorical_accuracy did not improve from 0.85981\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0518 - sparse_categorical_accuracy: 0.9860 - val_loss: 0.7817 - val_sparse_categorical_accuracy: 0.8598\n",
            "Epoch 90/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0630 - sparse_categorical_accuracy: 0.9688\n",
            "Epoch 90: val_sparse_categorical_accuracy did not improve from 0.85981\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0463 - sparse_categorical_accuracy: 0.9907 - val_loss: 0.7809 - val_sparse_categorical_accuracy: 0.8598\n",
            "Epoch 91/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0566 - sparse_categorical_accuracy: 0.9844\n",
            "Epoch 91: val_sparse_categorical_accuracy did not improve from 0.85981\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.0465 - sparse_categorical_accuracy: 0.9907 - val_loss: 0.7757 - val_sparse_categorical_accuracy: 0.8411\n",
            "Epoch 92/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0453 - sparse_categorical_accuracy: 0.9844\n",
            "Epoch 92: val_sparse_categorical_accuracy did not improve from 0.85981\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0645 - sparse_categorical_accuracy: 0.9790 - val_loss: 0.7676 - val_sparse_categorical_accuracy: 0.8318\n",
            "Epoch 93/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0293 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 93: val_sparse_categorical_accuracy did not improve from 0.85981\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0585 - sparse_categorical_accuracy: 0.9766 - val_loss: 0.7764 - val_sparse_categorical_accuracy: 0.8411\n",
            "Epoch 94/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0307 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 94: val_sparse_categorical_accuracy did not improve from 0.85981\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.1024 - sparse_categorical_accuracy: 0.9509 - val_loss: 0.7612 - val_sparse_categorical_accuracy: 0.8505\n",
            "Epoch 95/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0904 - sparse_categorical_accuracy: 0.9688\n",
            "Epoch 95: val_sparse_categorical_accuracy did not improve from 0.85981\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.0544 - sparse_categorical_accuracy: 0.9860 - val_loss: 0.7554 - val_sparse_categorical_accuracy: 0.8318\n",
            "Epoch 96/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0272 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 96: val_sparse_categorical_accuracy did not improve from 0.85981\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0616 - sparse_categorical_accuracy: 0.9860 - val_loss: 0.7573 - val_sparse_categorical_accuracy: 0.8131\n",
            "Epoch 97/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0786 - sparse_categorical_accuracy: 0.9688\n",
            "Epoch 97: val_sparse_categorical_accuracy did not improve from 0.85981\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0479 - sparse_categorical_accuracy: 0.9883 - val_loss: 0.7597 - val_sparse_categorical_accuracy: 0.8411\n",
            "Epoch 98/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0214 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 98: val_sparse_categorical_accuracy did not improve from 0.85981\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.0532 - sparse_categorical_accuracy: 0.9836 - val_loss: 0.7471 - val_sparse_categorical_accuracy: 0.8411\n",
            "Epoch 99/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0449 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 99: val_sparse_categorical_accuracy did not improve from 0.85981\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0654 - sparse_categorical_accuracy: 0.9766 - val_loss: 0.7123 - val_sparse_categorical_accuracy: 0.8505\n",
            "Epoch 100/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0851 - sparse_categorical_accuracy: 0.9688\n",
            "Epoch 100: val_sparse_categorical_accuracy did not improve from 0.85981\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0532 - sparse_categorical_accuracy: 0.9883 - val_loss: 0.7625 - val_sparse_categorical_accuracy: 0.8224\n",
            "Epoch 101/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0320 - sparse_categorical_accuracy: 0.9844\n",
            "Epoch 101: val_sparse_categorical_accuracy did not improve from 0.85981\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0769 - sparse_categorical_accuracy: 0.9603 - val_loss: 0.7648 - val_sparse_categorical_accuracy: 0.7944\n",
            "Epoch 102/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.1121 - sparse_categorical_accuracy: 0.9531\n",
            "Epoch 102: val_sparse_categorical_accuracy did not improve from 0.85981\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0720 - sparse_categorical_accuracy: 0.9743 - val_loss: 0.7635 - val_sparse_categorical_accuracy: 0.8411\n",
            "Epoch 103/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.1107 - sparse_categorical_accuracy: 0.9688\n",
            "Epoch 103: val_sparse_categorical_accuracy did not improve from 0.85981\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0786 - sparse_categorical_accuracy: 0.9766 - val_loss: 0.7847 - val_sparse_categorical_accuracy: 0.8318\n",
            "Epoch 104/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0605 - sparse_categorical_accuracy: 0.9688\n",
            "Epoch 104: val_sparse_categorical_accuracy did not improve from 0.85981\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0562 - sparse_categorical_accuracy: 0.9790 - val_loss: 0.8194 - val_sparse_categorical_accuracy: 0.8037\n",
            "Epoch 105/600\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0568 - sparse_categorical_accuracy: 0.9790\n",
            "Epoch 105: val_sparse_categorical_accuracy did not improve from 0.85981\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0568 - sparse_categorical_accuracy: 0.9790 - val_loss: 0.8007 - val_sparse_categorical_accuracy: 0.8318\n",
            "Epoch 106/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0713 - sparse_categorical_accuracy: 0.9688\n",
            "Epoch 106: val_sparse_categorical_accuracy did not improve from 0.85981\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0617 - sparse_categorical_accuracy: 0.9790 - val_loss: 0.8262 - val_sparse_categorical_accuracy: 0.8505\n",
            "Epoch 107/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0521 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 107: val_sparse_categorical_accuracy improved from 0.85981 to 0.86916, saving model to cnn_lstm_emodb3.ckpt\n",
            "7/7 [==============================] - 0s 34ms/step - loss: 0.0645 - sparse_categorical_accuracy: 0.9836 - val_loss: 0.8033 - val_sparse_categorical_accuracy: 0.8692\n",
            "Epoch 108/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0304 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 108: val_sparse_categorical_accuracy did not improve from 0.86916\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0327 - sparse_categorical_accuracy: 0.9907 - val_loss: 0.8248 - val_sparse_categorical_accuracy: 0.8411\n",
            "Epoch 109/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.1229 - sparse_categorical_accuracy: 0.9062\n",
            "Epoch 109: val_sparse_categorical_accuracy did not improve from 0.86916\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0794 - sparse_categorical_accuracy: 0.9673 - val_loss: 0.8189 - val_sparse_categorical_accuracy: 0.8505\n",
            "Epoch 110/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.1225 - sparse_categorical_accuracy: 0.9375\n",
            "Epoch 110: val_sparse_categorical_accuracy did not improve from 0.86916\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0476 - sparse_categorical_accuracy: 0.9836 - val_loss: 0.8057 - val_sparse_categorical_accuracy: 0.8318\n",
            "Epoch 111/600\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0489 - sparse_categorical_accuracy: 0.9813\n",
            "Epoch 111: val_sparse_categorical_accuracy did not improve from 0.86916\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0489 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.8103 - val_sparse_categorical_accuracy: 0.8411\n",
            "Epoch 112/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0349 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 112: val_sparse_categorical_accuracy did not improve from 0.86916\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0613 - sparse_categorical_accuracy: 0.9743 - val_loss: 0.8199 - val_sparse_categorical_accuracy: 0.8411\n",
            "Epoch 113/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0264 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 113: val_sparse_categorical_accuracy did not improve from 0.86916\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0346 - sparse_categorical_accuracy: 0.9953 - val_loss: 0.8248 - val_sparse_categorical_accuracy: 0.8411\n",
            "Epoch 114/600\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0403 - sparse_categorical_accuracy: 0.9883\n",
            "Epoch 114: val_sparse_categorical_accuracy did not improve from 0.86916\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0403 - sparse_categorical_accuracy: 0.9883 - val_loss: 0.8150 - val_sparse_categorical_accuracy: 0.8411\n",
            "Epoch 115/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0644 - sparse_categorical_accuracy: 0.9688\n",
            "Epoch 115: val_sparse_categorical_accuracy did not improve from 0.86916\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0901 - sparse_categorical_accuracy: 0.9579 - val_loss: 0.8158 - val_sparse_categorical_accuracy: 0.8318\n",
            "Epoch 116/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0261 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 116: val_sparse_categorical_accuracy did not improve from 0.86916\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0443 - sparse_categorical_accuracy: 0.9907 - val_loss: 0.8192 - val_sparse_categorical_accuracy: 0.8318\n",
            "Epoch 117/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0132 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 117: val_sparse_categorical_accuracy did not improve from 0.86916\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0353 - sparse_categorical_accuracy: 0.9836 - val_loss: 0.7985 - val_sparse_categorical_accuracy: 0.8131\n",
            "Epoch 118/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0427 - sparse_categorical_accuracy: 0.9844\n",
            "Epoch 118: val_sparse_categorical_accuracy did not improve from 0.86916\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0492 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.7614 - val_sparse_categorical_accuracy: 0.8224\n",
            "Epoch 119/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0141 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 119: val_sparse_categorical_accuracy did not improve from 0.86916\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0339 - sparse_categorical_accuracy: 0.9860 - val_loss: 0.7595 - val_sparse_categorical_accuracy: 0.8318\n",
            "Epoch 120/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0264 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 120: val_sparse_categorical_accuracy did not improve from 0.86916\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.0345 - sparse_categorical_accuracy: 0.9930 - val_loss: 0.7648 - val_sparse_categorical_accuracy: 0.8411\n",
            "Epoch 121/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0341 - sparse_categorical_accuracy: 0.9844\n",
            "Epoch 121: val_sparse_categorical_accuracy did not improve from 0.86916\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0302 - sparse_categorical_accuracy: 0.9907 - val_loss: 0.7759 - val_sparse_categorical_accuracy: 0.8411\n",
            "Epoch 122/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0377 - sparse_categorical_accuracy: 0.9844\n",
            "Epoch 122: val_sparse_categorical_accuracy did not improve from 0.86916\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0340 - sparse_categorical_accuracy: 0.9930 - val_loss: 0.7782 - val_sparse_categorical_accuracy: 0.8411\n",
            "Epoch 123/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0553 - sparse_categorical_accuracy: 0.9844\n",
            "Epoch 123: val_sparse_categorical_accuracy did not improve from 0.86916\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0428 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.7712 - val_sparse_categorical_accuracy: 0.8598\n",
            "Epoch 124/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0295 - sparse_categorical_accuracy: 0.9844\n",
            "Epoch 124: val_sparse_categorical_accuracy did not improve from 0.86916\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0289 - sparse_categorical_accuracy: 0.9907 - val_loss: 0.7976 - val_sparse_categorical_accuracy: 0.8411\n",
            "Epoch 125/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0607 - sparse_categorical_accuracy: 0.9688\n",
            "Epoch 125: val_sparse_categorical_accuracy did not improve from 0.86916\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0348 - sparse_categorical_accuracy: 0.9883 - val_loss: 0.7971 - val_sparse_categorical_accuracy: 0.8131\n",
            "Epoch 126/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0263 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 126: val_sparse_categorical_accuracy did not improve from 0.86916\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.0478 - sparse_categorical_accuracy: 0.9860 - val_loss: 0.8066 - val_sparse_categorical_accuracy: 0.8411\n",
            "Epoch 127/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0162 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 127: val_sparse_categorical_accuracy did not improve from 0.86916\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0325 - sparse_categorical_accuracy: 0.9953 - val_loss: 0.8067 - val_sparse_categorical_accuracy: 0.8505\n",
            "Epoch 128/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.0863 - sparse_categorical_accuracy: 0.9688\n",
            "Epoch 128: val_sparse_categorical_accuracy did not improve from 0.86916\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0433 - sparse_categorical_accuracy: 0.9883 - val_loss: 0.8210 - val_sparse_categorical_accuracy: 0.8224\n",
            "Epoch 129/600\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0418 - sparse_categorical_accuracy: 0.9883\n",
            "Epoch 129: val_sparse_categorical_accuracy did not improve from 0.86916\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0418 - sparse_categorical_accuracy: 0.9883 - val_loss: 0.8116 - val_sparse_categorical_accuracy: 0.8318\n",
            "Epoch 130/600\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0423 - sparse_categorical_accuracy: 0.9781\n",
            "Epoch 130: val_sparse_categorical_accuracy did not improve from 0.86916\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0409 - sparse_categorical_accuracy: 0.9790 - val_loss: 0.8000 - val_sparse_categorical_accuracy: 0.8224\n",
            "Epoch 131/600\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0319 - sparse_categorical_accuracy: 0.9896\n",
            "Epoch 131: val_sparse_categorical_accuracy did not improve from 0.86916\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.0302 - sparse_categorical_accuracy: 0.9907 - val_loss: 0.7825 - val_sparse_categorical_accuracy: 0.8224\n",
            "Epoch 132/600\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0421 - sparse_categorical_accuracy: 0.9836\n",
            "Epoch 132: val_sparse_categorical_accuracy did not improve from 0.86916\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0421 - sparse_categorical_accuracy: 0.9836 - val_loss: 0.7981 - val_sparse_categorical_accuracy: 0.8131\n",
            "Epoch 133/600\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0286 - sparse_categorical_accuracy: 0.9907\n",
            "Epoch 133: val_sparse_categorical_accuracy did not improve from 0.86916\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.0286 - sparse_categorical_accuracy: 0.9907 - val_loss: 0.7777 - val_sparse_categorical_accuracy: 0.8318\n",
            "Epoch 134/600\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0367 - sparse_categorical_accuracy: 0.9896\n",
            "Epoch 134: val_sparse_categorical_accuracy did not improve from 0.86916\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0412 - sparse_categorical_accuracy: 0.9860 - val_loss: 0.7793 - val_sparse_categorical_accuracy: 0.8411\n",
            "Epoch 135/600\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0464 - sparse_categorical_accuracy: 0.9844\n",
            "Epoch 135: val_sparse_categorical_accuracy did not improve from 0.86916\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.0442 - sparse_categorical_accuracy: 0.9860 - val_loss: 0.7848 - val_sparse_categorical_accuracy: 0.8411\n",
            "Epoch 136/600\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0337 - sparse_categorical_accuracy: 0.9896\n",
            "Epoch 136: val_sparse_categorical_accuracy did not improve from 0.86916\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0463 - sparse_categorical_accuracy: 0.9836 - val_loss: 0.7901 - val_sparse_categorical_accuracy: 0.8318\n",
            "Epoch 137/600\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0281 - sparse_categorical_accuracy: 0.9883\n",
            "Epoch 137: val_sparse_categorical_accuracy did not improve from 0.86916\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0281 - sparse_categorical_accuracy: 0.9883 - val_loss: 0.7966 - val_sparse_categorical_accuracy: 0.8318\n",
            "Epoch 138/600\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0613 - sparse_categorical_accuracy: 0.9766\n",
            "Epoch 138: val_sparse_categorical_accuracy did not improve from 0.86916\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.0613 - sparse_categorical_accuracy: 0.9766 - val_loss: 0.7839 - val_sparse_categorical_accuracy: 0.8318\n",
            "Epoch 139/600\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0209 - sparse_categorical_accuracy: 0.9948\n",
            "Epoch 139: val_sparse_categorical_accuracy did not improve from 0.86916\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.0236 - sparse_categorical_accuracy: 0.9930 - val_loss: 0.7937 - val_sparse_categorical_accuracy: 0.8318\n",
            "Epoch 140/600\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0258 - sparse_categorical_accuracy: 0.9948\n",
            "Epoch 140: val_sparse_categorical_accuracy did not improve from 0.86916\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0238 - sparse_categorical_accuracy: 0.9953 - val_loss: 0.7927 - val_sparse_categorical_accuracy: 0.8318\n",
            "Epoch 141/600\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0343 - sparse_categorical_accuracy: 0.9896\n",
            "Epoch 141: val_sparse_categorical_accuracy did not improve from 0.86916\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0323 - sparse_categorical_accuracy: 0.9907 - val_loss: 0.8070 - val_sparse_categorical_accuracy: 0.8131\n",
            "Epoch 142/600\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0280 - sparse_categorical_accuracy: 0.9937\n",
            "Epoch 142: val_sparse_categorical_accuracy did not improve from 0.86916\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.0318 - sparse_categorical_accuracy: 0.9930 - val_loss: 0.7792 - val_sparse_categorical_accuracy: 0.8224\n",
            "Epoch 143/600\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0274 - sparse_categorical_accuracy: 0.9896\n",
            "Epoch 143: val_sparse_categorical_accuracy did not improve from 0.86916\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.0355 - sparse_categorical_accuracy: 0.9883 - val_loss: 0.7685 - val_sparse_categorical_accuracy: 0.8411\n",
            "Epoch 144/600\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0295 - sparse_categorical_accuracy: 0.9937\n",
            "Epoch 144: val_sparse_categorical_accuracy did not improve from 0.86916\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.0289 - sparse_categorical_accuracy: 0.9953 - val_loss: 0.7798 - val_sparse_categorical_accuracy: 0.8318\n",
            "Epoch 145/600\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0371 - sparse_categorical_accuracy: 0.9906\n",
            "Epoch 145: val_sparse_categorical_accuracy did not improve from 0.86916\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.0335 - sparse_categorical_accuracy: 0.9907 - val_loss: 0.7713 - val_sparse_categorical_accuracy: 0.8505\n",
            "Epoch 146/600\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0236 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 146: val_sparse_categorical_accuracy did not improve from 0.86916\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.0230 - sparse_categorical_accuracy: 0.9977 - val_loss: 0.7732 - val_sparse_categorical_accuracy: 0.8411\n",
            "Epoch 147/600\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0296 - sparse_categorical_accuracy: 0.9937\n",
            "Epoch 147: val_sparse_categorical_accuracy did not improve from 0.86916\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.0311 - sparse_categorical_accuracy: 0.9907 - val_loss: 0.7910 - val_sparse_categorical_accuracy: 0.8224\n",
            "Epoch 148/600\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0320 - sparse_categorical_accuracy: 0.9907\n",
            "Epoch 148: val_sparse_categorical_accuracy did not improve from 0.86916\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.0320 - sparse_categorical_accuracy: 0.9907 - val_loss: 0.7956 - val_sparse_categorical_accuracy: 0.8037\n",
            "Epoch 149/600\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0353 - sparse_categorical_accuracy: 0.9937\n",
            "Epoch 149: val_sparse_categorical_accuracy did not improve from 0.86916\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.0409 - sparse_categorical_accuracy: 0.9907 - val_loss: 0.8168 - val_sparse_categorical_accuracy: 0.7944\n",
            "Epoch 150/600\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0316 - sparse_categorical_accuracy: 0.9818\n",
            "Epoch 150: val_sparse_categorical_accuracy did not improve from 0.86916\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0293 - sparse_categorical_accuracy: 0.9836 - val_loss: 0.8304 - val_sparse_categorical_accuracy: 0.8131\n",
            "Epoch 151/600\n",
            "4/7 [================>.............] - ETA: 0s - loss: 0.0254 - sparse_categorical_accuracy: 0.9961\n",
            "Epoch 151: val_sparse_categorical_accuracy did not improve from 0.86916\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.0295 - sparse_categorical_accuracy: 0.9930 - val_loss: 0.8230 - val_sparse_categorical_accuracy: 0.8224\n",
            "Epoch 152/600\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0229 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 152: val_sparse_categorical_accuracy did not improve from 0.86916\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.0216 - sparse_categorical_accuracy: 0.9977 - val_loss: 0.8222 - val_sparse_categorical_accuracy: 0.8224\n",
            "Epoch 153/600\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0327 - sparse_categorical_accuracy: 0.9948\n",
            "Epoch 153: val_sparse_categorical_accuracy did not improve from 0.86916\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0297 - sparse_categorical_accuracy: 0.9953 - val_loss: 0.7958 - val_sparse_categorical_accuracy: 0.8224\n",
            "Epoch 154/600\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0385 - sparse_categorical_accuracy: 0.9818\n",
            "Epoch 154: val_sparse_categorical_accuracy did not improve from 0.86916\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.0352 - sparse_categorical_accuracy: 0.9836 - val_loss: 0.7783 - val_sparse_categorical_accuracy: 0.8318\n",
            "Epoch 155/600\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0219 - sparse_categorical_accuracy: 0.9948\n",
            "Epoch 155: val_sparse_categorical_accuracy did not improve from 0.86916\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.0211 - sparse_categorical_accuracy: 0.9953 - val_loss: 0.7738 - val_sparse_categorical_accuracy: 0.8131\n",
            "Epoch 156/600\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0189 - sparse_categorical_accuracy: 0.9948\n",
            "Epoch 156: val_sparse_categorical_accuracy did not improve from 0.86916\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.0195 - sparse_categorical_accuracy: 0.9953 - val_loss: 0.7732 - val_sparse_categorical_accuracy: 0.8037\n",
            "Epoch 157/600\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0291 - sparse_categorical_accuracy: 0.9870\n",
            "Epoch 157: val_sparse_categorical_accuracy did not improve from 0.86916\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.0295 - sparse_categorical_accuracy: 0.9860 - val_loss: 0.7550 - val_sparse_categorical_accuracy: 0.8224\n"
          ]
        }
      ],
      "source": [
        "history = ANN_model.fit(x_traincnn, Y_train, validation_data=(x_testcnn, Y_test), batch_size=64, epochs=600, verbose=1,class_weight=class_weights,callbacks=cp_callback)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "07734eee",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07734eee",
        "outputId": "5f703e82-c025-4978-8ba2-0abf8e4de207"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7966fe841450>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "ANN_model.load_weights(checkpoint_path) #to load model with highest accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "432f2bf6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "432f2bf6",
        "outputId": "fe70ac5c-d18a-45e8-ece2-58714c551bed"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Plot model accuracy over ephocs\n",
        "plt.plot(history.history['sparse_categorical_accuracy'])\n",
        "plt.plot(history.history['val_sparse_categorical_accuracy'])\n",
        "plt.ylim(0, 1)\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "1f25db3c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f25db3c",
        "outputId": "e0ff1304-0cc9-4df8-9c4d-93f33ebeb285"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8033 - sparse_categorical_accuracy: 0.8692\n",
            "Pre-training accuracy: 86.9159%\n"
          ]
        }
      ],
      "source": [
        "# Calculate pre-training accuracy\n",
        "score = ANN_model.evaluate(x_testcnn, Y_test, verbose=1)\n",
        "accuracy = 100*score[1]\n",
        "\n",
        "print(\"Pre-training accuracy: %.4f%%\" % accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "6a416548",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6a416548",
        "outputId": "bc55d57c-9e77-4013-a661-db6cdbb4824c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy:  1.0\n",
            "Testing Accuracy:  0.8691588640213013\n"
          ]
        }
      ],
      "source": [
        "# Evaluating the model on the training and testing set\n",
        "score = ANN_model.evaluate(x_traincnn, Y_train, verbose=0)\n",
        "print(\"Training Accuracy: \", score[1])\n",
        "\n",
        "score = ANN_model.evaluate(x_testcnn, Y_test, verbose=0)\n",
        "print(\"Testing Accuracy: \", score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "ad9c9346",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad9c9346",
        "outputId": "7389b050-0132-484b-dbf0-4d90bf4bfb9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 4ms/step\n"
          ]
        }
      ],
      "source": [
        "#Get predictions from model\n",
        "y_test_predictions = ANN_model.predict(x_testcnn) # it will give the prediction data of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "196ef800",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "196ef800",
        "outputId": "00c25fed-9e01-4739-a9e5-8ae221709625"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(107, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "y_test_predictions.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "9b052414",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b052414",
        "outputId": "0123e1f5-a4cd-4668-dac5-53f578477fd6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.05414722e-06, 7.50622785e-05, 9.90843058e-01, 9.44150145e-08,\n",
              "        8.94588325e-03, 7.44657336e-10, 1.33814261e-04],\n",
              "       [1.80562574e-06, 8.79309810e-05, 2.46830612e-10, 9.99497890e-01,\n",
              "        3.89675904e-07, 4.11701156e-04, 2.28657612e-07],\n",
              "       [9.70820010e-01, 7.17730708e-10, 2.86868215e-02, 3.99654573e-06,\n",
              "        2.95946393e-07, 1.98077710e-09, 4.88933001e-04],\n",
              "       [1.55377595e-04, 4.35092574e-07, 7.05638994e-03, 7.86025776e-05,\n",
              "        9.92627800e-01, 1.67810976e-09, 8.13965453e-05],\n",
              "       [2.50314176e-02, 5.12412335e-09, 9.73230422e-01, 1.61453897e-07,\n",
              "        1.29706123e-07, 8.32635294e-09, 1.73791090e-03],\n",
              "       [7.27774901e-03, 2.73440255e-05, 6.45918190e-01, 5.58275701e-07,\n",
              "        3.35759789e-01, 8.35766834e-09, 1.10163968e-02],\n",
              "       [7.28818161e-09, 3.97467084e-04, 4.58845850e-10, 9.97909069e-01,\n",
              "        5.11849339e-06, 1.68733543e-03, 1.04144613e-06],\n",
              "       [5.72194722e-07, 6.71289116e-02, 6.29969727e-05, 3.45820677e-04,\n",
              "        1.32945017e-04, 9.32328701e-01, 1.16633288e-07],\n",
              "       [5.90878596e-11, 3.40057682e-06, 3.19928084e-08, 4.17503173e-07,\n",
              "        9.99994874e-01, 1.47270169e-08, 1.30203182e-06],\n",
              "       [2.73366857e-10, 4.32329252e-05, 8.02707500e-09, 9.99837875e-01,\n",
              "        3.30794319e-05, 8.48411291e-05, 9.36960475e-07],\n",
              "       [2.25714189e-07, 1.37415119e-08, 2.25770837e-05, 1.54897066e-07,\n",
              "        5.29355511e-08, 6.47165024e-08, 9.99976873e-01],\n",
              "       [2.77607296e-06, 5.64975977e-01, 3.64844209e-06, 1.11536449e-03,\n",
              "        1.34339653e-05, 4.33888733e-01, 5.47174999e-08],\n",
              "       [9.99634385e-01, 2.34108910e-09, 3.58723715e-04, 2.56089720e-06,\n",
              "        2.19351676e-07, 6.30983443e-09, 4.09423001e-06],\n",
              "       [8.47418414e-05, 2.12867119e-04, 1.24132418e-06, 5.94346285e-01,\n",
              "        3.98039311e-01, 1.58503190e-06, 7.31394487e-03],\n",
              "       [3.89812476e-06, 6.95132434e-01, 7.54252540e-07, 2.91254640e-01,\n",
              "        1.03938748e-06, 1.27351675e-02, 8.72076722e-04],\n",
              "       [4.73975970e-10, 1.41313738e-09, 1.36639864e-12, 9.99999404e-01,\n",
              "        1.56588413e-07, 1.48791190e-09, 4.52888486e-07],\n",
              "       [2.41157933e-04, 4.68018726e-08, 1.39871454e-02, 2.34309082e-05,\n",
              "        9.49139670e-02, 3.56178953e-06, 8.90830636e-01],\n",
              "       [8.24559538e-05, 9.14642274e-01, 1.32263249e-05, 2.95905083e-05,\n",
              "        2.48978467e-05, 8.52066502e-02, 8.39650340e-07],\n",
              "       [1.74364345e-06, 3.22478684e-08, 7.36047951e-08, 6.55370513e-08,\n",
              "        9.99997258e-01, 4.23552592e-07, 3.23375332e-07],\n",
              "       [2.41839618e-04, 3.97149452e-05, 1.00999387e-04, 1.45031418e-05,\n",
              "        9.99386430e-01, 2.17323691e-06, 2.14372296e-04],\n",
              "       [2.07101647e-02, 5.65687515e-07, 9.79252994e-01, 2.83254707e-07,\n",
              "        1.14582763e-05, 6.27648262e-07, 2.40197878e-05],\n",
              "       [8.67992416e-02, 9.03505802e-01, 1.76930627e-07, 2.81934135e-05,\n",
              "        1.89368275e-05, 7.38071464e-03, 2.26697908e-03],\n",
              "       [2.14779429e-05, 1.83671796e-06, 4.03253893e-08, 2.60199813e-05,\n",
              "        9.99949098e-01, 1.52757821e-06, 1.83407280e-08],\n",
              "       [2.89845389e-06, 1.94039929e-03, 5.46117917e-07, 2.95463578e-05,\n",
              "        1.42104745e-01, 2.81134289e-05, 8.55893791e-01],\n",
              "       [2.13062158e-03, 7.85506738e-04, 1.64759664e-10, 5.33604043e-06,\n",
              "        5.59038142e-07, 9.97076392e-01, 1.56121132e-06],\n",
              "       [1.36508213e-04, 1.84293654e-07, 9.99863029e-01, 1.33120665e-07,\n",
              "        4.19088124e-08, 1.22284959e-07, 3.97253208e-09],\n",
              "       [1.94880681e-06, 3.11735491e-08, 9.99995470e-01, 3.87478716e-09,\n",
              "        2.27431360e-06, 1.13953305e-07, 6.24856966e-08],\n",
              "       [3.08504933e-09, 7.24874326e-07, 7.33504535e-10, 9.99996781e-01,\n",
              "        1.68085364e-06, 1.92152456e-07, 6.59070963e-07],\n",
              "       [1.36892941e-08, 1.21868849e-04, 1.23037113e-04, 1.42943622e-06,\n",
              "        4.38314629e-09, 1.05756499e-07, 9.99753535e-01],\n",
              "       [7.91074157e-01, 1.42391491e-05, 3.93159053e-06, 5.86679489e-05,\n",
              "        9.95927081e-02, 7.62608761e-06, 1.09248683e-01],\n",
              "       [2.42667770e-08, 3.64933647e-02, 1.41717115e-11, 8.98172459e-07,\n",
              "        1.81712867e-10, 9.63505685e-01, 1.79631297e-08],\n",
              "       [2.84474897e-08, 9.99187887e-01, 2.20092303e-07, 4.60910456e-07,\n",
              "        2.08062397e-06, 7.98846828e-04, 1.04802939e-05],\n",
              "       [1.70621952e-08, 9.97336686e-01, 1.71392878e-06, 1.13669194e-05,\n",
              "        7.26609173e-08, 2.64984113e-03, 2.62810659e-07],\n",
              "       [9.89099920e-01, 3.82400231e-06, 2.33624550e-03, 3.66824054e-07,\n",
              "        1.85086307e-07, 8.55948869e-03, 2.23808296e-08],\n",
              "       [4.04461662e-06, 5.03777244e-07, 3.49154362e-07, 1.59826925e-07,\n",
              "        9.99973655e-01, 2.13411186e-05, 4.79072177e-08],\n",
              "       [2.04933439e-08, 9.99995470e-01, 1.42535939e-09, 7.73659625e-09,\n",
              "        2.11594647e-06, 2.44171406e-06, 2.34181852e-09],\n",
              "       [9.46086466e-01, 1.19592569e-05, 2.32833452e-04, 2.67963333e-06,\n",
              "        5.27518801e-02, 5.18619026e-06, 9.09003254e-04],\n",
              "       [4.12504005e-06, 7.02402413e-01, 3.01915826e-08, 1.04944035e-03,\n",
              "        1.65433089e-08, 2.96543568e-01, 3.42807709e-07],\n",
              "       [3.40385258e-01, 7.21131643e-09, 6.59613073e-01, 2.30360175e-08,\n",
              "        1.02890999e-06, 1.26240039e-07, 5.51837786e-07],\n",
              "       [8.28015734e-04, 1.85432855e-05, 9.98522937e-01, 4.99074019e-07,\n",
              "        1.25041720e-06, 2.74675749e-05, 6.01366512e-04],\n",
              "       [4.81415896e-07, 6.07889490e-08, 9.99998331e-01, 3.15649773e-09,\n",
              "        7.47625904e-07, 1.18426469e-09, 3.05124189e-07],\n",
              "       [3.51937860e-02, 2.47608132e-05, 9.50988531e-01, 7.28172108e-06,\n",
              "        8.34281615e-04, 4.19748005e-07, 1.29510313e-02],\n",
              "       [1.04640927e-08, 4.82566293e-06, 1.51909944e-06, 1.38065981e-04,\n",
              "        9.99811590e-01, 2.34417439e-05, 2.04771604e-05],\n",
              "       [3.14074032e-06, 9.98238087e-01, 2.31678655e-06, 5.13814302e-06,\n",
              "        5.98077143e-09, 1.75005442e-03, 1.29390082e-06],\n",
              "       [2.89697755e-09, 3.11743715e-05, 6.06881351e-11, 2.00618641e-03,\n",
              "        1.14150733e-09, 9.97962594e-01, 3.31623551e-09],\n",
              "       [9.98310566e-01, 1.17651076e-07, 3.60652484e-05, 4.89442755e-06,\n",
              "        3.26251275e-08, 1.21904293e-07, 1.64826913e-03],\n",
              "       [9.81869016e-05, 3.83270621e-01, 5.52785025e-07, 5.28879063e-05,\n",
              "        2.23317352e-06, 3.14655602e-02, 5.85109949e-01],\n",
              "       [7.64833175e-08, 9.89242733e-01, 1.73137707e-07, 1.11283794e-06,\n",
              "        2.32483970e-07, 1.07554318e-02, 2.39141798e-07],\n",
              "       [4.03375278e-04, 3.35896134e-01, 7.98542175e-08, 4.37116064e-03,\n",
              "        6.92906979e-05, 6.43310606e-01, 1.59493387e-02],\n",
              "       [2.79213364e-08, 1.51093491e-06, 1.15605407e-11, 9.99968052e-01,\n",
              "        3.24922169e-08, 3.02986628e-05, 5.34869926e-08],\n",
              "       [3.46538198e-09, 7.36373484e-01, 1.30831063e-06, 1.98694109e-03,\n",
              "        3.32629293e-06, 2.61630505e-01, 4.35040147e-06],\n",
              "       [1.55673086e-04, 5.97331405e-01, 1.27244803e-05, 1.07178334e-02,\n",
              "        3.39891195e-01, 4.96995822e-02, 2.19164323e-03],\n",
              "       [7.10746804e-07, 1.61469709e-02, 2.81418853e-08, 3.18517905e-08,\n",
              "        7.59812713e-10, 9.83849287e-01, 2.95063410e-06],\n",
              "       [1.45902581e-04, 1.27165606e-07, 1.17872830e-11, 1.98073631e-05,\n",
              "        6.14218006e-04, 1.53816401e-07, 9.99219775e-01],\n",
              "       [7.76084606e-03, 4.80475526e-09, 9.92130935e-01, 9.00756845e-07,\n",
              "        1.05730898e-04, 8.27219651e-07, 7.34710852e-07],\n",
              "       [1.20677930e-06, 2.85682381e-06, 4.01803888e-08, 6.99340086e-03,\n",
              "        2.36623309e-05, 9.92978394e-01, 4.54215922e-07],\n",
              "       [5.97845376e-01, 2.80453096e-05, 3.26647260e-03, 6.48619534e-05,\n",
              "        6.44872636e-02, 1.26513117e-03, 3.33042830e-01],\n",
              "       [2.13605776e-01, 9.32251060e-05, 7.62509823e-01, 3.76835756e-04,\n",
              "        2.33759973e-02, 2.95330938e-05, 8.73078170e-06],\n",
              "       [3.79203868e-07, 1.72945170e-03, 1.63396974e-09, 2.41356418e-02,\n",
              "        1.11187792e-05, 9.74119186e-01, 4.18205491e-06],\n",
              "       [1.59545120e-11, 9.93720889e-01, 6.61628690e-07, 5.39253280e-03,\n",
              "        3.55802285e-06, 8.82464519e-04, 2.18421392e-09],\n",
              "       [1.88307677e-05, 9.51197267e-01, 2.72765938e-05, 3.85074653e-02,\n",
              "        1.35204946e-05, 1.00784618e-02, 1.57146438e-04],\n",
              "       [4.59541334e-03, 1.34357479e-05, 2.89902408e-10, 1.86220394e-04,\n",
              "        9.86160219e-01, 2.44771491e-05, 9.02038254e-03],\n",
              "       [1.43091631e-04, 3.24301310e-02, 5.49896213e-05, 3.87284636e-05,\n",
              "        9.59934652e-01, 3.64894257e-03, 3.74947651e-03],\n",
              "       [2.03654008e-06, 9.50976834e-03, 1.10285623e-06, 1.82278731e-04,\n",
              "        4.78161454e-01, 7.19294985e-05, 5.12071431e-01],\n",
              "       [1.64664725e-05, 2.12846950e-01, 7.26518712e-09, 4.99323934e-01,\n",
              "        3.63704719e-04, 2.87285179e-01, 1.63777731e-04],\n",
              "       [1.10302869e-08, 2.42524766e-05, 1.19907173e-09, 9.99782026e-01,\n",
              "        8.93481047e-06, 2.28260774e-06, 1.82399250e-04],\n",
              "       [9.99972224e-01, 2.69442890e-09, 5.35473418e-06, 2.34353359e-09,\n",
              "        4.13443324e-08, 7.14672321e-09, 2.23417373e-05],\n",
              "       [1.19676474e-06, 8.37089090e-07, 2.57287525e-11, 9.99431193e-01,\n",
              "        2.73520618e-06, 9.02398483e-07, 5.63114183e-04],\n",
              "       [2.12650480e-06, 9.99996662e-01, 8.53155213e-10, 8.86523688e-10,\n",
              "        6.13915718e-09, 1.09369080e-06, 4.65600891e-08],\n",
              "       [1.72905601e-07, 9.78013635e-01, 7.28165014e-06, 1.51545887e-08,\n",
              "        1.52612529e-07, 2.19785981e-02, 1.57369172e-07],\n",
              "       [1.80464203e-11, 8.81175843e-09, 1.28367967e-11, 9.99999523e-01,\n",
              "        4.95479524e-09, 4.58255897e-07, 6.99076708e-09],\n",
              "       [2.46204674e-08, 3.50806743e-01, 4.95510676e-06, 1.83152873e-02,\n",
              "        3.87859400e-05, 6.30833983e-01, 2.32981094e-07],\n",
              "       [1.27795090e-06, 2.17265990e-02, 2.47535587e-04, 1.64942378e-06,\n",
              "        3.87963695e-07, 9.78017747e-01, 4.82989617e-06],\n",
              "       [6.20994210e-01, 3.66032764e-05, 2.75184691e-01, 3.54696676e-05,\n",
              "        9.84628499e-02, 1.61660559e-04, 5.12456568e-03],\n",
              "       [2.49635775e-07, 2.17234031e-09, 9.99999404e-01, 8.51143085e-08,\n",
              "        2.87937979e-07, 5.19843335e-10, 3.75294296e-10],\n",
              "       [1.61310737e-07, 9.99730527e-01, 1.62305769e-05, 1.12916114e-05,\n",
              "        6.28404734e-07, 2.36269625e-04, 4.90416687e-06],\n",
              "       [9.96499658e-01, 2.10111059e-04, 1.24423299e-04, 3.19792548e-06,\n",
              "        2.19692141e-04, 5.40516303e-05, 2.88887857e-03],\n",
              "       [7.07650185e-03, 2.35009646e-12, 9.92923021e-01, 5.66125209e-08,\n",
              "        3.29473622e-08, 3.73226117e-10, 3.98110160e-07],\n",
              "       [1.08552840e-05, 7.29840863e-08, 1.92207449e-06, 1.46113798e-05,\n",
              "        9.99972343e-01, 2.23360462e-11, 2.24604534e-07],\n",
              "       [4.19288158e-01, 9.68689346e-06, 8.67344730e-04, 9.35510543e-05,\n",
              "        5.79331577e-01, 3.42855375e-04, 6.68399443e-05],\n",
              "       [9.52026923e-04, 2.79866070e-01, 3.16648948e-06, 6.99313581e-01,\n",
              "        1.18723093e-02, 6.17054699e-04, 7.37577397e-03],\n",
              "       [2.98052598e-12, 2.69844321e-07, 1.50362028e-10, 1.10176525e-05,\n",
              "        9.99988556e-01, 5.54599140e-08, 1.38839326e-07],\n",
              "       [6.13499225e-08, 4.04549610e-06, 1.78998830e-11, 2.43283989e-06,\n",
              "        4.58199702e-06, 9.99988914e-01, 3.82656928e-08],\n",
              "       [9.95859087e-01, 2.52455948e-07, 3.16929258e-03, 7.62388822e-07,\n",
              "        3.11454132e-05, 5.39787252e-05, 8.85448651e-04],\n",
              "       [8.40523164e-04, 2.80703916e-05, 2.88434137e-07, 8.37167065e-08,\n",
              "        7.25573983e-08, 2.44269213e-05, 9.99106467e-01],\n",
              "       [7.09305015e-09, 1.16752972e-06, 2.76292567e-09, 2.72234075e-07,\n",
              "        3.28526362e-09, 2.40960730e-07, 9.99998331e-01],\n",
              "       [1.27027752e-05, 2.42523570e-02, 2.36185544e-04, 5.12713414e-05,\n",
              "        1.83044104e-08, 9.75427687e-01, 1.97423524e-05],\n",
              "       [9.91625478e-04, 4.42327701e-06, 9.25658562e-04, 6.24606173e-07,\n",
              "        9.98039067e-01, 7.45656052e-07, 3.79936573e-05],\n",
              "       [6.87104821e-01, 1.32470377e-05, 1.08548600e-04, 2.96525668e-05,\n",
              "        3.12653422e-01, 1.18176968e-05, 7.84734220e-05],\n",
              "       [9.10298139e-12, 4.80552612e-11, 1.43958187e-11, 9.99999404e-01,\n",
              "        5.09197207e-07, 7.54601857e-08, 6.07502326e-10],\n",
              "       [1.12549412e-06, 2.42572241e-06, 8.41556311e-01, 9.10588426e-07,\n",
              "        1.58417240e-01, 3.81317555e-09, 2.20200054e-05],\n",
              "       [1.51510845e-04, 3.71930291e-08, 9.99846339e-01, 3.65143755e-08,\n",
              "        6.11119333e-08, 3.36001893e-09, 2.04593766e-06],\n",
              "       [2.25990976e-10, 2.20806599e-01, 1.41656475e-09, 2.47442513e-04,\n",
              "        3.24248139e-09, 7.78945982e-01, 1.75950343e-09],\n",
              "       [1.43112922e-09, 1.26170976e-10, 9.99911666e-01, 2.12732701e-07,\n",
              "        8.66454575e-05, 8.42692561e-13, 1.48265622e-06],\n",
              "       [7.32630074e-01, 2.29212745e-07, 2.67251313e-01, 4.58394851e-08,\n",
              "        1.21610874e-05, 1.00608504e-05, 9.60783800e-05],\n",
              "       [1.02057494e-10, 2.30699783e-07, 1.34131781e-07, 9.99699473e-01,\n",
              "        2.98216677e-04, 5.36735172e-08, 1.97367058e-06],\n",
              "       [1.89213822e-09, 6.22377456e-07, 9.86938238e-01, 4.51548132e-09,\n",
              "        1.30608985e-02, 3.90837307e-10, 3.05751371e-07],\n",
              "       [9.94513273e-01, 4.39600534e-08, 5.43573080e-03, 4.18111495e-06,\n",
              "        2.68338990e-05, 1.26877211e-07, 1.99149745e-05],\n",
              "       [6.47300567e-06, 3.90124886e-04, 1.81590976e-09, 2.07861513e-06,\n",
              "        1.04821638e-07, 2.35417360e-06, 9.99598801e-01],\n",
              "       [1.54531730e-08, 1.85279117e-03, 7.59894874e-07, 9.46099818e-01,\n",
              "        4.58622724e-02, 5.87433809e-03, 3.09972238e-04],\n",
              "       [5.38747758e-04, 1.40572843e-06, 9.41827951e-04, 1.43149242e-04,\n",
              "        9.88488853e-01, 4.12140821e-07, 9.88573581e-03],\n",
              "       [2.74563740e-06, 1.45639591e-02, 1.30586200e-08, 3.92263569e-02,\n",
              "        9.06271301e-03, 1.52393794e-02, 9.21904802e-01],\n",
              "       [7.63262790e-07, 3.97545053e-04, 8.33222935e-11, 2.46345135e-05,\n",
              "        5.93830679e-11, 9.99576986e-01, 1.02431841e-07],\n",
              "       [4.16011380e-06, 1.58244386e-01, 2.59494704e-10, 7.14058444e-07,\n",
              "        6.27389962e-09, 8.41750264e-01, 4.63572064e-07],\n",
              "       [1.13357728e-05, 7.28779526e-07, 4.46036100e-01, 2.75148454e-06,\n",
              "        5.37571371e-01, 9.14958218e-06, 1.63684729e-02],\n",
              "       [1.43697594e-06, 9.43005025e-01, 1.75480134e-04, 7.35422509e-06,\n",
              "        4.08967317e-04, 1.14486739e-03, 5.52569181e-02],\n",
              "       [9.35453773e-01, 5.00069897e-09, 6.44209161e-02, 2.45039537e-05,\n",
              "        2.79075066e-05, 4.17233568e-05, 3.12232223e-05]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "y_test_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "d55ab0be",
      "metadata": {
        "id": "d55ab0be"
      },
      "outputs": [],
      "source": [
        "y_test_predictions=np.argmax(y_test_predictions,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "4162138e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4162138e",
        "outputId": "9b5a3a14-7fbf-42af-fe77-6dcc01ecd540"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 3, 0, 4, 2, 2, 3, 5, 4, 3, 6, 1, 0, 3, 1, 3, 6, 1, 4, 4, 2, 1,\n",
              "       4, 6, 5, 2, 2, 3, 6, 0, 5, 1, 1, 0, 4, 1, 0, 1, 2, 2, 2, 2, 4, 1,\n",
              "       5, 0, 6, 1, 5, 3, 1, 1, 5, 6, 2, 5, 0, 2, 5, 1, 1, 4, 4, 6, 3, 3,\n",
              "       0, 3, 1, 1, 3, 5, 5, 0, 2, 1, 0, 2, 4, 4, 3, 4, 5, 0, 6, 6, 5, 4,\n",
              "       0, 3, 2, 2, 5, 2, 0, 3, 2, 0, 6, 3, 4, 6, 5, 5, 4, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "y_test_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "33de2d8e",
      "metadata": {
        "id": "33de2d8e"
      },
      "outputs": [],
      "source": [
        "#df.replace({ 'neutral': 0, 'calm': 1,'happy': 2,'sad': 3, 'angry':4,'fearful':5,'disgust':6,'surprised':7}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "a7ee95c4",
      "metadata": {
        "id": "a7ee95c4"
      },
      "outputs": [],
      "source": [
        "emotions={\n",
        " 0: 'happyness',\n",
        " 1: 'neutral',\n",
        " 2: 'anger',\n",
        " 3: 'sadness',\n",
        " 4: 'fear',\n",
        " 5: 'boredom',\n",
        " 6: 'disgust',\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "c48c660c",
      "metadata": {
        "id": "c48c660c"
      },
      "outputs": [],
      "source": [
        "label=[]\n",
        "for i in y_test_predictions:\n",
        "    label1=emotions[i]\n",
        "    label.append(label1)\n",
        "label\n",
        "y_pred_acc=np.array(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "fe27f0ca",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe27f0ca",
        "outputId": "b4dbbc56-1795-4db3-c771-98848d2988cc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['anger', 'sadness', 'happyness', 'fear', 'anger', 'anger',\n",
              "       'sadness', 'boredom', 'fear', 'sadness', 'disgust', 'neutral',\n",
              "       'happyness', 'sadness', 'neutral', 'sadness', 'disgust', 'neutral',\n",
              "       'fear', 'fear', 'anger', 'neutral', 'fear', 'disgust', 'boredom',\n",
              "       'anger', 'anger', 'sadness', 'disgust', 'happyness', 'boredom',\n",
              "       'neutral', 'neutral', 'happyness', 'fear', 'neutral', 'happyness',\n",
              "       'neutral', 'anger', 'anger', 'anger', 'anger', 'fear', 'neutral',\n",
              "       'boredom', 'happyness', 'disgust', 'neutral', 'boredom', 'sadness',\n",
              "       'neutral', 'neutral', 'boredom', 'disgust', 'anger', 'boredom',\n",
              "       'happyness', 'anger', 'boredom', 'neutral', 'neutral', 'fear',\n",
              "       'fear', 'disgust', 'sadness', 'sadness', 'happyness', 'sadness',\n",
              "       'neutral', 'neutral', 'sadness', 'boredom', 'boredom', 'happyness',\n",
              "       'anger', 'neutral', 'happyness', 'anger', 'fear', 'fear',\n",
              "       'sadness', 'fear', 'boredom', 'happyness', 'disgust', 'disgust',\n",
              "       'boredom', 'fear', 'happyness', 'sadness', 'anger', 'anger',\n",
              "       'boredom', 'anger', 'happyness', 'sadness', 'anger', 'happyness',\n",
              "       'disgust', 'sadness', 'fear', 'disgust', 'boredom', 'boredom',\n",
              "       'fear', 'neutral', 'happyness'], dtype='<U9')"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "y_pred_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "c11f7f56",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c11f7f56",
        "outputId": "6d18dc80-a5b8-4395-bd59-db6454197873"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "458    2\n",
              "235    3\n",
              "281    0\n",
              "55     4\n",
              "284    2\n",
              "      ..\n",
              "355    5\n",
              "392    5\n",
              "162    4\n",
              "283    1\n",
              "499    2\n",
              "Name: Label, Length: 107, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "Y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "f1ef42f3",
      "metadata": {
        "id": "f1ef42f3"
      },
      "outputs": [],
      "source": [
        "#df.replace({ 'neutral': 0, 'calm': 1,'happy': 2,'sad': 3, 'angry':4,'fearful':5,'disgust':6,'surprised':7}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "185d8266",
      "metadata": {
        "id": "185d8266"
      },
      "outputs": [],
      "source": [
        "emotion={\n",
        " 0: 'happyness',\n",
        " 1: 'neutral',\n",
        " 2: 'anger',\n",
        " 3: 'sadness',\n",
        " 4: 'fear',\n",
        " 5: 'boredom',\n",
        " 6: 'disgust',\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "f19f7ff3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "f19f7ff3",
        "outputId": "20500f0e-707c-4c51-e21f-faced66243c1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'happyness'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "emotion[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "8fd2ffee",
      "metadata": {
        "id": "8fd2ffee"
      },
      "outputs": [],
      "source": [
        "label_test=[]\n",
        "for i in Y_test:\n",
        "    label_test.append(emotion[i])\n",
        "label_test\n",
        "y_true_accu=np.array(label_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "31a3449b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31a3449b",
        "outputId": "4df91222-20e5-4ee7-c5de-98e57423198a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['anger', 'sadness', 'happyness', 'fear', 'anger', 'happyness',\n",
              "       'sadness', 'boredom', 'fear', 'sadness', 'disgust', 'neutral',\n",
              "       'happyness', 'happyness', 'neutral', 'sadness', 'anger', 'neutral',\n",
              "       'fear', 'fear', 'anger', 'boredom', 'boredom', 'disgust',\n",
              "       'boredom', 'anger', 'anger', 'sadness', 'disgust', 'happyness',\n",
              "       'boredom', 'neutral', 'boredom', 'anger', 'fear', 'neutral',\n",
              "       'happyness', 'neutral', 'anger', 'happyness', 'anger', 'happyness',\n",
              "       'fear', 'neutral', 'boredom', 'happyness', 'disgust', 'neutral',\n",
              "       'boredom', 'sadness', 'neutral', 'neutral', 'boredom', 'disgust',\n",
              "       'anger', 'boredom', 'happyness', 'anger', 'boredom', 'neutral',\n",
              "       'neutral', 'fear', 'fear', 'disgust', 'sadness', 'sadness',\n",
              "       'happyness', 'sadness', 'neutral', 'neutral', 'sadness', 'boredom',\n",
              "       'boredom', 'happyness', 'anger', 'neutral', 'happyness', 'anger',\n",
              "       'fear', 'fear', 'disgust', 'fear', 'boredom', 'happyness',\n",
              "       'disgust', 'disgust', 'boredom', 'happyness', 'fear', 'sadness',\n",
              "       'anger', 'anger', 'boredom', 'anger', 'anger', 'sadness', 'anger',\n",
              "       'happyness', 'disgust', 'sadness', 'fear', 'disgust', 'boredom',\n",
              "       'boredom', 'fear', 'neutral', 'anger'], dtype='<U9')"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "y_true_accu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "5807d3ec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5807d3ec",
        "outputId": "40643a00-5858-4faf-9089-10850780bcc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 86.92%\n"
          ]
        }
      ],
      "source": [
        "#DataFlair - Calculate the accuracy of our model\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy=accuracy_score(y_true=y_true_accu, y_pred=y_pred_acc)\n",
        "\n",
        "#DataFlair - Print the accuracy\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "6635c085",
      "metadata": {
        "id": "6635c085"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm=confusion_matrix(y_true=y_true_accu, y_pred=y_pred_acc)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nD8Eq0d-OcaZ",
        "outputId": "d359b7dd-cf17-4543-9799-ee04d008f41d"
      },
      "id": "nD8Eq0d-OcaZ",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[15  0  1  0  3  0  0]\n",
            " [ 0 15  0  1  0  2  0]\n",
            " [ 0  0 10  0  0  0  1]\n",
            " [ 0  0  0 13  1  0  0]\n",
            " [ 3  0  0  1 11  0  1]\n",
            " [ 0  0  0  0  0 16  0]\n",
            " [ 0  0  0  0  0  0 13]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "2f781089",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f781089",
        "outputId": "3e9f7954-cea4-4f41-f6b5-397503c8e6f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.83      0.79      0.81        19\n",
            "     boredom       1.00      0.83      0.91        18\n",
            "     disgust       0.91      0.91      0.91        11\n",
            "        fear       0.87      0.93      0.90        14\n",
            "   happyness       0.73      0.69      0.71        16\n",
            "     neutral       0.89      1.00      0.94        16\n",
            "     sadness       0.87      1.00      0.93        13\n",
            "\n",
            "    accuracy                           0.87       107\n",
            "   macro avg       0.87      0.88      0.87       107\n",
            "weighted avg       0.87      0.87      0.87       107\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_true_accu,y_pred_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "673530e6",
      "metadata": {
        "id": "673530e6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "ae5cce6c",
      "metadata": {
        "id": "ae5cce6c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "964855f9",
      "metadata": {
        "id": "964855f9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "5f2c0e1a",
      "metadata": {
        "id": "5f2c0e1a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "112a6c83",
      "metadata": {
        "id": "112a6c83"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}